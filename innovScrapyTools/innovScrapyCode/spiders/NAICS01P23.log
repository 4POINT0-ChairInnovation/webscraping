2019-11-09 18:11:44 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: innovScrapyCode)
2019-11-09 18:11:44 [scrapy.utils.log] INFO: Overridden settings: {'AJAXCRAWL_ENABLED': True, 'BOT_NAME': 'innovScrapyCode', 'CONCURRENT_REQUESTS': 160, 'CONCURRENT_REQUESTS_PER_DOMAIN': 32, 'DEPTH_LIMIT': 5, 'DEPTH_PRIORITY': 1, 'DOWNLOAD_DELAY': 2, 'DOWNLOAD_MAXSIZE': 5242880, 'DOWNLOAD_TIMEOUT': 15, 'LOG_FILE': 'NAICS01P23.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'innovationScraping.innovScrapyTools.innovScrapyCode.spiders', 'REACTOR_THREADPOOL_MAXSIZE': 100, 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['innovationScraping.innovScrapyTools.innovScrapyCode.spiders'], 'TELNETCONSOLE_PORT': None}
2019-11-09 18:11:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats', 'scrapy.extensions.logstats.LogStats']
2019-11-09 18:11:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy_fake_useragent.middleware.RandomUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.ajaxcrawl.AjaxCrawlMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-09 18:11:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-09 18:11:44 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-11-09 18:11:44 [scrapy.core.engine] INFO: Spider opened
2019-11-09 18:11:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:11:45 [root] INFO: spider 23 start
2019-11-09 18:11:49 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://www.zapworld.com/robots.txt>: DNS lookup failed: no results for hostname lookup: www.zapworld.com.
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: www.zapworld.com.
2019-11-09 18:13:37 [scrapy.extensions.logstats] INFO: Crawled 51 pages (at 51 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:14:06 [scrapy.extensions.logstats] INFO: Crawled 54 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:14:06 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET https://www.procapslabs.com:443/robots.txt>: User timeout caused connection failure: Getting https://www.procapslabs.com:443/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.procapslabs.com:443/robots.txt took longer than 15.0 seconds..
2019-11-09 18:15:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zuca.com/control/welcome>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zuca.com/control/welcome took longer than 15.0 seconds..
2019-11-09 18:15:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zivobioscience.com/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zivobioscience.com/ took longer than 15.0 seconds..
2019-11-09 18:15:03 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://www.zivix.net/robots.txt>: User timeout caused connection failure.
twisted.internet.error.TimeoutError: User timeout caused connection failure.
2019-11-09 18:15:03 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://ygyi.com/robots.txt>: User timeout caused connection failure.
twisted.internet.error.TimeoutError: User timeout caused connection failure.
2019-11-09 18:15:03 [scrapy.extensions.logstats] INFO: Crawled 54 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:16:21 [scrapy.extensions.logstats] INFO: Crawled 56 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:16:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zonediet.com/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zonediet.com/ took longer than 15.0 seconds..
2019-11-09 18:17:22 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET https://sds.zepinc.com/robots.txt>: User timeout caused connection failure: Getting https://sds.zepinc.com/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://sds.zepinc.com/robots.txt took longer than 15.0 seconds..
2019-11-09 18:17:22 [scrapy.extensions.logstats] INFO: Crawled 58 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:18:20 [scrapy.extensions.logstats] INFO: Crawled 59 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:18:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.procapslabs.com:443/>: User timeout caused connection failure.
2019-11-09 18:18:47 [scrapy.core.scraper] ERROR: Error downloading <GET http://ygyi.com/>: User timeout caused connection failure.
2019-11-09 18:18:47 [scrapy.extensions.logstats] INFO: Crawled 61 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:19:45 [scrapy.extensions.logstats] INFO: Crawled 63 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:21:09 [scrapy.extensions.logstats] INFO: Crawled 67 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:22:04 [scrapy.extensions.logstats] INFO: Crawled 69 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:22:57 [scrapy.extensions.logstats] INFO: Crawled 69 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:24:47 [scrapy.extensions.logstats] INFO: Crawled 76 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:26:10 [scrapy.extensions.logstats] INFO: Crawled 79 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:27:29 [scrapy.extensions.logstats] INFO: Crawled 81 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:28:22 [scrapy.extensions.logstats] INFO: Crawled 83 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:29:19 [scrapy.extensions.logstats] INFO: Crawled 85 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:30:18 [scrapy.extensions.logstats] INFO: Crawled 87 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:31:04 [scrapy.extensions.logstats] INFO: Crawled 88 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:31:52 [scrapy.extensions.logstats] INFO: Crawled 91 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:32:45 [scrapy.extensions.logstats] INFO: Crawled 93 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:33:49 [scrapy.extensions.logstats] INFO: Crawled 96 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:34:46 [scrapy.extensions.logstats] INFO: Crawled 99 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:36:02 [scrapy.extensions.logstats] INFO: Crawled 109 pages (at 10 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:38:24 [scrapy.extensions.logstats] INFO: Crawled 117 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:39:40 [scrapy.extensions.logstats] INFO: Crawled 120 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:41:07 [scrapy.extensions.logstats] INFO: Crawled 120 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:42:26 [scrapy.extensions.logstats] INFO: Crawled 120 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:42:51 [scrapy.extensions.logstats] INFO: Crawled 126 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:44:28 [scrapy.extensions.logstats] INFO: Crawled 131 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:46:53 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET https://support.zagg.com/robots.txt>: User timeout caused connection failure: Getting https://support.zagg.com/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://support.zagg.com/robots.txt took longer than 15.0 seconds..
2019-11-09 18:46:53 [scrapy.extensions.logstats] INFO: Crawled 131 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:47:49 [scrapy.extensions.logstats] INFO: Crawled 138 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:50:02 [scrapy.extensions.logstats] INFO: Crawled 138 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:50:58 [scrapy.extensions.logstats] INFO: Crawled 144 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:52:46 [scrapy.extensions.logstats] INFO: Crawled 147 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:54:12 [scrapy.extensions.logstats] INFO: Crawled 147 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:55:35 [scrapy.extensions.logstats] INFO: Crawled 156 pages (at 9 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:56:56 [scrapy.extensions.logstats] INFO: Crawled 156 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:58:21 [scrapy.extensions.logstats] INFO: Crawled 156 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:58:46 [scrapy.extensions.logstats] INFO: Crawled 160 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:00:07 [scrapy.extensions.logstats] INFO: Crawled 165 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:01:28 [scrapy.extensions.logstats] INFO: Crawled 165 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:02:22 [scrapy.extensions.logstats] INFO: Crawled 165 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:02:50 [scrapy.extensions.logstats] INFO: Crawled 169 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:04:07 [scrapy.extensions.logstats] INFO: Crawled 173 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:05:57 [scrapy.extensions.logstats] INFO: Crawled 173 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:08:16 [scrapy.extensions.logstats] INFO: Crawled 184 pages (at 11 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:10:07 [scrapy.extensions.logstats] INFO: Crawled 188 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:11:41 [scrapy.extensions.logstats] INFO: Crawled 191 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:12:36 [scrapy.extensions.logstats] INFO: Crawled 191 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:12:57 [scrapy.extensions.logstats] INFO: Crawled 196 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:14:19 [scrapy.extensions.logstats] INFO: Crawled 202 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:16:32 [scrapy.extensions.logstats] INFO: Crawled 206 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:18:18 [scrapy.extensions.logstats] INFO: Crawled 206 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:18:48 [scrapy.extensions.logstats] INFO: Crawled 211 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:20:40 [scrapy.extensions.logstats] INFO: Crawled 217 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:23:12 [scrapy.extensions.logstats] INFO: Crawled 217 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:24:19 [scrapy.extensions.logstats] INFO: Crawled 224 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:25:34 [scrapy.extensions.logstats] INFO: Crawled 226 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:26:13 [scrapy.extensions.logstats] INFO: Crawled 229 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:26:52 [scrapy.extensions.logstats] INFO: Crawled 232 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:28:07 [scrapy.extensions.logstats] INFO: Crawled 236 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:29:33 [scrapy.extensions.logstats] INFO: Crawled 239 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:30:02 [scrapy.extensions.logstats] INFO: Crawled 239 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:31:23 [scrapy.extensions.logstats] INFO: Crawled 239 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:31:23 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.eyepromise.com/perform/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.eyepromise.com/perform/ took longer than 15.0 seconds..
2019-11-09 19:31:46 [scrapy.extensions.logstats] INFO: Crawled 243 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:33:07 [scrapy.extensions.logstats] INFO: Crawled 247 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:34:56 [scrapy.extensions.logstats] INFO: Crawled 247 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:36:16 [scrapy.extensions.logstats] INFO: Crawled 255 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:38:23 [scrapy.extensions.logstats] INFO: Crawled 255 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:38:50 [scrapy.extensions.logstats] INFO: Crawled 259 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:40:12 [scrapy.extensions.logstats] INFO: Crawled 262 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:41:30 [scrapy.extensions.logstats] INFO: Crawled 266 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:41:58 [scrapy.extensions.logstats] INFO: Crawled 271 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:43:23 [scrapy.extensions.logstats] INFO: Crawled 271 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:45:30 [scrapy.extensions.logstats] INFO: Crawled 271 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:45:49 [scrapy.extensions.logstats] INFO: Crawled 275 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:47:01 [scrapy.extensions.logstats] INFO: Crawled 280 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:48:21 [scrapy.extensions.logstats] INFO: Crawled 285 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:49:13 [scrapy.extensions.logstats] INFO: Crawled 285 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:51:20 [scrapy.extensions.logstats] INFO: Crawled 285 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:51:48 [scrapy.extensions.logstats] INFO: Crawled 289 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:53:59 [scrapy.extensions.logstats] INFO: Crawled 295 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:55:44 [scrapy.extensions.logstats] INFO: Crawled 298 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:57:08 [scrapy.extensions.logstats] INFO: Crawled 298 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:58:04 [scrapy.extensions.logstats] INFO: Crawled 304 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:00:00 [scrapy.extensions.logstats] INFO: Crawled 304 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:01:00 [scrapy.extensions.logstats] INFO: Crawled 310 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:02:18 [scrapy.extensions.logstats] INFO: Crawled 316 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:03:14 [scrapy.extensions.logstats] INFO: Crawled 319 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:04:11 [scrapy.extensions.logstats] INFO: Crawled 319 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:05:02 [scrapy.extensions.logstats] INFO: Crawled 319 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:05:54 [scrapy.extensions.logstats] INFO: Crawled 327 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:06:49 [scrapy.extensions.logstats] INFO: Crawled 329 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:08:01 [scrapy.extensions.logstats] INFO: Crawled 333 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:09:15 [scrapy.extensions.logstats] INFO: Crawled 337 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:09:51 [scrapy.extensions.logstats] INFO: Crawled 339 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:11:03 [scrapy.extensions.logstats] INFO: Crawled 343 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:12:41 [scrapy.extensions.logstats] INFO: Crawled 343 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:13:02 [scrapy.extensions.logstats] INFO: Crawled 346 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:13:57 [scrapy.extensions.logstats] INFO: Crawled 351 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:15:15 [scrapy.extensions.logstats] INFO: Crawled 351 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:16:07 [scrapy.extensions.logstats] INFO: Crawled 351 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:16:59 [scrapy.extensions.logstats] INFO: Crawled 357 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:18:45 [scrapy.extensions.logstats] INFO: Crawled 363 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:20:03 [scrapy.extensions.logstats] INFO: Crawled 366 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:21:12 [scrapy.extensions.logstats] INFO: Crawled 366 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:22:31 [scrapy.extensions.logstats] INFO: Crawled 366 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:22:54 [scrapy.extensions.logstats] INFO: Crawled 369 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:23:49 [scrapy.extensions.logstats] INFO: Crawled 372 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:25:06 [scrapy.extensions.logstats] INFO: Crawled 378 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:26:22 [scrapy.extensions.logstats] INFO: Crawled 381 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:27:44 [scrapy.extensions.logstats] INFO: Crawled 381 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:29:02 [scrapy.extensions.logstats] INFO: Crawled 381 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:30:27 [scrapy.extensions.logstats] INFO: Crawled 387 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:31:31 [scrapy.extensions.logstats] INFO: Crawled 389 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:32:07 [scrapy.extensions.logstats] INFO: Crawled 391 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:32:49 [scrapy.extensions.logstats] INFO: Crawled 393 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:33:46 [scrapy.extensions.logstats] INFO: Crawled 395 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:35:32 [scrapy.extensions.logstats] INFO: Crawled 399 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:36:29 [scrapy.extensions.logstats] INFO: Crawled 401 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:37:25 [scrapy.extensions.logstats] INFO: Crawled 403 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:38:17 [scrapy.extensions.logstats] INFO: Crawled 405 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:39:05 [scrapy.extensions.logstats] INFO: Crawled 407 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:40:19 [scrapy.extensions.logstats] INFO: Crawled 411 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:40:56 [scrapy.extensions.logstats] INFO: Crawled 413 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:42:12 [scrapy.extensions.logstats] INFO: Crawled 417 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:43:08 [scrapy.extensions.logstats] INFO: Crawled 419 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:44:08 [scrapy.extensions.logstats] INFO: Crawled 421 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:45:02 [scrapy.extensions.logstats] INFO: Crawled 422 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:45:59 [scrapy.extensions.logstats] INFO: Crawled 424 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:46:55 [scrapy.extensions.logstats] INFO: Crawled 427 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:47:54 [scrapy.extensions.logstats] INFO: Crawled 429 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:48:50 [scrapy.extensions.logstats] INFO: Crawled 431 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:50:02 [scrapy.extensions.logstats] INFO: Crawled 434 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:50:58 [scrapy.extensions.logstats] INFO: Crawled 437 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:51:51 [scrapy.extensions.logstats] INFO: Crawled 439 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:53:08 [scrapy.extensions.logstats] INFO: Crawled 442 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:54:02 [scrapy.extensions.logstats] INFO: Crawled 445 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:54:56 [scrapy.extensions.logstats] INFO: Crawled 447 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:55:50 [scrapy.extensions.logstats] INFO: Crawled 447 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:56:45 [scrapy.extensions.logstats] INFO: Crawled 449 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:58:07 [scrapy.extensions.logstats] INFO: Crawled 455 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:58:54 [scrapy.extensions.logstats] INFO: Crawled 458 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:00:08 [scrapy.extensions.logstats] INFO: Crawled 458 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:01:20 [scrapy.extensions.logstats] INFO: Crawled 464 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:01:56 [scrapy.extensions.logstats] INFO: Crawled 467 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:02:53 [scrapy.extensions.logstats] INFO: Crawled 469 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:04:15 [scrapy.extensions.logstats] INFO: Crawled 472 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:05:36 [scrapy.extensions.logstats] INFO: Crawled 472 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:06:02 [scrapy.extensions.logstats] INFO: Crawled 475 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:06:55 [scrapy.extensions.logstats] INFO: Crawled 477 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:07:52 [scrapy.extensions.logstats] INFO: Crawled 481 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:09:15 [scrapy.extensions.logstats] INFO: Crawled 485 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:10:11 [scrapy.extensions.logstats] INFO: Crawled 487 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:11:10 [scrapy.extensions.logstats] INFO: Crawled 489 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:12:00 [scrapy.extensions.logstats] INFO: Crawled 491 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:12:46 [scrapy.extensions.logstats] INFO: Crawled 493 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:13:47 [scrapy.extensions.logstats] INFO: Crawled 495 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:15:29 [scrapy.extensions.logstats] INFO: Crawled 497 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:16:24 [scrapy.extensions.logstats] INFO: Crawled 497 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:16:52 [scrapy.extensions.logstats] INFO: Crawled 499 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:17:46 [scrapy.extensions.logstats] INFO: Crawled 503 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:19:06 [scrapy.extensions.logstats] INFO: Crawled 508 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:20:27 [scrapy.extensions.logstats] INFO: Crawled 508 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:21:18 [scrapy.extensions.logstats] INFO: Crawled 508 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:21:45 [scrapy.extensions.logstats] INFO: Crawled 509 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:23:05 [scrapy.extensions.logstats] INFO: Crawled 515 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:24:27 [scrapy.extensions.logstats] INFO: Crawled 519 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:25:20 [scrapy.extensions.logstats] INFO: Crawled 521 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:26:17 [scrapy.extensions.logstats] INFO: Crawled 521 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:27:01 [scrapy.extensions.logstats] INFO: Crawled 521 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:27:57 [scrapy.extensions.logstats] INFO: Crawled 527 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:28:52 [scrapy.extensions.logstats] INFO: Crawled 531 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:30:05 [scrapy.extensions.logstats] INFO: Crawled 535 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:31:18 [scrapy.extensions.logstats] INFO: Crawled 539 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:31:56 [scrapy.extensions.logstats] INFO: Crawled 541 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:32:48 [scrapy.extensions.logstats] INFO: Crawled 543 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:34:22 [scrapy.extensions.logstats] INFO: Crawled 547 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:35:17 [scrapy.extensions.logstats] INFO: Crawled 549 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:36:10 [scrapy.extensions.logstats] INFO: Crawled 549 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:37:09 [scrapy.extensions.logstats] INFO: Crawled 549 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:37:53 [scrapy.extensions.logstats] INFO: Crawled 555 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:39:11 [scrapy.extensions.logstats] INFO: Crawled 559 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:40:07 [scrapy.extensions.logstats] INFO: Crawled 561 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:41:01 [scrapy.extensions.logstats] INFO: Crawled 561 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:41:50 [scrapy.extensions.logstats] INFO: Crawled 561 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:43:09 [scrapy.extensions.logstats] INFO: Crawled 566 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:43:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.yorktownecabinetry.com/site-map/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.yorktownecabinetry.com/site-map/ took longer than 15.0 seconds..
2019-11-09 21:43:59 [scrapy.extensions.logstats] INFO: Crawled 570 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:44:53 [scrapy.extensions.logstats] INFO: Crawled 572 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:45:50 [scrapy.extensions.logstats] INFO: Crawled 572 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:46:45 [scrapy.extensions.logstats] INFO: Crawled 572 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:48:06 [scrapy.extensions.logstats] INFO: Crawled 575 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:49:01 [scrapy.extensions.logstats] INFO: Crawled 577 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:49:58 [scrapy.extensions.logstats] INFO: Crawled 579 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:50:51 [scrapy.extensions.logstats] INFO: Crawled 581 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:51:47 [scrapy.extensions.logstats] INFO: Crawled 584 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:52:47 [scrapy.extensions.logstats] INFO: Crawled 586 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:53:47 [scrapy.extensions.logstats] INFO: Crawled 589 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:55:03 [scrapy.extensions.logstats] INFO: Crawled 592 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:56:01 [scrapy.extensions.logstats] INFO: Crawled 595 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:57:02 [scrapy.extensions.logstats] INFO: Crawled 598 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:57:02 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET https://redesign-omega-en-my.cms.youngliving.com/robots.txt>: DNS lookup failed: no results for hostname lookup: redesign-omega-en-my.cms.youngliving.com.
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: redesign-omega-en-my.cms.youngliving.com.
2019-11-09 21:58:01 [scrapy.extensions.logstats] INFO: Crawled 603 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:59:25 [scrapy.extensions.logstats] INFO: Crawled 607 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:59:53 [scrapy.extensions.logstats] INFO: Crawled 609 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:00:48 [scrapy.extensions.logstats] INFO: Crawled 611 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:02:35 [scrapy.extensions.logstats] INFO: Crawled 613 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:02:59 [scrapy.extensions.logstats] INFO: Crawled 613 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:03:49 [scrapy.extensions.logstats] INFO: Crawled 615 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:05:07 [scrapy.extensions.logstats] INFO: Crawled 617 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:06:02 [scrapy.extensions.logstats] INFO: Crawled 619 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:06:58 [scrapy.extensions.logstats] INFO: Crawled 621 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:07:52 [scrapy.extensions.logstats] INFO: Crawled 623 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:09:12 [scrapy.extensions.logstats] INFO: Crawled 626 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:10:06 [scrapy.extensions.logstats] INFO: Crawled 628 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:10:58 [scrapy.extensions.logstats] INFO: Crawled 631 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:11:52 [scrapy.extensions.logstats] INFO: Crawled 633 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:13:11 [scrapy.extensions.logstats] INFO: Crawled 636 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:14:02 [scrapy.extensions.logstats] INFO: Crawled 638 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:14:56 [scrapy.extensions.logstats] INFO: Crawled 640 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:15:51 [scrapy.extensions.logstats] INFO: Crawled 642 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:16:46 [scrapy.extensions.logstats] INFO: Crawled 644 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:18:08 [scrapy.extensions.logstats] INFO: Crawled 647 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:19:00 [scrapy.extensions.logstats] INFO: Crawled 649 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:19:59 [scrapy.extensions.logstats] INFO: Crawled 651 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:20:55 [scrapy.extensions.logstats] INFO: Crawled 653 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:21:49 [scrapy.extensions.logstats] INFO: Crawled 655 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:23:11 [scrapy.extensions.logstats] INFO: Crawled 658 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:24:02 [scrapy.extensions.logstats] INFO: Crawled 660 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:24:57 [scrapy.extensions.logstats] INFO: Crawled 662 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:25:51 [scrapy.extensions.logstats] INFO: Crawled 664 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:27:08 [scrapy.extensions.logstats] INFO: Crawled 666 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:27:59 [scrapy.extensions.logstats] INFO: Crawled 668 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:28:53 [scrapy.extensions.logstats] INFO: Crawled 670 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:29:47 [scrapy.extensions.logstats] INFO: Crawled 672 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:31:12 [scrapy.extensions.logstats] INFO: Crawled 675 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:32:05 [scrapy.extensions.logstats] INFO: Crawled 677 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:33:00 [scrapy.extensions.logstats] INFO: Crawled 679 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:33:46 [scrapy.extensions.logstats] INFO: Crawled 681 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:35:10 [scrapy.extensions.logstats] INFO: Crawled 684 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:36:07 [scrapy.extensions.logstats] INFO: Crawled 686 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:36:59 [scrapy.extensions.logstats] INFO: Crawled 688 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:37:53 [scrapy.extensions.logstats] INFO: Crawled 690 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:38:47 [scrapy.extensions.logstats] INFO: Crawled 692 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:40:08 [scrapy.extensions.logstats] INFO: Crawled 695 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:40:35 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.zapworld.com>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: www.zapworld.com.
2019-11-09 22:41:04 [scrapy.extensions.logstats] INFO: Crawled 697 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:41:58 [scrapy.extensions.logstats] INFO: Crawled 699 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:42:53 [scrapy.extensions.logstats] INFO: Crawled 701 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:43:50 [scrapy.extensions.logstats] INFO: Crawled 703 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:44:45 [scrapy.extensions.logstats] INFO: Crawled 705 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:45:48 [scrapy.extensions.logstats] INFO: Crawled 707 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:46:59 [scrapy.extensions.logstats] INFO: Crawled 710 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:47:52 [scrapy.extensions.logstats] INFO: Crawled 712 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:48:48 [scrapy.extensions.logstats] INFO: Crawled 714 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:49:45 [scrapy.extensions.logstats] INFO: Crawled 716 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:51:10 [scrapy.extensions.logstats] INFO: Crawled 720 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:52:09 [scrapy.extensions.logstats] INFO: Crawled 722 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:53:03 [scrapy.extensions.logstats] INFO: Crawled 724 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:54:08 [scrapy.extensions.logstats] INFO: Crawled 726 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:54:49 [scrapy.extensions.logstats] INFO: Crawled 728 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:55:49 [scrapy.extensions.logstats] INFO: Crawled 731 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:57:03 [scrapy.extensions.logstats] INFO: Crawled 734 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:58:00 [scrapy.extensions.logstats] INFO: Crawled 736 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:58:56 [scrapy.extensions.logstats] INFO: Crawled 738 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:59:52 [scrapy.extensions.logstats] INFO: Crawled 740 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:00:57 [scrapy.extensions.logstats] INFO: Crawled 742 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:01:45 [scrapy.extensions.logstats] INFO: Crawled 744 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:03:05 [scrapy.extensions.logstats] INFO: Crawled 747 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:03:57 [scrapy.extensions.logstats] INFO: Crawled 749 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:04:55 [scrapy.extensions.logstats] INFO: Crawled 752 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:05:48 [scrapy.extensions.logstats] INFO: Crawled 755 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:07:10 [scrapy.extensions.logstats] INFO: Crawled 758 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:08:06 [scrapy.extensions.logstats] INFO: Crawled 760 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:08:59 [scrapy.extensions.logstats] INFO: Crawled 762 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:09:55 [scrapy.extensions.logstats] INFO: Crawled 764 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:10:53 [scrapy.extensions.logstats] INFO: Crawled 766 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:11:51 [scrapy.extensions.logstats] INFO: Crawled 768 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:12:48 [scrapy.extensions.logstats] INFO: Crawled 770 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:13:49 [scrapy.extensions.logstats] INFO: Crawled 772 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:14:47 [scrapy.extensions.logstats] INFO: Crawled 774 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:15:48 [scrapy.extensions.logstats] INFO: Crawled 776 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:17:07 [scrapy.extensions.logstats] INFO: Crawled 779 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:17:59 [scrapy.extensions.logstats] INFO: Crawled 780 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:18:56 [scrapy.extensions.logstats] INFO: Crawled 781 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:19:53 [scrapy.extensions.logstats] INFO: Crawled 783 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:20:47 [scrapy.extensions.logstats] INFO: Crawled 785 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:21:56 [scrapy.extensions.logstats] INFO: Crawled 788 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:23:07 [scrapy.extensions.logstats] INFO: Crawled 791 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:24:01 [scrapy.extensions.logstats] INFO: Crawled 793 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:24:59 [scrapy.extensions.logstats] INFO: Crawled 795 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:25:57 [scrapy.extensions.logstats] INFO: Crawled 797 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:26:55 [scrapy.extensions.logstats] INFO: Crawled 799 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:27:52 [scrapy.extensions.logstats] INFO: Crawled 801 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:28:47 [scrapy.extensions.logstats] INFO: Crawled 803 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:29:52 [scrapy.extensions.logstats] INFO: Crawled 806 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:30:50 [scrapy.extensions.logstats] INFO: Crawled 808 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:31:48 [scrapy.extensions.logstats] INFO: Crawled 810 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:32:50 [scrapy.extensions.logstats] INFO: Crawled 812 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:33:49 [scrapy.extensions.logstats] INFO: Crawled 814 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:34:46 [scrapy.extensions.logstats] INFO: Crawled 816 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:36:11 [scrapy.extensions.logstats] INFO: Crawled 819 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:37:11 [scrapy.extensions.logstats] INFO: Crawled 821 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:38:08 [scrapy.extensions.logstats] INFO: Crawled 823 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:39:07 [scrapy.extensions.logstats] INFO: Crawled 825 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:39:57 [scrapy.extensions.logstats] INFO: Crawled 827 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:40:51 [scrapy.extensions.logstats] INFO: Crawled 829 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:41:45 [scrapy.extensions.logstats] INFO: Crawled 832 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:42:45 [scrapy.extensions.logstats] INFO: Crawled 834 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:44:08 [scrapy.extensions.logstats] INFO: Crawled 837 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:45:09 [scrapy.extensions.logstats] INFO: Crawled 839 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:46:11 [scrapy.extensions.logstats] INFO: Crawled 841 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:47:14 [scrapy.extensions.logstats] INFO: Crawled 843 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:48:01 [scrapy.extensions.logstats] INFO: Crawled 845 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:48:54 [scrapy.extensions.logstats] INFO: Crawled 849 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:49:59 [scrapy.extensions.logstats] INFO: Crawled 853 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:51:29 [scrapy.extensions.logstats] INFO: Crawled 855 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:51:49 [scrapy.extensions.logstats] INFO: Crawled 856 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:52:50 [scrapy.extensions.logstats] INFO: Crawled 859 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:53:45 [scrapy.extensions.logstats] INFO: Crawled 861 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:54:57 [scrapy.extensions.logstats] INFO: Crawled 864 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:56:10 [scrapy.extensions.logstats] INFO: Crawled 867 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:57:02 [scrapy.extensions.logstats] INFO: Crawled 869 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:57:59 [scrapy.extensions.logstats] INFO: Crawled 870 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:58:56 [scrapy.extensions.logstats] INFO: Crawled 872 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:59:58 [scrapy.extensions.logstats] INFO: Crawled 874 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:00:55 [scrapy.extensions.logstats] INFO: Crawled 876 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:01:53 [scrapy.extensions.logstats] INFO: Crawled 878 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:02:49 [scrapy.extensions.logstats] INFO: Crawled 880 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:03:45 [scrapy.extensions.logstats] INFO: Crawled 882 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:04:49 [scrapy.extensions.logstats] INFO: Crawled 885 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:05:51 [scrapy.extensions.logstats] INFO: Crawled 886 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:06:38 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET https://vo-zh-tw.cms.youngliving.com/robots.txt>: DNS lookup failed: no results for hostname lookup: vo-zh-tw.cms.youngliving.com.
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: vo-zh-tw.cms.youngliving.com.
2019-11-10 00:07:10 [scrapy.extensions.logstats] INFO: Crawled 889 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:07:51 [scrapy.extensions.logstats] INFO: Crawled 891 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:08:45 [scrapy.extensions.logstats] INFO: Crawled 893 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:09:59 [scrapy.extensions.logstats] INFO: Crawled 898 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:10:45 [scrapy.extensions.logstats] INFO: Crawled 899 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:11:48 [scrapy.extensions.logstats] INFO: Crawled 901 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:13:07 [scrapy.extensions.logstats] INFO: Crawled 904 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:13:56 [scrapy.extensions.logstats] INFO: Crawled 906 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:14:49 [scrapy.extensions.logstats] INFO: Crawled 908 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:15:59 [scrapy.extensions.logstats] INFO: Crawled 911 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:16:54 [scrapy.extensions.logstats] INFO: Crawled 913 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:17:46 [scrapy.extensions.logstats] INFO: Crawled 915 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:18:57 [scrapy.extensions.logstats] INFO: Crawled 918 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:19:45 [scrapy.extensions.logstats] INFO: Crawled 921 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:20:45 [scrapy.extensions.logstats] INFO: Crawled 923 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:22:08 [scrapy.extensions.logstats] INFO: Crawled 926 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:23:12 [scrapy.extensions.logstats] INFO: Crawled 928 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:23:45 [scrapy.extensions.logstats] INFO: Crawled 929 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:25:08 [scrapy.extensions.logstats] INFO: Crawled 934 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:26:10 [scrapy.extensions.logstats] INFO: Crawled 936 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:27:07 [scrapy.extensions.logstats] INFO: Crawled 938 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:28:01 [scrapy.extensions.logstats] INFO: Crawled 940 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:29:00 [scrapy.extensions.logstats] INFO: Crawled 942 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:30:00 [scrapy.extensions.logstats] INFO: Crawled 944 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:30:55 [scrapy.extensions.logstats] INFO: Crawled 946 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:31:53 [scrapy.extensions.logstats] INFO: Crawled 948 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:32:50 [scrapy.extensions.logstats] INFO: Crawled 949 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:33:54 [scrapy.extensions.logstats] INFO: Crawled 951 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:34:59 [scrapy.extensions.logstats] INFO: Crawled 953 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:35:51 [scrapy.extensions.logstats] INFO: Crawled 955 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:36:50 [scrapy.extensions.logstats] INFO: Crawled 958 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:38:07 [scrapy.extensions.logstats] INFO: Crawled 960 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:39:02 [scrapy.extensions.logstats] INFO: Crawled 962 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:40:00 [scrapy.extensions.logstats] INFO: Crawled 964 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:40:59 [scrapy.extensions.logstats] INFO: Crawled 965 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:41:54 [scrapy.extensions.logstats] INFO: Crawled 967 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:42:51 [scrapy.extensions.logstats] INFO: Crawled 970 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:43:50 [scrapy.extensions.logstats] INFO: Crawled 971 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:44:55 [scrapy.extensions.logstats] INFO: Crawled 973 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:45:45 [scrapy.extensions.logstats] INFO: Crawled 975 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:46:47 [scrapy.extensions.logstats] INFO: Crawled 978 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:48:03 [scrapy.extensions.logstats] INFO: Crawled 981 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:48:45 [scrapy.extensions.logstats] INFO: Crawled 983 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:49:55 [scrapy.extensions.logstats] INFO: Crawled 985 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:50:56 [scrapy.extensions.logstats] INFO: Crawled 987 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:51:59 [scrapy.extensions.logstats] INFO: Crawled 990 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:52:50 [scrapy.extensions.logstats] INFO: Crawled 993 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:53:49 [scrapy.extensions.logstats] INFO: Crawled 995 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:54:50 [scrapy.extensions.logstats] INFO: Crawled 998 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:55:52 [scrapy.extensions.logstats] INFO: Crawled 1001 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:56:48 [scrapy.extensions.logstats] INFO: Crawled 1004 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:57:48 [scrapy.extensions.logstats] INFO: Crawled 1007 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:58:46 [scrapy.extensions.logstats] INFO: Crawled 1010 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:59:51 [scrapy.extensions.logstats] INFO: Crawled 1014 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:00:52 [scrapy.extensions.logstats] INFO: Crawled 1017 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:01:48 [scrapy.extensions.logstats] INFO: Crawled 1019 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:02:49 [scrapy.extensions.logstats] INFO: Crawled 1022 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:03:49 [scrapy.extensions.logstats] INFO: Crawled 1025 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:04:48 [scrapy.extensions.logstats] INFO: Crawled 1028 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:05:48 [scrapy.extensions.logstats] INFO: Crawled 1032 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:06:48 [scrapy.extensions.logstats] INFO: Crawled 1035 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:07:45 [scrapy.extensions.logstats] INFO: Crawled 1038 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:08:45 [scrapy.extensions.logstats] INFO: Crawled 1042 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:09:48 [scrapy.extensions.logstats] INFO: Crawled 1044 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:11:05 [scrapy.extensions.logstats] INFO: Crawled 1048 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:12:03 [scrapy.extensions.logstats] INFO: Crawled 1052 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:13:34 [scrapy.extensions.logstats] INFO: Crawled 1052 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:14:06 [scrapy.extensions.logstats] INFO: Crawled 1053 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:15:03 [scrapy.extensions.logstats] INFO: Crawled 1055 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:16:00 [scrapy.extensions.logstats] INFO: Crawled 1058 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:17:02 [scrapy.extensions.logstats] INFO: Crawled 1059 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:18:02 [scrapy.extensions.logstats] INFO: Crawled 1061 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:18:59 [scrapy.extensions.logstats] INFO: Crawled 1063 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:19:55 [scrapy.extensions.logstats] INFO: Crawled 1065 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:20:51 [scrapy.extensions.logstats] INFO: Crawled 1067 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:21:56 [scrapy.extensions.logstats] INFO: Crawled 1069 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:22:59 [scrapy.extensions.logstats] INFO: Crawled 1072 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:23:45 [scrapy.extensions.logstats] INFO: Crawled 1074 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:24:45 [scrapy.extensions.logstats] INFO: Crawled 1077 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:25:54 [scrapy.extensions.logstats] INFO: Crawled 1081 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:27:03 [scrapy.extensions.logstats] INFO: Crawled 1086 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:28:14 [scrapy.extensions.logstats] INFO: Crawled 1090 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:28:56 [scrapy.extensions.logstats] INFO: Crawled 1091 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:30:04 [scrapy.extensions.logstats] INFO: Crawled 1095 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:30:52 [scrapy.extensions.logstats] INFO: Crawled 1097 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:32:23 [scrapy.extensions.logstats] INFO: Crawled 1101 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:33:07 [scrapy.extensions.logstats] INFO: Crawled 1103 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:33:49 [scrapy.extensions.logstats] INFO: Crawled 1105 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:35:29 [scrapy.extensions.logstats] INFO: Crawled 1109 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:36:19 [scrapy.extensions.logstats] INFO: Crawled 1111 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:37:16 [scrapy.extensions.logstats] INFO: Crawled 1113 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:38:14 [scrapy.extensions.logstats] INFO: Crawled 1115 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:39:20 [scrapy.extensions.logstats] INFO: Crawled 1115 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:40:09 [scrapy.extensions.logstats] INFO: Crawled 1116 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:40:54 [scrapy.extensions.logstats] INFO: Crawled 1120 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:42:00 [scrapy.extensions.logstats] INFO: Crawled 1123 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:43:04 [scrapy.extensions.logstats] INFO: Crawled 1123 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:44:07 [scrapy.extensions.logstats] INFO: Crawled 1125 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:45:07 [scrapy.extensions.logstats] INFO: Crawled 1127 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:46:10 [scrapy.extensions.logstats] INFO: Crawled 1129 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:47:08 [scrapy.extensions.logstats] INFO: Crawled 1131 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:47:51 [scrapy.extensions.logstats] INFO: Crawled 1132 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:48:53 [scrapy.extensions.logstats] INFO: Crawled 1136 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:50:12 [scrapy.extensions.logstats] INFO: Crawled 1141 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:51:02 [scrapy.extensions.logstats] INFO: Crawled 1143 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:52:20 [scrapy.extensions.logstats] INFO: Crawled 1146 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:53:18 [scrapy.extensions.logstats] INFO: Crawled 1147 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:53:50 [scrapy.extensions.logstats] INFO: Crawled 1149 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:55:05 [scrapy.extensions.logstats] INFO: Crawled 1153 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:55:51 [scrapy.extensions.logstats] INFO: Crawled 1155 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:56:51 [scrapy.extensions.logstats] INFO: Crawled 1157 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:57:53 [scrapy.extensions.logstats] INFO: Crawled 1159 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:58:53 [scrapy.extensions.logstats] INFO: Crawled 1161 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:59:57 [scrapy.extensions.logstats] INFO: Crawled 1163 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:00:59 [scrapy.extensions.logstats] INFO: Crawled 1163 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:01:58 [scrapy.extensions.logstats] INFO: Crawled 1163 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:02:57 [scrapy.extensions.logstats] INFO: Crawled 1166 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:03:57 [scrapy.extensions.logstats] INFO: Crawled 1170 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:05:33 [scrapy.extensions.logstats] INFO: Crawled 1174 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:06:43 [scrapy.extensions.logstats] INFO: Crawled 1176 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:07:50 [scrapy.extensions.logstats] INFO: Crawled 1178 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:08:57 [scrapy.extensions.logstats] INFO: Crawled 1180 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:09:53 [scrapy.extensions.logstats] INFO: Crawled 1182 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:10:53 [scrapy.extensions.logstats] INFO: Crawled 1184 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:11:57 [scrapy.extensions.logstats] INFO: Crawled 1186 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:13:02 [scrapy.extensions.logstats] INFO: Crawled 1187 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:14:04 [scrapy.extensions.logstats] INFO: Crawled 1189 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:15:04 [scrapy.extensions.logstats] INFO: Crawled 1191 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:16:03 [scrapy.extensions.logstats] INFO: Crawled 1191 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:17:08 [scrapy.extensions.logstats] INFO: Crawled 1194 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:18:07 [scrapy.extensions.logstats] INFO: Crawled 1198 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:19:08 [scrapy.extensions.logstats] INFO: Crawled 1202 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:20:31 [scrapy.extensions.logstats] INFO: Crawled 1203 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:20:56 [scrapy.extensions.logstats] INFO: Crawled 1203 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:22:03 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:23:01 [scrapy.extensions.logstats] INFO: Crawled 1211 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:24:33 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:24:59 [scrapy.extensions.logstats] INFO: Crawled 1217 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:25:58 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:27:26 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:27:55 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:28:57 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:30:27 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:31:20 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:31:51 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:32:55 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:33:49 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:34:51 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:35:53 [scrapy.extensions.logstats] INFO: Crawled 1241 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:36:56 [scrapy.extensions.logstats] INFO: Crawled 1244 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:38:03 [scrapy.extensions.logstats] INFO: Crawled 1247 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:39:01 [scrapy.extensions.logstats] INFO: Crawled 1249 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:40:03 [scrapy.extensions.logstats] INFO: Crawled 1251 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:41:01 [scrapy.extensions.logstats] INFO: Crawled 1253 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:42:00 [scrapy.extensions.logstats] INFO: Crawled 1255 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:43:01 [scrapy.extensions.logstats] INFO: Crawled 1257 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:44:01 [scrapy.extensions.logstats] INFO: Crawled 1259 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:45:01 [scrapy.extensions.logstats] INFO: Crawled 1261 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:45:45 [scrapy.extensions.logstats] INFO: Crawled 1263 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:46:46 [scrapy.extensions.logstats] INFO: Crawled 1266 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:47:53 [scrapy.extensions.logstats] INFO: Crawled 1268 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:48:52 [scrapy.extensions.logstats] INFO: Crawled 1270 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:50:03 [scrapy.extensions.logstats] INFO: Crawled 1274 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:51:08 [scrapy.extensions.logstats] INFO: Crawled 1276 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:52:12 [scrapy.extensions.logstats] INFO: Crawled 1277 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:52:46 [scrapy.extensions.logstats] INFO: Crawled 1278 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:54:09 [scrapy.extensions.logstats] INFO: Crawled 1284 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:55:44 [scrapy.extensions.logstats] INFO: Crawled 1288 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:55:45 [scrapy.extensions.logstats] INFO: Crawled 1288 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:56:46 [scrapy.extensions.logstats] INFO: Crawled 1292 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:57:47 [scrapy.extensions.logstats] INFO: Crawled 1296 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:58:48 [scrapy.extensions.logstats] INFO: Crawled 1298 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:59:48 [scrapy.extensions.logstats] INFO: Crawled 1300 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:00:48 [scrapy.extensions.logstats] INFO: Crawled 1304 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:02:14 [scrapy.extensions.logstats] INFO: Crawled 1310 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:02:45 [scrapy.extensions.logstats] INFO: Crawled 1311 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:04:12 [scrapy.extensions.logstats] INFO: Crawled 1314 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:04:59 [scrapy.extensions.logstats] INFO: Crawled 1318 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:06:29 [scrapy.extensions.logstats] INFO: Crawled 1326 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:07:03 [scrapy.extensions.logstats] INFO: Crawled 1329 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:08:01 [scrapy.extensions.logstats] INFO: Crawled 1332 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:10:05 [scrapy.extensions.logstats] INFO: Crawled 1338 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:11:34 [scrapy.extensions.logstats] INFO: Crawled 1340 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:13:03 [scrapy.extensions.logstats] INFO: Crawled 1343 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:14:01 [scrapy.extensions.logstats] INFO: Crawled 1343 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:15:15 [scrapy.extensions.logstats] INFO: Crawled 1344 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:15:48 [scrapy.extensions.logstats] INFO: Crawled 1345 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:16:53 [scrapy.extensions.logstats] INFO: Crawled 1347 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:17:52 [scrapy.extensions.logstats] INFO: Crawled 1349 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:18:53 [scrapy.extensions.logstats] INFO: Crawled 1351 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:19:53 [scrapy.extensions.logstats] INFO: Crawled 1353 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:20:58 [scrapy.extensions.logstats] INFO: Crawled 1358 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:22:03 [scrapy.extensions.logstats] INFO: Crawled 1358 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:23:03 [scrapy.extensions.logstats] INFO: Crawled 1358 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:23:59 [scrapy.extensions.logstats] INFO: Crawled 1362 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:25:02 [scrapy.extensions.logstats] INFO: Crawled 1365 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:26:30 [scrapy.extensions.logstats] INFO: Crawled 1365 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:26:54 [scrapy.extensions.logstats] INFO: Crawled 1368 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:28:26 [scrapy.extensions.logstats] INFO: Crawled 1370 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:28:58 [scrapy.extensions.logstats] INFO: Crawled 1370 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:29:45 [scrapy.extensions.logstats] INFO: Crawled 1376 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:31:26 [scrapy.extensions.logstats] INFO: Crawled 1380 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:32:16 [scrapy.extensions.logstats] INFO: Crawled 1382 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:33:22 [scrapy.extensions.logstats] INFO: Crawled 1382 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:34:28 [scrapy.extensions.logstats] INFO: Crawled 1382 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:35:00 [scrapy.extensions.logstats] INFO: Crawled 1384 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:37:01 [scrapy.extensions.logstats] INFO: Crawled 1389 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:37:55 [scrapy.extensions.logstats] INFO: Crawled 1390 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:39:54 [scrapy.extensions.logstats] INFO: Crawled 1395 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:40:58 [scrapy.extensions.logstats] INFO: Crawled 1400 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:41:56 [scrapy.extensions.logstats] INFO: Crawled 1400 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:43:27 [scrapy.extensions.logstats] INFO: Crawled 1400 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:43:58 [scrapy.extensions.logstats] INFO: Crawled 1402 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:45:00 [scrapy.extensions.logstats] INFO: Crawled 1408 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:45:49 [scrapy.extensions.logstats] INFO: Crawled 1411 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:47:20 [scrapy.extensions.logstats] INFO: Crawled 1413 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:48:32 [scrapy.extensions.logstats] INFO: Crawled 1413 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:49:12 [scrapy.extensions.logstats] INFO: Crawled 1413 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:49:54 [scrapy.extensions.logstats] INFO: Crawled 1416 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:51:27 [scrapy.extensions.logstats] INFO: Crawled 1421 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:52:30 [scrapy.extensions.logstats] INFO: Crawled 1421 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:53:08 [scrapy.extensions.logstats] INFO: Crawled 1425 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:54:31 [scrapy.extensions.logstats] INFO: Crawled 1429 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:56:34 [scrapy.extensions.logstats] INFO: Crawled 1431 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:57:39 [scrapy.extensions.logstats] INFO: Crawled 1433 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:58:40 [scrapy.extensions.logstats] INFO: Crawled 1436 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:00:12 [scrapy.extensions.logstats] INFO: Crawled 1439 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:01:40 [scrapy.extensions.logstats] INFO: Crawled 1442 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:03:07 [scrapy.extensions.logstats] INFO: Crawled 1444 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:03:48 [scrapy.extensions.logstats] INFO: Crawled 1449 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:05:08 [scrapy.extensions.logstats] INFO: Crawled 1451 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:06:01 [scrapy.extensions.logstats] INFO: Crawled 1454 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:07:03 [scrapy.extensions.logstats] INFO: Crawled 1454 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:08:31 [scrapy.extensions.logstats] INFO: Crawled 1454 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:09:02 [scrapy.extensions.logstats] INFO: Crawled 1457 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:10:07 [scrapy.extensions.logstats] INFO: Crawled 1461 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:11:05 [scrapy.extensions.logstats] INFO: Crawled 1464 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:12:03 [scrapy.extensions.logstats] INFO: Crawled 1467 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:13:30 [scrapy.extensions.logstats] INFO: Crawled 1469 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:15:00 [scrapy.extensions.logstats] INFO: Crawled 1469 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:15:58 [scrapy.extensions.logstats] INFO: Crawled 1469 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:16:59 [scrapy.extensions.logstats] INFO: Crawled 1474 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:18:27 [scrapy.extensions.logstats] INFO: Crawled 1476 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:19:26 [scrapy.extensions.logstats] INFO: Crawled 1476 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:19:58 [scrapy.extensions.logstats] INFO: Crawled 1478 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:20:56 [scrapy.extensions.logstats] INFO: Crawled 1484 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:21:57 [scrapy.extensions.logstats] INFO: Crawled 1487 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:23:22 [scrapy.extensions.logstats] INFO: Crawled 1490 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:24:50 [scrapy.extensions.logstats] INFO: Crawled 1492 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:26:00 [scrapy.extensions.logstats] INFO: Crawled 1492 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:26:45 [scrapy.extensions.logstats] INFO: Crawled 1492 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:29:01 [scrapy.extensions.logstats] INFO: Crawled 1502 pages (at 10 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:31:38 [scrapy.extensions.logstats] INFO: Crawled 1504 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:32:35 [scrapy.extensions.logstats] INFO: Crawled 1507 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:34:09 [scrapy.extensions.logstats] INFO: Crawled 1511 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:36:15 [scrapy.extensions.logstats] INFO: Crawled 1515 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:38:25 [scrapy.extensions.logstats] INFO: Crawled 1518 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:39:59 [scrapy.extensions.logstats] INFO: Crawled 1521 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:41:30 [scrapy.extensions.logstats] INFO: Crawled 1524 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:42:58 [scrapy.extensions.logstats] INFO: Crawled 1528 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:45:01 [scrapy.extensions.logstats] INFO: Crawled 1531 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:46:03 [scrapy.extensions.logstats] INFO: Crawled 1535 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:48:03 [scrapy.extensions.logstats] INFO: Crawled 1538 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:49:22 [scrapy.extensions.logstats] INFO: Crawled 1540 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:50:06 [scrapy.extensions.logstats] INFO: Crawled 1545 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:51:09 [scrapy.extensions.logstats] INFO: Crawled 1545 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:52:38 [scrapy.extensions.logstats] INFO: Crawled 1545 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:53:09 [scrapy.extensions.logstats] INFO: Crawled 1551 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:54:12 [scrapy.extensions.logstats] INFO: Crawled 1556 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:55:43 [scrapy.extensions.logstats] INFO: Crawled 1556 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:57:46 [scrapy.extensions.logstats] INFO: Crawled 1556 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:00:52 [scrapy.extensions.logstats] INFO: Crawled 1568 pages (at 12 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:03:55 [scrapy.extensions.logstats] INFO: Crawled 1568 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:05:00 [scrapy.extensions.logstats] INFO: Crawled 1577 pages (at 9 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:06:29 [scrapy.extensions.logstats] INFO: Crawled 1577 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:08:32 [scrapy.extensions.logstats] INFO: Crawled 1577 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:09:06 [scrapy.extensions.logstats] INFO: Crawled 1582 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:11:04 [scrapy.extensions.logstats] INFO: Crawled 1587 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:13:34 [scrapy.extensions.logstats] INFO: Crawled 1591 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:14:58 [scrapy.extensions.logstats] INFO: Crawled 1595 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:16:25 [scrapy.extensions.logstats] INFO: Crawled 1603 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:17:48 [scrapy.extensions.logstats] INFO: Crawled 1607 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:19:13 [scrapy.extensions.logstats] INFO: Crawled 1611 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:21:13 [scrapy.extensions.logstats] INFO: Crawled 1615 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:23:24 [scrapy.extensions.logstats] INFO: Crawled 1615 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:25:26 [scrapy.extensions.logstats] INFO: Crawled 1615 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:25:59 [scrapy.extensions.logstats] INFO: Crawled 1620 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:28:02 [scrapy.extensions.logstats] INFO: Crawled 1628 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:30:04 [scrapy.extensions.logstats] INFO: Crawled 1628 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:32:19 [scrapy.extensions.logstats] INFO: Crawled 1628 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:32:52 [scrapy.extensions.logstats] INFO: Crawled 1634 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:35:32 [scrapy.extensions.logstats] INFO: Crawled 1638 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:37:08 [scrapy.extensions.logstats] INFO: Crawled 1642 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:39:13 [scrapy.extensions.logstats] INFO: Crawled 1646 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:41:19 [scrapy.extensions.logstats] INFO: Crawled 1650 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:43:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zerochroma.com/warranty>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zerochroma.com/warranty took longer than 15.0 seconds..
2019-11-10 05:43:25 [scrapy.extensions.logstats] INFO: Crawled 1654 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:45:29 [scrapy.extensions.logstats] INFO: Crawled 1658 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:47:08 [scrapy.extensions.logstats] INFO: Crawled 1662 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:49:07 [scrapy.extensions.logstats] INFO: Crawled 1666 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:50:42 [scrapy.extensions.logstats] INFO: Crawled 1670 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:52:21 [scrapy.extensions.logstats] INFO: Crawled 1674 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:54:16 [scrapy.extensions.logstats] INFO: Crawled 1678 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:55:17 [scrapy.extensions.logstats] INFO: Crawled 1682 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:56:16 [scrapy.extensions.logstats] INFO: Crawled 1682 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:57:50 [scrapy.extensions.logstats] INFO: Crawled 1682 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:59:14 [scrapy.extensions.logstats] INFO: Crawled 1691 pages (at 9 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:01:32 [scrapy.extensions.logstats] INFO: Crawled 1695 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:03:42 [scrapy.extensions.logstats] INFO: Crawled 1695 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:04:11 [scrapy.extensions.logstats] INFO: Crawled 1702 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:07:20 [scrapy.extensions.logstats] INFO: Crawled 1706 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:08:50 [scrapy.extensions.logstats] INFO: Crawled 1710 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:10:52 [scrapy.extensions.logstats] INFO: Crawled 1713 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:10:52 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.zerowater.com>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.zerowater.com took longer than 15.0 seconds..
2019-11-10 06:12:01 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://zivix.net/robots.txt>: User timeout caused connection failure: Getting http://zivix.co took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://zivix.co took longer than 15.0 seconds..
2019-11-10 06:12:01 [scrapy.extensions.logstats] INFO: Crawled 1716 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:13:11 [scrapy.extensions.logstats] INFO: Crawled 1718 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:13:50 [scrapy.core.scraper] ERROR: Error downloading <GET http://zivix.net/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://zivix.net/ took longer than 15.0 seconds..
2019-11-10 06:13:50 [scrapy.extensions.logstats] INFO: Crawled 1721 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:14:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.eyepromise.com/resources/overview-2/nutrients/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.eyepromise.com/resources/overview-2/nutrients/ took longer than 15.0 seconds..
2019-11-10 06:14:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://sds.zepinc.com>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://sds.zepinc.com took longer than 15.0 seconds..
2019-11-10 06:14:56 [scrapy.extensions.logstats] INFO: Crawled 1727 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:16:00 [scrapy.extensions.logstats] INFO: Crawled 1730 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:17:26 [scrapy.extensions.logstats] INFO: Crawled 1733 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:18:34 [scrapy.core.scraper] ERROR: Error downloading <GET http://zagtoys.com/news/>: User timeout caused connection failure.
2019-11-10 06:18:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.eyepromise.com/return-policy/>: User timeout caused connection failure.
2019-11-10 06:18:34 [scrapy.extensions.logstats] INFO: Crawled 1736 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:19:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.eyepromise.com/eyepromise-faq/>: User timeout caused connection failure.
2019-11-10 06:19:49 [scrapy.extensions.logstats] INFO: Crawled 1736 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:21:25 [scrapy.core.scraper] ERROR: Error downloading <GET http://zagtoys.com/?s=marvel>: User timeout caused connection failure.
2019-11-10 06:21:25 [scrapy.extensions.logstats] INFO: Crawled 1736 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:21:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.eyepromise.com/my-account/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.eyepromise.com/my-account/ took longer than 15.0 seconds..
2019-11-10 06:21:25 [scrapy.core.scraper] ERROR: Error downloading <GET http://zagtoys.com/rockerz/>: User timeout caused connection failure.
2019-11-10 06:21:55 [scrapy.extensions.logstats] INFO: Crawled 1740 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:23:30 [scrapy.core.scraper] ERROR: Error downloading <GET http://zagtoys.com/?s=nickelodeon>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://zagtoys.com/?s=nickelodeon took longer than 15.0 seconds..
2019-11-10 06:23:30 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.eyepromise.com>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.eyepromise.com took longer than 15.0 seconds..
2019-11-10 06:23:30 [scrapy.extensions.logstats] INFO: Crawled 1744 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:25:30 [scrapy.core.scraper] ERROR: Error downloading <GET http://zagtoys.com/domez/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://zagtoys.com/domez/ took longer than 15.0 seconds..
2019-11-10 06:25:30 [scrapy.extensions.logstats] INFO: Crawled 1744 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:25:30 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.eyepromise.com/doctors/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.eyepromise.com/doctors/ took longer than 15.0 seconds..
2019-11-10 06:25:30 [scrapy.core.scraper] ERROR: Error downloading <GET http://zagtoys.com/hello-neighbor/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://zagtoys.com/hello-neighbor/ took longer than 15.0 seconds..
2019-11-10 06:26:03 [scrapy.extensions.logstats] INFO: Crawled 1748 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:27:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.youngliving.com/en_ZA>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.youngliving.com/en_ZA took longer than 15.0 seconds..
2019-11-10 06:27:34 [scrapy.extensions.logstats] INFO: Crawled 1753 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:30:06 [scrapy.core.scraper] ERROR: Error downloading <GET http://zagtoys.com/psyonix-and-zag-toys-announce-partnership-to-debut-rocket-league-toy-line/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://zagtoys.com/psyonix-and-zag-toys-announce-partnership-to-debut-rocket-league-toy-line/ took longer than 15.0 seconds..
2019-11-10 06:30:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.eyepromise.com/product-category/eyepromise-screen-shield-pro/>: User timeout caused connection failure.
2019-11-10 06:30:07 [scrapy.extensions.logstats] INFO: Crawled 1754 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:30:07 [scrapy.core.scraper] ERROR: Error downloading <GET http://zagtoys.com/viz-media-announces-new-officially-licensed-product-partners-for-naruto/>: User timeout caused connection failure.
2019-11-10 06:30:42 [scrapy.core.scraper] ERROR: Error downloading <GET http://zagtoys.com/digimon-domez-flying-off-shelves-hit/>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2019-11-10 06:31:15 [scrapy.extensions.logstats] INFO: Crawled 1756 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:31:50 [scrapy.extensions.logstats] INFO: Crawled 1757 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:32:53 [scrapy.extensions.logstats] INFO: Crawled 1759 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:33:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.eyepromise.com/cart/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.eyepromise.com/cart/ took longer than 15.0 seconds..
2019-11-10 06:33:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.eyepromise.com/connect/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.eyepromise.com/connect/ took longer than 15.0 seconds..
2019-11-10 06:33:59 [scrapy.extensions.logstats] INFO: Crawled 1761 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:33:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.eyepromise.com/about-us/careers/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.eyepromise.com/about-us/careers/ took longer than 15.0 seconds..
2019-11-10 06:34:30 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.eyepromise.com/about-us/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.eyepromise.com/about-us/ took longer than 15.0 seconds..
2019-11-10 06:35:02 [scrapy.core.scraper] ERROR: Error downloading <GET http://store.zephyronline.com/en/home>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://store.zephyronline.com/en/home took longer than 15.0 seconds..
2019-11-10 06:35:02 [scrapy.extensions.logstats] INFO: Crawled 1763 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:35:37 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.eyepromise.com/category/blog/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.eyepromise.com/category/blog/ took longer than 15.0 seconds..
2019-11-10 06:35:37 [scrapy.core.scraper] ERROR: Error downloading <GET http://zagtoys.com/success-digimon-domez-leads-digimon-plush-line-may-2017/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://zagtoys.com/success-digimon-domez-leads-digimon-plush-line-may-2017/ took longer than 15.0 seconds..
2019-11-10 06:35:37 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.eyepromise.com/resources/nsf/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.eyepromise.com/resources/nsf/ took longer than 15.0 seconds..
2019-11-10 06:36:13 [scrapy.extensions.logstats] INFO: Crawled 1764 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:36:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.eyepromise.com/resources/vizual-edge-pro-overview/the-edge/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.eyepromise.com/resources/vizual-edge-pro-overview/the-edge/ took longer than 15.0 seconds..
2019-11-10 06:36:13 [scrapy.core.scraper] ERROR: Error downloading <GET http://zoskinhealth.com/blog/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://zoskinhealth.com/blog/ took longer than 15.0 seconds..
2019-11-10 06:39:48 [scrapy.extensions.logstats] INFO: Crawled 1776 pages (at 12 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:39:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.youniqueproducts.com/business/backorders>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.youniqueproducts.com/business/backorders took longer than 15.0 seconds..
2019-11-10 06:42:17 [scrapy.extensions.logstats] INFO: Crawled 1780 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:42:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zak.com/tabletop-shallow-plastic-bowls>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 06:42:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.eyepromise.com/resources/overview/contrast-sensitivity/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.eyepromise.com/resources/overview/contrast-sensitivity/ took longer than 15.0 seconds..
2019-11-10 06:44:21 [scrapy.extensions.logstats] INFO: Crawled 1784 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:44:52 [scrapy.extensions.logstats] INFO: Crawled 1786 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:46:30 [scrapy.core.scraper] ERROR: Error downloading <GET http://investors.zagg.com/News>: User timeout caused connection failure.
2019-11-10 06:46:30 [scrapy.extensions.logstats] INFO: Crawled 1786 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:47:31 [scrapy.extensions.logstats] INFO: Crawled 1786 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:48:07 [scrapy.extensions.logstats] INFO: Crawled 1792 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:50:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://zagtoys.com/zag-toys-goes-overseas-along-marvel-dc-superhero-domez/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://zagtoys.com/zag-toys-goes-overseas-along-marvel-dc-superhero-domez/ took longer than 15.0 seconds..
2019-11-10 06:50:20 [scrapy.extensions.logstats] INFO: Crawled 1797 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:52:58 [scrapy.core.scraper] ERROR: Error downloading <GET http://zagtoys.com/zag-toys-psyonix-announce-new-rocket-league-toys/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://zagtoys.com/zag-toys-psyonix-announce-new-rocket-league-toys/ took longer than 15.0 seconds..
2019-11-10 06:52:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.eyepromise.com/resources/night-driving-overview/night-driving-vision-solutions/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.eyepromise.com/resources/night-driving-overview/night-driving-vision-solutions/ took longer than 15.0 seconds..
2019-11-10 06:52:59 [scrapy.extensions.logstats] INFO: Crawled 1797 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:52:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.eyepromise.com/resources/retinal-health-overview/retinal-health-mpod/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.eyepromise.com/resources/retinal-health-overview/retinal-health-mpod/ took longer than 15.0 seconds..
2019-11-10 06:52:59 [scrapy.core.scraper] ERROR: Error downloading <GET http://zagtoys.com/?s=toei>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://zagtoys.com/?s=toei took longer than 15.0 seconds..
2019-11-10 06:55:41 [scrapy.core.scraper] ERROR: Error downloading <GET http://zagtoys.com/?s=ubisoft>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://zagtoys.com/?s=ubisoft took longer than 15.0 seconds..
2019-11-10 06:55:41 [scrapy.extensions.logstats] INFO: Crawled 1814 pages (at 17 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:58:53 [scrapy.extensions.logstats] INFO: Crawled 1814 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:01:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.eyepromise.com/resources/importance-of-eye-health/early-warning-signs/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.eyepromise.com/resources/importance-of-eye-health/early-warning-signs/ took longer than 15.0 seconds..
2019-11-10 07:01:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zak.com/kitchen_tools_face_spoons>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zak.com/kitchen_tools_face_spoons took longer than 15.0 seconds..
2019-11-10 07:01:28 [scrapy.extensions.logstats] INFO: Crawled 1814 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:01:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zak.com/kitchen_dining_drinkware_tumblers_cups>: User timeout caused connection failure.
2019-11-10 07:02:00 [scrapy.extensions.logstats] INFO: Crawled 1819 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:04:06 [scrapy.extensions.logstats] INFO: Crawled 1823 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:06:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://zephyronline.com/about/in-the-news/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://zephyronline.com/about/in-the-news/ took longer than 15.0 seconds..
2019-11-10 07:06:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zak.com/kitchen_dining_foodprep>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zak.com/kitchen_dining_foodprep took longer than 15.0 seconds..
2019-11-10 07:06:11 [scrapy.extensions.logstats] INFO: Crawled 1823 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:06:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://zephyronline.com/about/awards/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://zephyronline.com/about/awards/ took longer than 15.0 seconds..
2019-11-10 07:06:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zak.com/5-picnic-food-ideas-from-around-the-world>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zak.com/5-picnic-food-ideas-from-around-the-world took longer than 15.0 seconds..
2019-11-10 07:07:13 [scrapy.extensions.logstats] INFO: Crawled 1831 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:08:46 [scrapy.extensions.logstats] INFO: Crawled 1831 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:10:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zak.com/characters-dc-comics>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zak.com/characters-dc-comics took longer than 15.0 seconds..
2019-11-10 07:10:26 [scrapy.extensions.logstats] INFO: Crawled 1831 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:10:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://zephyronline.com/privacy-policy>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://zephyronline.com/privacy-policy took longer than 15.0 seconds..
2019-11-10 07:10:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zak.com/character-collections-ryans-world>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zak.com/character-collections-ryans-world took longer than 15.0 seconds..
2019-11-10 07:10:49 [scrapy.extensions.logstats] INFO: Crawled 1836 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:12:51 [scrapy.extensions.logstats] INFO: Crawled 1844 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:15:05 [scrapy.extensions.logstats] INFO: Crawled 1847 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:17:07 [scrapy.extensions.logstats] INFO: Crawled 1847 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:18:34 [scrapy.extensions.logstats] INFO: Crawled 1847 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:19:05 [scrapy.extensions.logstats] INFO: Crawled 1850 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:20:07 [scrapy.extensions.logstats] INFO: Crawled 1854 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:22:01 [scrapy.extensions.logstats] INFO: Crawled 1858 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:24:03 [scrapy.extensions.logstats] INFO: Crawled 1862 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:26:08 [scrapy.extensions.logstats] INFO: Crawled 1867 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:28:53 [scrapy.extensions.logstats] INFO: Crawled 1871 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:31:02 [scrapy.extensions.logstats] INFO: Crawled 1874 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:32:41 [scrapy.extensions.logstats] INFO: Crawled 1874 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:33:12 [scrapy.extensions.logstats] INFO: Crawled 1878 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:34:46 [scrapy.extensions.logstats] INFO: Crawled 1882 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:34:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://zoskinhealth.com/products/anti-aging/wrinkle-texture-repair>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://zoskinhealth.com/products/anti-aging/wrinkle-texture-repair took longer than 15.0 seconds..
2019-11-10 07:36:53 [scrapy.extensions.logstats] INFO: Crawled 1886 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:39:08 [scrapy.extensions.logstats] INFO: Crawled 1890 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:41:16 [scrapy.extensions.logstats] INFO: Crawled 1894 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:43:30 [scrapy.extensions.logstats] INFO: Crawled 1897 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:44:36 [scrapy.extensions.logstats] INFO: Crawled 1900 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:44:58 [scrapy.extensions.logstats] INFO: Crawled 1903 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:45:47 [scrapy.extensions.logstats] INFO: Crawled 1906 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:47:27 [scrapy.extensions.logstats] INFO: Crawled 1910 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:48:57 [scrapy.extensions.logstats] INFO: Crawled 1910 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:51:06 [scrapy.extensions.logstats] INFO: Crawled 1910 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:51:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.youngliving.com/maintenance/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.youngliving.com/maintenance/ took longer than 15.0 seconds..
2019-11-10 07:51:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.eyepromise.com/resources/importance-of-eye-health/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.eyepromise.com/resources/importance-of-eye-health/ took longer than 15.0 seconds..
2019-11-10 07:52:33 [scrapy.extensions.logstats] INFO: Crawled 1916 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:54:08 [scrapy.extensions.logstats] INFO: Crawled 1919 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:55:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zak.com/replacement_center>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zak.com/replacement_center took longer than 15.0 seconds..
2019-11-10 07:55:49 [scrapy.extensions.logstats] INFO: Crawled 1923 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:57:54 [scrapy.extensions.logstats] INFO: Crawled 1927 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:00:11 [scrapy.extensions.logstats] INFO: Crawled 1929 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:01:07 [scrapy.extensions.logstats] INFO: Crawled 1933 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:02:34 [scrapy.extensions.logstats] INFO: Crawled 1937 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:04:02 [scrapy.extensions.logstats] INFO: Crawled 1939 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:04:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zak.com/about_us>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zak.com/about_us took longer than 15.0 seconds..
2019-11-10 08:04:45 [scrapy.extensions.logstats] INFO: Crawled 1941 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:05:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.eyepromise.com/resources/zeaxanthin/dietary-zeaxanthin-vs-meso-zeaxanthin/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.eyepromise.com/resources/zeaxanthin/dietary-zeaxanthin-vs-meso-zeaxanthin/ took longer than 15.0 seconds..
2019-11-10 08:05:53 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.eyepromise.com/resources/zeaxanthin/video/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.eyepromise.com/resources/zeaxanthin/video/ took longer than 15.0 seconds..
2019-11-10 08:05:53 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zak.com/articles-care-and-use-symbol-decoder>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zak.com/articles-care-and-use-symbol-decoder took longer than 15.0 seconds..
2019-11-10 08:05:53 [scrapy.extensions.logstats] INFO: Crawled 1947 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:06:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.eyepromise.com/how-it-works/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.eyepromise.com/how-it-works/ took longer than 15.0 seconds..
2019-11-10 08:06:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zak.com/articles-how-to-make-juice-in-four-different-ways>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zak.com/articles-how-to-make-juice-in-four-different-ways took longer than 15.0 seconds..
2019-11-10 08:08:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zak.com/Sweet-Tips-for-Different-Types-of-Candy_c_6143.html>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zak.com/Sweet-Tips-for-Different-Types-of-Candy_c_6143.html took longer than 15.0 seconds..
2019-11-10 08:08:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.eyepromise.com/product/eyepromise-zeaxanthin/>: User timeout caused connection failure.
2019-11-10 08:08:06 [scrapy.extensions.logstats] INFO: Crawled 1947 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:09:08 [scrapy.extensions.logstats] INFO: Crawled 1957 pages (at 10 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:10:51 [scrapy.extensions.logstats] INFO: Crawled 1957 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:12:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zak.com/articles-the-best-method-of-making-coffee>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zak.com/articles-the-best-method-of-making-coffee took longer than 15.0 seconds..
2019-11-10 08:12:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.eyepromise.com/product/eyepromise-screen-shield-pro/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.eyepromise.com/product/eyepromise-screen-shield-pro/ took longer than 15.0 seconds..
2019-11-10 08:12:57 [scrapy.extensions.logstats] INFO: Crawled 1957 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:15:13 [scrapy.extensions.logstats] INFO: Crawled 1966 pages (at 9 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:17:23 [scrapy.extensions.logstats] INFO: Crawled 1971 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:19:54 [scrapy.extensions.logstats] INFO: Crawled 1971 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:19:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zak.com/kitchen_dining_dinnerware_pasta_bowls>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 08:19:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.eyepromise.com/product/eyepromise-vizual-edge-chewable-2/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.eyepromise.com/product/eyepromise-vizual-edge-chewable-2/ took longer than 15.0 seconds..
2019-11-10 08:22:51 [scrapy.extensions.logstats] INFO: Crawled 1984 pages (at 13 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:22:51 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zak.com/enter-page-name_ep_80.html>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zak.com/enter-page-name_ep_80.html took longer than 15.0 seconds..
2019-11-10 08:26:01 [scrapy.extensions.logstats] INFO: Crawled 1989 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:27:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zak.com/genesis>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 08:27:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.eyepromise.com/product/areds-2-plus-zinc-free-2/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.eyepromise.com/product/areds-2-plus-zinc-free-2/ took longer than 15.0 seconds..
2019-11-10 08:27:09 [scrapy.extensions.logstats] INFO: Crawled 1994 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:28:44 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zak.com/walgreens_selector>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zak.com/walgreens_selector took longer than 15.0 seconds..
2019-11-10 08:28:44 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.eyepromise.com/product/eyepromise-restore-2/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.eyepromise.com/product/eyepromise-restore-2/ took longer than 15.0 seconds..
2019-11-10 08:28:44 [scrapy.extensions.logstats] INFO: Crawled 1994 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:30:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zak.com/retailer_signup>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zak.com/retailer_signup took longer than 15.0 seconds..
2019-11-10 08:30:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.eyepromise.com/my-account?action=register>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.eyepromise.com/my-account?action=register took longer than 15.0 seconds..
2019-11-10 08:30:58 [scrapy.extensions.logstats] INFO: Crawled 1994 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:30:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zak.com/meet_irv_zakheim>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zak.com/meet_irv_zakheim took longer than 15.0 seconds..
2019-11-10 08:30:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.yorktownecabinetry.com/historic/>: User timeout caused connection failure.
2019-11-10 08:32:01 [scrapy.extensions.logstats] INFO: Crawled 2005 pages (at 11 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:33:38 [scrapy.extensions.logstats] INFO: Crawled 2005 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:36:43 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zak.com/stainless-steel-travel-mugs>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zak.com/stainless-steel-travel-mugs took longer than 15.0 seconds..
2019-11-10 08:36:43 [scrapy.extensions.logstats] INFO: Crawled 2005 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:36:43 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.yorktownecabinetry.com/america-strong/material-characteristics/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.yorktownecabinetry.com/america-strong/material-characteristics/ took longer than 15.0 seconds..
2019-11-10 08:36:43 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zak.com/planet-zak-clarion-tumbler>: User timeout caused connection failure.
2019-11-10 08:36:43 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zagg.com/en_us/shop-by-device/google-pixel-2>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zagg.com/en_us/shop-by-device/google-pixel-2 took longer than 15.0 seconds..
2019-11-10 08:37:15 [scrapy.extensions.logstats] INFO: Crawled 2009 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:38:53 [scrapy.extensions.logstats] INFO: Crawled 2015 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:42:10 [scrapy.extensions.logstats] INFO: Crawled 2019 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:42:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zak.com/articles-setting-the-table>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zak.com/articles-setting-the-table took longer than 15.0 seconds..
2019-11-10 08:44:01 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zak.com/articles-staying-hydrated>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zak.com/articles-staying-hydrated took longer than 15.0 seconds..
2019-11-10 08:44:01 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zagg.com/en_us/store-finder/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zagg.com/en_us/store-finder/ took longer than 15.0 seconds..
2019-11-10 08:44:01 [scrapy.extensions.logstats] INFO: Crawled 2022 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:45:08 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zak.com/disney-frozen-2-movie-plastic-cups_FRZA-U090>: User timeout caused connection failure.
2019-11-10 08:45:08 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zagg.com/en_us/screen-protection>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zagg.com/en_us/screen-protection took longer than 15.0 seconds..
2019-11-10 08:45:08 [scrapy.extensions.logstats] INFO: Crawled 2022 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:45:08 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zagg.com/en_us/cases>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zagg.com/en_us/cases took longer than 15.0 seconds..
2019-11-10 08:47:53 [scrapy.extensions.logstats] INFO: Crawled 2031 pages (at 9 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:49:35 [scrapy.extensions.logstats] INFO: Crawled 2034 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:50:40 [scrapy.extensions.logstats] INFO: Crawled 2040 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:51:02 [scrapy.extensions.logstats] INFO: Crawled 2046 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:53:20 [scrapy.extensions.logstats] INFO: Crawled 2046 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:56:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.youniqueproducts.com/business/party>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.youniqueproducts.com/business/party took longer than 15.0 seconds..
2019-11-10 08:56:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zeromotorcycles.com/zero-srf/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zeromotorcycles.com/zero-srf/ took longer than 15.0 seconds..
2019-11-10 08:56:31 [scrapy.extensions.logstats] INFO: Crawled 2046 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:56:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.youniqueproducts.com/business/presenterinfo>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.youniqueproducts.com/business/presenterinfo took longer than 15.0 seconds..
2019-11-10 08:56:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zeromotorcycles.com/technology/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zeromotorcycles.com/technology/ took longer than 15.0 seconds..
2019-11-10 08:56:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.yorktownecabinetry.com/stylish-storage/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.yorktownecabinetry.com/stylish-storage/ took longer than 15.0 seconds..
2019-11-10 08:57:06 [scrapy.extensions.logstats] INFO: Crawled 2052 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:59:48 [scrapy.extensions.logstats] INFO: Crawled 2058 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:03:07 [scrapy.extensions.logstats] INFO: Crawled 2064 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:06:24 [scrapy.extensions.logstats] INFO: Crawled 2064 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:06:58 [scrapy.extensions.logstats] INFO: Crawled 2067 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:08:09 [scrapy.extensions.logstats] INFO: Crawled 2070 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:09:46 [scrapy.extensions.logstats] INFO: Crawled 2073 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:11:18 [scrapy.extensions.logstats] INFO: Crawled 2076 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:11:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zagg.com/en_us/halo/>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 09:11:50 [scrapy.extensions.logstats] INFO: Crawled 2079 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:12:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zagg.com/en_us/invisibleshield/>: User timeout caused connection failure.
2019-11-10 09:12:54 [scrapy.extensions.logstats] INFO: Crawled 2079 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:14:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zagg.com/en_us/brv-x2>: User timeout caused connection failure.
2019-11-10 09:14:29 [scrapy.extensions.logstats] INFO: Crawled 2079 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:14:30 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zagg.com/en_us/glass-elite-visionguard-plus-iphone-11-pro-max>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zagg.com/en_us/glass-elite-visionguard-plus-iphone-11-pro-max took longer than 15.0 seconds..
2019-11-10 09:14:54 [scrapy.extensions.logstats] INFO: Crawled 2085 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:17:45 [scrapy.extensions.logstats] INFO: Crawled 2091 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:20:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zagg.com/en_us/speakers/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zagg.com/en_us/speakers/ took longer than 15.0 seconds..
2019-11-10 09:20:14 [scrapy.extensions.logstats] INFO: Crawled 2091 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:20:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zagg.com/en_us/shop-by-device/iphone-11-pro?brand=481>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zagg.com/en_us/shop-by-device/iphone-11-pro?brand=481 took longer than 15.0 seconds..
2019-11-10 09:21:38 [scrapy.extensions.logstats] INFO: Crawled 2101 pages (at 10 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:22:23 [scrapy.extensions.logstats] INFO: Crawled 2101 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:25:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zagg.com/en_us/shop-by-device/galaxy-s7>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zagg.com/en_us/shop-by-device/galaxy-s7 took longer than 15.0 seconds..
2019-11-10 09:25:05 [scrapy.extensions.logstats] INFO: Crawled 2101 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:25:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zagg.com/en_us/mophie/custom-branding>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zagg.com/en_us/mophie/custom-branding took longer than 15.0 seconds..
2019-11-10 09:28:21 [scrapy.extensions.logstats] INFO: Crawled 2113 pages (at 12 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:30:59 [scrapy.extensions.logstats] INFO: Crawled 2119 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:33:42 [scrapy.extensions.logstats] INFO: Crawled 2123 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:35:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zagg.com/en_us/shop-by-device/iphone-11/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zagg.com/en_us/shop-by-device/iphone-11/ took longer than 15.0 seconds..
2019-11-10 09:35:50 [scrapy.extensions.logstats] INFO: Crawled 2123 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:35:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://redesign-omega-en-my.cms.youngliving.com/en_MY/discover/seed-to-seal>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: redesign-omega-en-my.cms.youngliving.com.
2019-11-10 09:35:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.youngliving.com/es_ES>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.youngliving.com/es_ES took longer than 15.0 seconds..
2019-11-10 09:35:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zagg.com/en_us/other-accessories>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zagg.com/en_us/other-accessories took longer than 15.0 seconds..
2019-11-10 09:35:51 [scrapy.core.scraper] ERROR: Error downloading <GET https://vo-zh-tw.cms.youngliving.com/vo/Membernews/index?nicmd=sp&version=wver.gZZDfTRs20F6mTMq1k4&rnd=405217783.922579>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: vo-zh-tw.cms.youngliving.com.
2019-11-10 09:36:57 [scrapy.extensions.logstats] INFO: Crawled 2135 pages (at 12 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:39:01 [scrapy.extensions.logstats] INFO: Crawled 2135 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:41:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zagg.com/en_us/universal-batteries>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zagg.com/en_us/universal-batteries took longer than 15.0 seconds..
2019-11-10 09:41:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.yorktownecabinetry.com/products/decorative-inserts/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.yorktownecabinetry.com/products/decorative-inserts/ took longer than 15.0 seconds..
2019-11-10 09:41:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.youngliving.com/fr_FR>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.youngliving.com/fr_FR took longer than 15.0 seconds..
2019-11-10 09:41:17 [scrapy.extensions.logstats] INFO: Crawled 2135 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:41:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zagg.com/en_us/shop-by-device/apple-watch-series-2>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zagg.com/en_us/shop-by-device/apple-watch-series-2 took longer than 15.0 seconds..
2019-11-10 09:41:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.yorktownecabinetry.com/products/hoods/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.yorktownecabinetry.com/products/hoods/ took longer than 15.0 seconds..
2019-11-10 09:41:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.youngliving.com/es_CO>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.youngliving.com/es_CO took longer than 15.0 seconds..
2019-11-10 09:43:08 [scrapy.extensions.logstats] INFO: Crawled 2146 pages (at 11 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:44:16 [scrapy.extensions.logstats] INFO: Crawled 2146 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:45:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.youngliving.com/en_CA>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.youngliving.com/en_CA took longer than 15.0 seconds..
2019-11-10 09:45:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zagg.com/en_us/zagg>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zagg.com/en_us/zagg took longer than 15.0 seconds..
2019-11-10 09:45:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zeromotorcycles.com/ca/charging>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zeromotorcycles.com/ca/charging took longer than 15.0 seconds..
2019-11-10 09:45:48 [scrapy.extensions.logstats] INFO: Crawled 2146 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:45:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.youngliving.com/ja_JP/products/c/-%e5%ae%b6%e5%ba%ad%e3%81%a7%e4%bd%bf%e3%81%88%e3%82%8b%e8%a3%bd%e5%93%81>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.youngliving.com/ja_JP/products/c/-%e5%ae%b6%e5%ba%ad%e3%81%a7%e4%bd%bf%e3%81%88%e3%82%8b%e8%a3%bd%e5%93%81 took longer than 15.0 seconds..
2019-11-10 09:45:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zagg.com/en_us/shop-by-device/apple-watch-series-3>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zagg.com/en_us/shop-by-device/apple-watch-series-3 took longer than 15.0 seconds..
2019-11-10 09:45:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zeromotorcycles.com/ca/advantages>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zeromotorcycles.com/ca/advantages took longer than 15.0 seconds..
2019-11-10 09:48:18 [scrapy.extensions.logstats] INFO: Crawled 2158 pages (at 12 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:49:27 [scrapy.extensions.logstats] INFO: Crawled 2158 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:52:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://zoskinhealth.com/products/anti-aging/wrinkle-texture-repair>: User timeout caused connection failure.
2019-11-10 09:52:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zeromotorcycles.com/press-releases/oct-23-2018-2019-model-line>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zeromotorcycles.com/press-releases/oct-23-2018-2019-model-line took longer than 15.0 seconds..
2019-11-10 09:52:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zagg.com/en_us/shop-by-device/iphone-xs-max>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zagg.com/en_us/shop-by-device/iphone-xs-max took longer than 15.0 seconds..
2019-11-10 09:52:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.youngliving.com/ja_JP/company/management-team/executive-management-team>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.youngliving.com/ja_JP/company/management-team/executive-management-team took longer than 15.0 seconds..
2019-11-10 09:52:02 [scrapy.extensions.logstats] INFO: Crawled 2158 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:52:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zagg.com/en_us/shop-by-device/iphone-5?color=Group%3A+White>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zagg.com/en_us/shop-by-device/iphone-5?color=Group%3A+White took longer than 15.0 seconds..
2019-11-10 09:52:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.youngliving.com/ja_JP/company/about/mission-statement>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.youngliving.com/ja_JP/company/about/mission-statement took longer than 15.0 seconds..
2019-11-10 09:52:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://zoskinhealth.com/growth-factor-serum>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://zoskinhealth.com/growth-factor-serum took longer than 15.0 seconds..
2019-11-10 09:52:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://zephyronline.com/products/wine-beverage-coolers/beverage-cooler/?filter_install-type=built-in>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://zephyronline.com/products/wine-beverage-coolers/beverage-cooler/?filter_install-type=built-in took longer than 15.0 seconds..
2019-11-10 09:55:56 [scrapy.extensions.logstats] INFO: Crawled 2171 pages (at 13 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:58:35 [scrapy.core.scraper] ERROR: Error downloading <GET http://investors.zagg.com/Sustainability/Index?KeyGenPage=330894>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://investors.zagg.com/Sustainability/Index?KeyGenPage=330894 took longer than 15.0 seconds..
2019-11-10 09:58:35 [scrapy.core.scraper] ERROR: Error downloading <GET http://zagtoys.com/original-minis-collection/?term=marvel>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://zagtoys.com/original-minis-collection/?term=marvel took longer than 15.0 seconds..
2019-11-10 09:58:35 [scrapy.extensions.logstats] INFO: Crawled 2178 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:58:57 [scrapy.core.scraper] ERROR: Error downloading <GET http://zagtoys.com/original-minis-collection/?term=dc-comics>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2019-11-10 09:58:57 [scrapy.core.scraper] ERROR: Error downloading <GET http://investors.zagg.com/govdocs>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://investors.zagg.com/govdocs took longer than 15.0 seconds..
2019-11-10 09:58:57 [scrapy.extensions.logstats] INFO: Crawled 2185 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:01:46 [scrapy.core.scraper] ERROR: Error downloading <GET http://zagtoys.com/original-minis-collection/?term=nickelodeon>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://zagtoys.com/original-minis-collection/?term=nickelodeon took longer than 15.0 seconds..
2019-11-10 10:01:46 [scrapy.core.scraper] ERROR: Error downloading <GET http://investors.zagg.com/CustomPage/Index?KeyGenPage=1073750472>: User timeout caused connection failure.
2019-11-10 10:01:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zak.com/hydratrak-periwinkle-with-rainbow-bands-tumblers_1503-R108>: User timeout caused connection failure.
2019-11-10 10:01:46 [scrapy.extensions.logstats] INFO: Crawled 2185 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:05:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zagg.com/en_us/powerstation-plus-2016>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zagg.com/en_us/powerstation-plus-2016 took longer than 15.0 seconds..
2019-11-10 10:05:24 [scrapy.core.scraper] ERROR: Error downloading <GET http://investors.zagg.com/Stock>: User timeout caused connection failure.
2019-11-10 10:05:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.yorktownecabinetry.com/product/base-with-pull-out-waste-container/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.yorktownecabinetry.com/product/base-with-pull-out-waste-container/ took longer than 15.0 seconds..
2019-11-10 10:05:24 [scrapy.core.scraper] ERROR: Error downloading <GET http://zagtoys.com/rocket-league-mini-pull-back-racers/?term=cartoon-network>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://zagtoys.com/rocket-league-mini-pull-back-racers/?term=cartoon-network took longer than 15.0 seconds..
2019-11-10 10:05:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.youngliving.com/ja_JP/opportunity/90days>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.youngliving.com/ja_JP/opportunity/90days took longer than 15.0 seconds..
2019-11-10 10:05:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zak.com/hydratrak_replacement_straw_2186-R480>: User timeout caused connection failure.
2019-11-10 10:05:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://store.zephyronline.com/en/terms-conditions>: User timeout caused connection failure.
2019-11-10 10:05:24 [scrapy.extensions.logstats] INFO: Crawled 2186 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:05:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.yorktownecabinetry.com/product/pull-out-waste-container-2/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.yorktownecabinetry.com/product/pull-out-waste-container-2/ took longer than 15.0 seconds..
2019-11-10 10:05:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.youngliving.com/ja_JP/company/about/Parterships>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.youngliving.com/ja_JP/company/about/Parterships took longer than 15.0 seconds..
2019-11-10 10:05:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zagg.com/en_us/powerstation-plus-mini>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zagg.com/en_us/powerstation-plus-mini took longer than 15.0 seconds..
2019-11-10 10:05:57 [scrapy.core.scraper] ERROR: Error downloading <GET http://investors.zagg.com/QuarterlyResults>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://investors.zagg.com/QuarterlyResults took longer than 15.0 seconds..
2019-11-10 10:05:57 [scrapy.core.scraper] ERROR: Error downloading <GET http://zagtoys.com/rocket-league-mini-pull-back-racers/?term=nickelodeon>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://zagtoys.com/rocket-league-mini-pull-back-racers/?term=nickelodeon took longer than 15.0 seconds..
2019-11-10 10:05:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zak.com/hydratrak_replacement_bands_2212-R405>: User timeout caused connection failure.
2019-11-10 10:05:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://store.zephyronline.com/en/shipping-policy>: User timeout caused connection failure.
2019-11-10 10:05:57 [scrapy.extensions.logstats] INFO: Crawled 2187 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:05:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zeromotorcycles.com/eu/environment>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 10:06:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zak.com/insulated_tumbler_with_lid_2184-R101>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zak.com/insulated_tumbler_with_lid_2184-R101 took longer than 15.0 seconds..
2019-11-10 10:06:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.youngliving.com/ja_JP/company/experiencecenter>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.youngliving.com/ja_JP/company/experiencecenter took longer than 15.0 seconds..
2019-11-10 10:06:31 [scrapy.core.scraper] ERROR: Error downloading <GET http://investors.zagg.com/Presentations>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://investors.zagg.com/Presentations took longer than 15.0 seconds..
2019-11-10 10:06:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://store.zephyronline.com/en/find-your-model>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://store.zephyronline.com/en/find-your-model took longer than 15.0 seconds..
2019-11-10 10:06:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zagg.com/en_us/gear4>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zagg.com/en_us/gear4 took longer than 15.0 seconds..
2019-11-10 10:06:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.yorktownecabinetry.com/product/installed-pull-out-storage-for-sink-base-with-door-organizer-and-sink-mat/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.yorktownecabinetry.com/product/installed-pull-out-storage-for-sink-base-with-door-organizer-and-sink-mat/ took longer than 15.0 seconds..
2019-11-10 10:06:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zeromotorcycles.com/ca/fleet>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 10:06:31 [scrapy.core.scraper] ERROR: Error downloading <GET http://investors.zagg.com/event>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://investors.zagg.com/event took longer than 15.0 seconds..
2019-11-10 10:06:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zak.com/hydratrak-black-stainless-steel-tumblers_0052-S854>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zak.com/hydratrak-black-stainless-steel-tumblers_0052-S854 took longer than 15.0 seconds..
2019-11-10 10:06:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zagg.com/en_us/shop-by-device/google-pixel-3a?cat=2739>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zagg.com/en_us/shop-by-device/google-pixel-3a?cat=2739 took longer than 15.0 seconds..
2019-11-10 10:06:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://store.zephyronline.com/en/find-your-part>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://store.zephyronline.com/en/find-your-part took longer than 15.0 seconds..
2019-11-10 10:06:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.youngliving.com/en_SG/company/privacy>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.youngliving.com/en_SG/company/privacy took longer than 15.0 seconds..
2019-11-10 10:06:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.yorktownecabinetry.com/product/sink-base-with-two-door-organizers/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.yorktownecabinetry.com/product/sink-base-with-two-door-organizers/ took longer than 15.0 seconds..
2019-11-10 10:06:31 [scrapy.core.scraper] ERROR: Error downloading <GET http://zagtoys.com/2017/02/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://zagtoys.com/2017/02/ took longer than 15.0 seconds..
2019-11-10 10:07:03 [scrapy.extensions.logstats] INFO: Crawled 2194 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:07:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://investors.zagg.com/CustomPage/Index?KeyGenPage=1073751939>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2019-11-10 10:09:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://store.zephyronline.com/en/accessories/range-hoods/blowers>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://store.zephyronline.com/en/accessories/range-hoods/blowers took longer than 15.0 seconds..
2019-11-10 10:09:54 [scrapy.extensions.logstats] INFO: Crawled 2202 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:09:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://store.zephyronline.com/en/accessories>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 10:13:41 [scrapy.core.scraper] ERROR: Error downloading <GET http://investors.zagg.com/CorporateProfile>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://investors.zagg.com/CorporateProfile took longer than 15.0 seconds..
2019-11-10 10:13:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zak.com/hydratrak-black-stainless-steel-tumblers_0052-S852>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zak.com/hydratrak-black-stainless-steel-tumblers_0052-S852 took longer than 15.0 seconds..
2019-11-10 10:13:42 [scrapy.extensions.logstats] INFO: Crawled 2209 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:14:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zak.com/hydratrak_water_intake_calculator_bottle_2184-R580>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 10:14:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://store.zephyronline.com/en/parts/wine-beverage-coolers>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 10:14:13 [scrapy.extensions.logstats] INFO: Crawled 2216 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:16:44 [scrapy.core.scraper] ERROR: Error downloading <GET https://store.zephyronline.com/en/parts/range-hoods/filters>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://store.zephyronline.com/en/parts/range-hoods/filters took longer than 15.0 seconds..
2019-11-10 10:16:44 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zak.com/hydratrak_water_intake_calculator_bottle_1503-R580>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zak.com/hydratrak_water_intake_calculator_bottle_1503-R580 took longer than 15.0 seconds..
2019-11-10 10:16:44 [scrapy.extensions.logstats] INFO: Crawled 2216 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:20:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://store.zephyronline.com/en/parts>: User timeout caused connection failure.
2019-11-10 10:20:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zeromotorcycles.com/ca/newsletter/subscribe>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zeromotorcycles.com/ca/newsletter/subscribe took longer than 15.0 seconds..
2019-11-10 10:20:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.youngliving.com/ja_JP/products/c/%E3%81%9D%E3%81%AE%E4%BB%96>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.youngliving.com/ja_JP/products/c/%E3%81%9D%E3%81%AE%E4%BB%96 took longer than 15.0 seconds..
2019-11-10 10:20:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://zephyronline.com/about/designers/fu-tung-cheng/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://zephyronline.com/about/designers/fu-tung-cheng/ took longer than 15.0 seconds..
2019-11-10 10:20:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.yorktownecabinetry.com/product/walk-in-pantry/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.yorktownecabinetry.com/product/walk-in-pantry/ took longer than 15.0 seconds..
2019-11-10 10:20:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zak.com/hydratrak-black-stainless-steel-tumblers_0015-S853>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zak.com/hydratrak-black-stainless-steel-tumblers_0015-S853 took longer than 15.0 seconds..
2019-11-10 10:20:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zagg.com/en_us/dual-wireless-charging-pad>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zagg.com/en_us/dual-wireless-charging-pad took longer than 15.0 seconds..
2019-11-10 10:20:03 [scrapy.extensions.logstats] INFO: Crawled 2216 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:20:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zeromotorcycles.com/ca/privacy-policy>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zeromotorcycles.com/ca/privacy-policy took longer than 15.0 seconds..
2019-11-10 10:20:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.youngliving.com/ja_JP/products/c/%E3%82%A8%E3%83%83%E3%82%BB%E3%83%B3%E3%82%B7%E3%83%A3%E3%83%AB%E3%82%AA%E3%82%A4%E3%83%AB/%E3%82%B7%E3%83%B3%E3%82%B0%E3%83%AB%E3%82%AA%E3%82%A4%E3%83%AB>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.youngliving.com/ja_JP/products/c/%E3%82%A8%E3%83%83%E3%82%BB%E3%83%B3%E3%82%B7%E3%83%A3%E3%83%AB%E3%82%AA%E3%82%A4%E3%83%AB/%E3%82%B7%E3%83%B3%E3%82%B0%E3%83%AB%E3%82%AA%E3%82%A4%E3%83%AB took longer than 15.0 seconds..
2019-11-10 10:20:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://store.zephyronline.com/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://store.zephyronline.com/ took longer than 15.0 seconds..
2019-11-10 10:20:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zagg.com/en_us/wireless-charging-base-single-coil-apple-2019>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zagg.com/en_us/wireless-charging-base-single-coil-apple-2019 took longer than 15.0 seconds..
2019-11-10 10:20:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zak.com/hydratrak-water-intake-calculator-bottle-1503-R590>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zak.com/hydratrak-water-intake-calculator-bottle-1503-R590 took longer than 15.0 seconds..
2019-11-10 10:20:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.yorktownecabinetry.com/product/sink-base-organizer-2/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.yorktownecabinetry.com/product/sink-base-organizer-2/ took longer than 15.0 seconds..
2019-11-10 10:20:04 [scrapy.core.scraper] ERROR: Error downloading <GET http://zoskinhealth.com/international-distributors>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://zoskinhealth.com/international-distributors took longer than 15.0 seconds..
2019-11-10 10:24:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://store.zephyronline.com/Accounts/Register>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://store.zephyronline.com/Accounts/Register took longer than 15.0 seconds..
2019-11-10 10:24:18 [scrapy.extensions.logstats] INFO: Crawled 2230 pages (at 14 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:24:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://store.zephyronline.com/Cart>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 10:24:49 [scrapy.core.scraper] ERROR: Error downloading <GET http://zagtoys.com/plush/?term=marvel>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://zagtoys.com/plush/?term=marvel took longer than 15.0 seconds..
2019-11-10 10:24:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zak.com/hydratrak-black-stainless-steel-tumblers_0015-S851>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zak.com/hydratrak-black-stainless-steel-tumblers_0015-S851 took longer than 15.0 seconds..
2019-11-10 10:24:49 [scrapy.extensions.logstats] INFO: Crawled 2235 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:27:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zak.com/hydratrak-black-stainless-steel-tumblers_0015-S850>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zak.com/hydratrak-black-stainless-steel-tumblers_0015-S850 took longer than 15.0 seconds..
2019-11-10 10:27:34 [scrapy.core.scraper] ERROR: Error downloading <GET http://zagtoys.com/plush/?term=cartoon-network>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://zagtoys.com/plush/?term=cartoon-network took longer than 15.0 seconds..
2019-11-10 10:27:34 [scrapy.extensions.logstats] INFO: Crawled 2235 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:30:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.youniqueproducts.com/products/view/US-12002-02>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.youniqueproducts.com/products/view/US-12002-02 took longer than 15.0 seconds..
2019-11-10 10:30:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.yorktownecabinetry.com/product/knife-drawer-insert/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.yorktownecabinetry.com/product/knife-drawer-insert/ took longer than 15.0 seconds..
2019-11-10 10:30:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.youngliving.com/en_KR/company/return-policy>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.youngliving.com/en_KR/company/return-policy took longer than 15.0 seconds..
2019-11-10 10:30:21 [scrapy.core.scraper] ERROR: Error downloading <GET http://zagtoys.com/plush/?term=nickelodeon>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://zagtoys.com/plush/?term=nickelodeon took longer than 15.0 seconds..
2019-11-10 10:30:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zak.com/planet-zak-water-bottles-1503-R592>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zak.com/planet-zak-water-bottles-1503-R592 took longer than 15.0 seconds..
2019-11-10 10:30:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zeromotorcycles.com/it/advantages>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zeromotorcycles.com/it/advantages took longer than 15.0 seconds..
2019-11-10 10:30:22 [scrapy.extensions.logstats] INFO: Crawled 2235 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:30:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://zephyronline.com/products/range-hoods/?filter_product-filters=mesh>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://zephyronline.com/products/range-hoods/?filter_product-filters=mesh took longer than 15.0 seconds..
2019-11-10 10:30:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.yorktownecabinetry.com/product/deep-slide-out-shelves-2/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.yorktownecabinetry.com/product/deep-slide-out-shelves-2/ took longer than 15.0 seconds..
2019-11-10 10:30:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zeromotorcycles.com/it>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zeromotorcycles.com/it took longer than 15.0 seconds..
2019-11-10 10:30:22 [scrapy.core.scraper] ERROR: Error downloading <GET http://zagtoys.com/2018/02/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://zagtoys.com/2018/02/ took longer than 15.0 seconds..
2019-11-10 10:30:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.youngliving.com/en_KR/company/local-delivery-policy>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.youngliving.com/en_KR/company/local-delivery-policy took longer than 15.0 seconds..
2019-11-10 10:30:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zak.com/hydratrak-black-stainless-steel-water-bottles_0015-S863>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zak.com/hydratrak-black-stainless-steel-water-bottles_0015-S863 took longer than 15.0 seconds..
2019-11-10 10:30:56 [scrapy.extensions.logstats] INFO: Crawled 2242 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:33:50 [scrapy.extensions.logstats] INFO: Crawled 2247 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:36:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zak.com/hydratrak-black-stainless-steel-water-bottles_0015-S860>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zak.com/hydratrak-black-stainless-steel-water-bottles_0015-S860 took longer than 15.0 seconds..
2019-11-10 10:36:41 [scrapy.core.scraper] ERROR: Error downloading <GET http://zagtoys.com/2017/03/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://zagtoys.com/2017/03/ took longer than 15.0 seconds..
2019-11-10 10:36:41 [scrapy.extensions.logstats] INFO: Crawled 2251 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:37:12 [scrapy.core.scraper] ERROR: Error downloading <GET http://zagtoys.com>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2019-11-10 10:37:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zak.com/hydratrak-black-stainless-steel-water-bottles_0015-S862>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 10:37:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.yorktownecabinetry.com/products/stylish-storage/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.yorktownecabinetry.com/products/stylish-storage/ took longer than 15.0 seconds..
2019-11-10 10:37:12 [scrapy.extensions.logstats] INFO: Crawled 2255 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:38:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.yorktownecabinetry.com/dealer-locator>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.yorktownecabinetry.com/dealer-locator took longer than 15.0 seconds..
2019-11-10 10:38:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zak.com/hydratrak-black-stainless-steel-water-bottles_0015-S861>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zak.com/hydratrak-black-stainless-steel-water-bottles_0015-S861 took longer than 15.0 seconds..
2019-11-10 10:38:39 [scrapy.core.scraper] ERROR: Error downloading <GET http://zagtoys.com/2017/01/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://zagtoys.com/2017/01/ took longer than 15.0 seconds..
2019-11-10 10:38:39 [scrapy.extensions.logstats] INFO: Crawled 2255 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:40:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.youngliving.com/en_AU/company/Partnerships>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.youngliving.com/en_AU/company/Partnerships took longer than 15.0 seconds..
2019-11-10 10:40:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zeromotorcycles.com/legal/terms-and-conditions>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zeromotorcycles.com/legal/terms-and-conditions took longer than 15.0 seconds..
2019-11-10 10:40:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.youniqueproducts.com/enrollment/preregister>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.youniqueproducts.com/enrollment/preregister took longer than 15.0 seconds..
2019-11-10 10:40:10 [scrapy.core.scraper] ERROR: Error downloading <GET http://zagtoys.com>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://zagtoys.com took longer than 15.0 seconds..
2019-11-10 10:40:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.yorktownecabinetry.com/product/base-with-roll-out-trays/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.yorktownecabinetry.com/product/base-with-roll-out-trays/ took longer than 15.0 seconds..
2019-11-10 10:40:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://zephyronline.com/product/luce-wall-mounted-hood-vent/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://zephyronline.com/product/luce-wall-mounted-hood-vent/ took longer than 15.0 seconds..
2019-11-10 10:40:10 [scrapy.extensions.logstats] INFO: Crawled 2255 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:40:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.zeromotorcycles.com/legal/terms-of-sale>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.zeromotorcycles.com/legal/terms-of-sale took longer than 15.0 seconds..
2019-11-10 10:40:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.yorktownecabinetry.com/product/drawer-divider/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.yorktownecabinetry.com/product/drawer-divider/ took longer than 15.0 seconds..
2019-11-10 10:40:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://zephyronline.com/products/range-hoods/pro-collection/?filter_product-filters=baffle>: User timeout caused connection failure.
2019-11-10 10:40:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.youngliving.com/en_AU/company/brand-ambassadors/chef-kate>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.youngliving.com/en_AU/company/brand-ambassadors/chef-kate took longer than 15.0 seconds..
2019-11-10 10:42:01 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.yorktownecabinetry.com/products/custom-choices/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.yorktownecabinetry.com/products/custom-choices/ took longer than 15.0 seconds..
2019-11-10 10:42:02 [scrapy.extensions.logstats] INFO: Crawled 2263 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:44:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.yorktownecabinetry.com/products/decorative-hardware/page/7/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.yorktownecabinetry.com/products/decorative-hardware/page/7/ took longer than 15.0 seconds..
2019-11-10 10:44:16 [scrapy.extensions.logstats] INFO: Crawled 2267 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:44:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.yorktownecabinetry.com/product/traditional-knob-j-2/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.yorktownecabinetry.com/product/traditional-knob-j-2/ took longer than 15.0 seconds..
2019-11-10 10:44:47 [scrapy.extensions.logstats] INFO: Crawled 2269 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:46:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.yorktownecabinetry.com/product/contemporary-knob-f-2/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.yorktownecabinetry.com/product/contemporary-knob-f-2/ took longer than 15.0 seconds..
2019-11-10 10:46:27 [scrapy.extensions.logstats] INFO: Crawled 2269 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:47:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.yorktownecabinetry.com/product/contemporary-knob-f/>: User timeout caused connection failure.
2019-11-10 10:47:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://zephyronline.com/product/incline-wall/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://zephyronline.com/product/incline-wall/ took longer than 15.0 seconds..
2019-11-10 10:47:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.youngliving.com/en_AU/products/c/wellness/healthy-snacking>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.youngliving.com/en_AU/products/c/wellness/healthy-snacking took longer than 15.0 seconds..
2019-11-10 10:47:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.youniqueproducts.com/MascaraFibers>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.youniqueproducts.com/MascaraFibers took longer than 15.0 seconds..
2019-11-10 10:47:25 [scrapy.extensions.logstats] INFO: Crawled 2270 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:47:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.youniqueproducts.com/TristaBrazan>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.youniqueproducts.com/TristaBrazan took longer than 15.0 seconds..
2019-11-10 10:47:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://zephyronline.com/products/wine-beverage-coolers/beverage-cooler/?filter_door-finish=ss-glass&filter_cooling-zones=dual>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://zephyronline.com/products/wine-beverage-coolers/beverage-cooler/?filter_door-finish=ss-glass&filter_cooling-zones=dual took longer than 15.0 seconds..
2019-11-10 10:47:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.youngliving.com/en_AU/products/c/wellness/inner-cleanse>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.youngliving.com/en_AU/products/c/wellness/inner-cleanse took longer than 15.0 seconds..
2019-11-10 10:47:58 [scrapy.extensions.logstats] INFO: Crawled 2270 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:47:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://zephyronline.com/products/wine-beverage-coolers/beverage-cooler/?filter_door-finish=ss-glass&filter_product-collections=zephyr-presrv&query_type_product-collections=or>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://zephyronline.com/products/wine-beverage-coolers/beverage-cooler/?filter_door-finish=ss-glass&filter_product-collections=zephyr-presrv&query_type_product-collections=or took longer than 15.0 seconds..
2019-11-10 10:47:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.youniqueproducts.com/teambeauty>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.youniqueproducts.com/teambeauty took longer than 15.0 seconds..
2019-11-10 10:47:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.youngliving.com/en_AU/products>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.youngliving.com/en_AU/products took longer than 15.0 seconds..
2019-11-10 10:49:03 [scrapy.extensions.logstats] INFO: Crawled 2274 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:50:09 [scrapy.extensions.logstats] INFO: Crawled 2276 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:50:47 [scrapy.extensions.logstats] INFO: Crawled 2278 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:52:17 [scrapy.extensions.logstats] INFO: Crawled 2282 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:53:17 [scrapy.extensions.logstats] INFO: Crawled 2284 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:54:31 [scrapy.extensions.logstats] INFO: Crawled 2285 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:55:41 [scrapy.extensions.logstats] INFO: Crawled 2286 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:56:10 [scrapy.extensions.logstats] INFO: Crawled 2287 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:57:13 [scrapy.extensions.logstats] INFO: Crawled 2289 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:57:45 [scrapy.extensions.logstats] INFO: Crawled 2289 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:58:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.youniqueproducts.com/ChantelleSchreyer/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.youniqueproducts.com/ChantelleSchreyer/ took longer than 15.0 seconds..
2019-11-10 10:58:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.youniqueproducts.com/products/view/US-46200-04>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.youniqueproducts.com/products/view/US-46200-04 took longer than 15.0 seconds..
2019-11-10 10:58:51 [scrapy.extensions.logstats] INFO: Crawled 2290 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:59:56 [scrapy.extensions.logstats] INFO: Crawled 2292 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 11:01:04 [scrapy.extensions.logstats] INFO: Crawled 2294 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 11:02:13 [scrapy.extensions.logstats] INFO: Crawled 2296 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 11:02:44 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-10 11:02:44 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 1537,
 'downloader/exception_type_count/scrapy.exceptions.IgnoreRequest': 18,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 18,
 'downloader/exception_type_count/twisted.internet.error.TimeoutError': 1404,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 97,
 'downloader/request_bytes': 2100399,
 'downloader/request_count': 4162,
 'downloader/request_method_count/GET': 4162,
 'downloader/response_bytes': 56881648,
 'downloader/response_count': 2643,
 'downloader/response_status_count/200': 2242,
 'downloader/response_status_count/301': 231,
 'downloader/response_status_count/302': 106,
 'downloader/response_status_count/307': 5,
 'downloader/response_status_count/403': 3,
 'downloader/response_status_count/404': 53,
 'downloader/response_status_count/503': 3,
 'dupefilter/filtered': 7066,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 10, 10, 2, 44, 61069),
 'log_count/ERROR': 252,
 'log_count/INFO': 822,
 'offsite/domains': 570,
 'offsite/filtered': 12501,
 'request_depth_count/0': 16,
 'request_depth_count/1': 1028,
 'request_depth_count/2': 10740,
 'request_depth_count/3': 9933,
 'request_depth_count/4': 368,
 'request_depth_max': 4,
 'response_received_count': 2297,
 'retry/count': 1269,
 'retry/max_reached': 253,
 'retry/reason_count/503 Service Unavailable': 2,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 12,
 'retry/reason_count/twisted.internet.error.TimeoutError': 1173,
 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 82,
 'scheduler/dequeued': 4098,
 'scheduler/dequeued/memory': 4098,
 'scheduler/enqueued': 4098,
 'scheduler/enqueued/memory': 4098,
 'start_time': datetime.datetime(2019, 11, 9, 17, 11, 45, 8872)}
2019-11-10 11:02:44 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-10 11:02:44 [root] INFO: spider 23 end
