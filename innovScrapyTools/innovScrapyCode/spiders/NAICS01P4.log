2019-11-08 22:56:29 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: innovScrapyCode)
2019-11-08 22:56:29 [scrapy.utils.log] INFO: Overridden settings: {'AJAXCRAWL_ENABLED': True, 'BOT_NAME': 'innovScrapyCode', 'CONCURRENT_REQUESTS': 160, 'CONCURRENT_REQUESTS_PER_DOMAIN': 32, 'DEPTH_LIMIT': 5, 'DEPTH_PRIORITY': 1, 'DOWNLOAD_DELAY': 2, 'DOWNLOAD_MAXSIZE': 5242880, 'DOWNLOAD_TIMEOUT': 15, 'LOG_FILE': 'NAICS01P4.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'innovationScraping.innovScrapyTools.innovScrapyCode.spiders', 'REACTOR_THREADPOOL_MAXSIZE': 100, 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['innovationScraping.innovScrapyTools.innovScrapyCode.spiders'], 'TELNETCONSOLE_PORT': None}
2019-11-08 22:56:29 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats', 'scrapy.extensions.logstats.LogStats']
2019-11-08 22:56:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy_fake_useragent.middleware.RandomUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.ajaxcrawl.AjaxCrawlMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-08 22:56:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-08 22:56:30 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-11-08 22:56:30 [scrapy.core.engine] INFO: Spider opened
2019-11-08 22:56:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 22:56:30 [root] INFO: spider 4 start
2019-11-08 22:56:36 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://www.coscojuvenile.com/robots.txt>: DNS lookup failed: no results for hostname lookup: www.coscojuvenile.com.
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: www.coscojuvenile.com.
2019-11-08 22:56:36 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://www.global.dcshoes.com/robots.txt>: DNS lookup failed: no results for hostname lookup: www.global.dcshoes.com.
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: www.global.dcshoes.com.
2019-11-08 22:56:38 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://www.countryhomeproducts.com/robots.txt>: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'ssl3_read_bytes', 'tlsv1 unrecognized name')]>]
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'ssl3_read_bytes', 'tlsv1 unrecognized name')]>]
2019-11-08 22:56:39 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://www.iam.delphi.com/robots.txt>: DNS lookup failed: no results for hostname lookup: www.iam.delphi.com.
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: www.iam.delphi.com.
2019-11-08 22:56:39 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://www.combatbaseball.com/robots.txt>: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'ssl3_read_bytes', 'sslv3 alert handshake failure')]>]
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'ssl3_read_bytes', 'sslv3 alert handshake failure')]>]
2019-11-08 22:56:41 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.crabtree-evelyn.com/%redirect_store_url%>: HTTP status code is not handled or not allowed
2019-11-08 22:56:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.combatbaseball.com/>: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'ssl3_read_bytes', 'sslv3 alert handshake failure')]>]
2019-11-08 22:57:30 [scrapy.extensions.logstats] INFO: Crawled 405 pages (at 405 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 22:58:30 [scrapy.extensions.logstats] INFO: Crawled 452 pages (at 47 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 22:59:30 [scrapy.extensions.logstats] INFO: Crawled 512 pages (at 60 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:00:30 [scrapy.extensions.logstats] INFO: Crawled 604 pages (at 92 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:01:30 [scrapy.extensions.logstats] INFO: Crawled 733 pages (at 129 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:02:30 [scrapy.extensions.logstats] INFO: Crawled 900 pages (at 167 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:03:30 [scrapy.extensions.logstats] INFO: Crawled 1057 pages (at 157 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:04:30 [scrapy.extensions.logstats] INFO: Crawled 1106 pages (at 49 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:05:30 [scrapy.extensions.logstats] INFO: Crawled 1151 pages (at 45 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:06:30 [scrapy.extensions.logstats] INFO: Crawled 1192 pages (at 41 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:07:30 [scrapy.extensions.logstats] INFO: Crawled 1216 pages (at 24 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:08:30 [scrapy.extensions.logstats] INFO: Crawled 1252 pages (at 36 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:09:30 [scrapy.extensions.logstats] INFO: Crawled 1299 pages (at 47 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:10:30 [scrapy.extensions.logstats] INFO: Crawled 1371 pages (at 72 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:11:30 [scrapy.extensions.logstats] INFO: Crawled 1470 pages (at 99 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:12:30 [scrapy.extensions.logstats] INFO: Crawled 1617 pages (at 147 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:12:42 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET https://cybexworld.cybexintl.com/robots.txt>: User timeout caused connection failure.
twisted.internet.error.TimeoutError: User timeout caused connection failure.
2019-11-08 23:13:30 [scrapy.extensions.logstats] INFO: Crawled 1739 pages (at 122 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:14:30 [scrapy.extensions.logstats] INFO: Crawled 1803 pages (at 64 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:15:30 [scrapy.extensions.logstats] INFO: Crawled 1841 pages (at 38 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:16:30 [scrapy.extensions.logstats] INFO: Crawled 1898 pages (at 57 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:17:30 [scrapy.extensions.logstats] INFO: Crawled 1943 pages (at 45 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:18:30 [scrapy.extensions.logstats] INFO: Crawled 1981 pages (at 38 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:19:30 [scrapy.extensions.logstats] INFO: Crawled 2021 pages (at 40 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:20:30 [scrapy.extensions.logstats] INFO: Crawled 2068 pages (at 47 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:21:30 [scrapy.extensions.logstats] INFO: Crawled 2136 pages (at 68 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:22:30 [scrapy.extensions.logstats] INFO: Crawled 2260 pages (at 124 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:22:41 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=16176>: HTTP status code is not handled or not allowed
2019-11-08 23:22:49 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=16185>: HTTP status code is not handled or not allowed
2019-11-08 23:22:57 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=16175>: HTTP status code is not handled or not allowed
2019-11-08 23:23:05 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=16174>: HTTP status code is not handled or not allowed
2019-11-08 23:23:14 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=16187>: HTTP status code is not handled or not allowed
2019-11-08 23:23:21 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=398>: HTTP status code is not handled or not allowed
2019-11-08 23:23:29 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=405>: HTTP status code is not handled or not allowed
2019-11-08 23:23:30 [scrapy.extensions.logstats] INFO: Crawled 2370 pages (at 110 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:23:36 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=469>: HTTP status code is not handled or not allowed
2019-11-08 23:23:45 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=17756>: HTTP status code is not handled or not allowed
2019-11-08 23:23:52 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=17752>: HTTP status code is not handled or not allowed
2019-11-08 23:23:59 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=17754>: HTTP status code is not handled or not allowed
2019-11-08 23:24:07 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=16149>: HTTP status code is not handled or not allowed
2019-11-08 23:24:14 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=17714>: HTTP status code is not handled or not allowed
2019-11-08 23:24:23 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=17718>: HTTP status code is not handled or not allowed
2019-11-08 23:24:30 [scrapy.extensions.logstats] INFO: Crawled 2502 pages (at 132 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:24:31 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=17717>: HTTP status code is not handled or not allowed
2019-11-08 23:24:39 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=17723>: HTTP status code is not handled or not allowed
2019-11-08 23:25:30 [scrapy.extensions.logstats] INFO: Crawled 2618 pages (at 116 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:26:30 [scrapy.extensions.logstats] INFO: Crawled 2689 pages (at 71 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:27:30 [scrapy.extensions.logstats] INFO: Crawled 2739 pages (at 50 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:28:30 [scrapy.extensions.logstats] INFO: Crawled 2762 pages (at 23 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:29:30 [scrapy.extensions.logstats] INFO: Crawled 2800 pages (at 38 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:30:30 [scrapy.extensions.logstats] INFO: Crawled 2827 pages (at 27 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:31:30 [scrapy.extensions.logstats] INFO: Crawled 2863 pages (at 36 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:32:30 [scrapy.extensions.logstats] INFO: Crawled 2917 pages (at 54 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:32:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ir.deckers.com/Cache/1500124665.PDF?O=PDF&T=&Y=&D=&FID=1500124665&iid=4391531> (referer: http://ir.deckers.com)
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\root\Desktop\GitHub\innovScraping\innovationScraping\innovScrapyTools\innovScrapyCode\spiders\customized_web_crawler.py", line 67, in parse_item
    insert_into_mongo(response.url, response.text, self.coll)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\http\response\__init__.py", line 93, in text
    raise AttributeError("Response content isn't text")
AttributeError: Response content isn't text
2019-11-08 23:33:31 [scrapy.extensions.logstats] INFO: Crawled 2997 pages (at 80 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:34:30 [scrapy.extensions.logstats] INFO: Crawled 3062 pages (at 65 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:35:30 [scrapy.extensions.logstats] INFO: Crawled 3130 pages (at 68 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:36:32 [scrapy.extensions.logstats] INFO: Crawled 3175 pages (at 45 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:37:30 [scrapy.extensions.logstats] INFO: Crawled 3202 pages (at 27 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:38:22 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=16186>: HTTP status code is not handled or not allowed
2019-11-08 23:38:35 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=16148>: HTTP status code is not handled or not allowed
2019-11-08 23:38:35 [scrapy.extensions.logstats] INFO: Crawled 3234 pages (at 32 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:39:03 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=399>: HTTP status code is not handled or not allowed
2019-11-08 23:39:32 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=16191>: HTTP status code is not handled or not allowed
2019-11-08 23:39:32 [scrapy.extensions.logstats] INFO: Crawled 3256 pages (at 22 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:40:02 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=16190>: HTTP status code is not handled or not allowed
2019-11-08 23:40:29 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=17795>: HTTP status code is not handled or not allowed
2019-11-08 23:40:39 [scrapy.extensions.logstats] INFO: Crawled 3281 pages (at 25 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:40:55 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=16146>: HTTP status code is not handled or not allowed
2019-11-08 23:41:25 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=16145>: HTTP status code is not handled or not allowed
2019-11-08 23:41:35 [scrapy.extensions.logstats] INFO: Crawled 3310 pages (at 29 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:42:27 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=17755>: HTTP status code is not handled or not allowed
2019-11-08 23:42:38 [scrapy.extensions.logstats] INFO: Crawled 3328 pages (at 18 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:43:23 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=17753>: HTTP status code is not handled or not allowed
2019-11-08 23:43:33 [scrapy.extensions.logstats] INFO: Crawled 3346 pages (at 18 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:44:01 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=17763>: HTTP status code is not handled or not allowed
2019-11-08 23:44:38 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=17799>: HTTP status code is not handled or not allowed
2019-11-08 23:44:38 [scrapy.extensions.logstats] INFO: Crawled 3369 pages (at 23 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:45:37 [scrapy.extensions.logstats] INFO: Crawled 3380 pages (at 11 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:46:19 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=457>: HTTP status code is not handled or not allowed
2019-11-08 23:46:31 [scrapy.extensions.logstats] INFO: Crawled 3394 pages (at 14 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:47:41 [scrapy.extensions.logstats] INFO: Crawled 3410 pages (at 16 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:48:31 [scrapy.extensions.logstats] INFO: Crawled 3422 pages (at 12 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:49:31 [scrapy.extensions.logstats] INFO: Crawled 3437 pages (at 15 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:50:34 [scrapy.extensions.logstats] INFO: Crawled 3452 pages (at 15 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:50:45 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=428>: HTTP status code is not handled or not allowed
2019-11-08 23:51:32 [scrapy.extensions.logstats] INFO: Crawled 3468 pages (at 16 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:52:09 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.crestliner.com/download_spec_sheet/1615/> (referer: https://www.crestliner.com/raptor/1850-raptor/)
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\root\Desktop\GitHub\innovScraping\innovationScraping\innovScrapyTools\innovScrapyCode\spiders\customized_web_crawler.py", line 67, in parse_item
    insert_into_mongo(response.url, response.text, self.coll)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\http\response\__init__.py", line 93, in text
    raise AttributeError("Response content isn't text")
AttributeError: Response content isn't text
2019-11-08 23:52:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.crestliner.com/download_spec_sheet/1576/> (referer: https://www.crestliner.com/raptor/1850-raptor/)
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\root\Desktop\GitHub\innovScraping\innovationScraping\innovScrapyTools\innovScrapyCode\spiders\customized_web_crawler.py", line 67, in parse_item
    insert_into_mongo(response.url, response.text, self.coll)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\http\response\__init__.py", line 93, in text
    raise AttributeError("Response content isn't text")
AttributeError: Response content isn't text
2019-11-08 23:52:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.crestliner.com/download_engine_performance/6257> (referer: https://www.crestliner.com/raptor/1850-raptor/)
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\root\Desktop\GitHub\innovScraping\innovationScraping\innovScrapyTools\innovScrapyCode\spiders\customized_web_crawler.py", line 67, in parse_item
    insert_into_mongo(response.url, response.text, self.coll)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\http\response\__init__.py", line 93, in text
    raise AttributeError("Response content isn't text")
AttributeError: Response content isn't text
2019-11-08 23:52:36 [scrapy.extensions.logstats] INFO: Crawled 3485 pages (at 17 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:53:32 [scrapy.extensions.logstats] INFO: Crawled 3496 pages (at 11 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:54:30 [scrapy.extensions.logstats] INFO: Crawled 3508 pages (at 12 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:55:31 [scrapy.extensions.logstats] INFO: Crawled 3523 pages (at 15 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:56:35 [scrapy.extensions.logstats] INFO: Crawled 3539 pages (at 16 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:57:30 [scrapy.extensions.logstats] INFO: Crawled 3553 pages (at 14 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:58:35 [scrapy.extensions.logstats] INFO: Crawled 3568 pages (at 15 pages/min), scraped 0 items (at 0 items/min)
2019-11-08 23:59:35 [scrapy.extensions.logstats] INFO: Crawled 3580 pages (at 12 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:00:37 [scrapy.extensions.logstats] INFO: Crawled 3590 pages (at 10 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:01:35 [scrapy.extensions.logstats] INFO: Crawled 3600 pages (at 10 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:02:37 [scrapy.extensions.logstats] INFO: Crawled 3613 pages (at 13 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:03:33 [scrapy.extensions.logstats] INFO: Crawled 3622 pages (at 9 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:03:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.drhorton.com/Freedom-Homes>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-09 00:03:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.drhorton.com/Emerald-Homes>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-09 00:03:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.drhorton.com/Express-Homes>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-09 00:04:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.drhorton.com/About-Us/The-Horton-Story>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-09 00:04:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.drhorton.com/indiana/indianapolis/indianapolis/~/link?_id=B284066C29A2400AB0FED4134A1DDB65&_z=z>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-09 00:04:35 [scrapy.extensions.logstats] INFO: Crawled 3632 pages (at 10 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:05:32 [scrapy.extensions.logstats] INFO: Crawled 3642 pages (at 10 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:06:32 [scrapy.extensions.logstats] INFO: Crawled 3652 pages (at 10 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:07:37 [scrapy.extensions.logstats] INFO: Crawled 3663 pages (at 11 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:08:32 [scrapy.extensions.logstats] INFO: Crawled 3672 pages (at 9 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:09:36 [scrapy.extensions.logstats] INFO: Crawled 3682 pages (at 10 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:10:30 [scrapy.extensions.logstats] INFO: Crawled 3690 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:11:30 [scrapy.extensions.logstats] INFO: Crawled 3700 pages (at 10 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:12:34 [scrapy.extensions.logstats] INFO: Crawled 3710 pages (at 10 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:13:34 [scrapy.extensions.logstats] INFO: Crawled 3719 pages (at 9 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:14:34 [scrapy.extensions.logstats] INFO: Crawled 3728 pages (at 9 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:15:41 [scrapy.extensions.logstats] INFO: Crawled 3736 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:16:55 [scrapy.extensions.logstats] INFO: Crawled 3749 pages (at 13 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:17:31 [scrapy.extensions.logstats] INFO: Crawled 3752 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:18:31 [scrapy.extensions.logstats] INFO: Crawled 3762 pages (at 10 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:19:35 [scrapy.extensions.logstats] INFO: Crawled 3779 pages (at 17 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:20:35 [scrapy.extensions.logstats] INFO: Crawled 3788 pages (at 9 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:21:39 [scrapy.extensions.logstats] INFO: Crawled 3799 pages (at 11 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:22:33 [scrapy.extensions.logstats] INFO: Crawled 3813 pages (at 14 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:23:35 [scrapy.extensions.logstats] INFO: Crawled 3827 pages (at 14 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:24:31 [scrapy.extensions.logstats] INFO: Crawled 3846 pages (at 19 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:25:31 [scrapy.extensions.logstats] INFO: Crawled 3856 pages (at 10 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:26:47 [scrapy.extensions.logstats] INFO: Crawled 3870 pages (at 14 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:27:33 [scrapy.extensions.logstats] INFO: Crawled 3879 pages (at 9 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:28:35 [scrapy.extensions.logstats] INFO: Crawled 3890 pages (at 11 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:29:30 [scrapy.extensions.logstats] INFO: Crawled 3905 pages (at 15 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:30:42 [scrapy.extensions.logstats] INFO: Crawled 3920 pages (at 15 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:31:37 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://blog.lowepro.com/robots.txt>: User timeout caused connection failure: Getting http://blog.lowepro.com/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://blog.lowepro.com/robots.txt took longer than 15.0 seconds..
2019-11-09 00:31:37 [scrapy.extensions.logstats] INFO: Crawled 3932 pages (at 12 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:31:55 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://naturalskincare.com?chrole=17&promocode=&promocodeaction=overwrite&sj=cMONMJRNtCx4a4AHQ6b5cLzli%3B1573251383%3B360883000>: HTTP status code is not handled or not allowed
2019-11-09 00:32:31 [scrapy.extensions.logstats] INFO: Crawled 3940 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:33:31 [scrapy.extensions.logstats] INFO: Crawled 3949 pages (at 9 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:34:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://naturalskincare.com/blog/?vid=VPUwuHaMAtj_FlK_&chrole=17&ck=q0G3PnaMAtb_FtVm&cktime=167030&promocode=&promocodeaction=overwrite&sj=cMONMJRNtCx4a4AHQ6b5cLzli%3B1573251383%3B360883000>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://naturalskincare.com/blog/?vid=VPUwuHaMAtj_FlK_&chrole=17&ck=q0G3PnaMAtb_FtVm&cktime=167030&promocode=&promocodeaction=overwrite&sj=cMONMJRNtCx4a4AHQ6b5cLzli%3B1573251383%3B360883000 took longer than 15.0 seconds..
2019-11-09 00:34:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://naturalskincare.com/our-promise/?vid=VPUwuHaMAtj_FlK_&chrole=17&ck=q0G3PnaMAtb_FtVm&cktime=167030&promocode=&promocodeaction=overwrite&sj=cMONMJRNtCx4a4AHQ6b5cLzli%3B1573251383%3B360883000>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://naturalskincare.com/our-promise/?vid=VPUwuHaMAtj_FlK_&chrole=17&ck=q0G3PnaMAtb_FtVm&cktime=167030&promocode=&promocodeaction=overwrite&sj=cMONMJRNtCx4a4AHQ6b5cLzli%3B1573251383%3B360883000 took longer than 15.0 seconds..
2019-11-09 00:34:38 [scrapy.extensions.logstats] INFO: Crawled 3962 pages (at 13 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:35:34 [scrapy.extensions.logstats] INFO: Crawled 3969 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:36:32 [scrapy.extensions.logstats] INFO: Crawled 3978 pages (at 9 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:37:33 [scrapy.extensions.logstats] INFO: Crawled 3986 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:38:32 [scrapy.extensions.logstats] INFO: Crawled 3993 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:39:36 [scrapy.extensions.logstats] INFO: Crawled 4001 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:40:37 [scrapy.extensions.logstats] INFO: Crawled 4009 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:41:34 [scrapy.extensions.logstats] INFO: Crawled 4016 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:42:32 [scrapy.extensions.logstats] INFO: Crawled 4023 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:43:36 [scrapy.extensions.logstats] INFO: Crawled 4030 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:44:37 [scrapy.extensions.logstats] INFO: Crawled 4037 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:45:34 [scrapy.extensions.logstats] INFO: Crawled 4044 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:46:33 [scrapy.extensions.logstats] INFO: Crawled 4051 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:47:37 [scrapy.extensions.logstats] INFO: Crawled 4059 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:48:35 [scrapy.extensions.logstats] INFO: Crawled 4066 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:49:31 [scrapy.extensions.logstats] INFO: Crawled 4073 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:50:33 [scrapy.extensions.logstats] INFO: Crawled 4079 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:51:36 [scrapy.extensions.logstats] INFO: Crawled 4087 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:52:38 [scrapy.extensions.logstats] INFO: Crawled 4095 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:53:35 [scrapy.extensions.logstats] INFO: Crawled 4101 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:54:37 [scrapy.extensions.logstats] INFO: Crawled 4108 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:55:33 [scrapy.extensions.logstats] INFO: Crawled 4114 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:56:34 [scrapy.extensions.logstats] INFO: Crawled 4121 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:57:36 [scrapy.extensions.logstats] INFO: Crawled 4129 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:58:30 [scrapy.extensions.logstats] INFO: Crawled 4135 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 00:59:32 [scrapy.extensions.logstats] INFO: Crawled 4142 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:00:34 [scrapy.extensions.logstats] INFO: Crawled 4149 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:01:36 [scrapy.extensions.logstats] INFO: Crawled 4156 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:02:37 [scrapy.extensions.logstats] INFO: Crawled 4163 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:03:37 [scrapy.extensions.logstats] INFO: Crawled 4170 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:04:31 [scrapy.extensions.logstats] INFO: Crawled 4176 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:05:35 [scrapy.extensions.logstats] INFO: Crawled 4183 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:06:41 [scrapy.extensions.logstats] INFO: Crawled 4190 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:07:33 [scrapy.extensions.logstats] INFO: Crawled 4196 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:08:35 [scrapy.extensions.logstats] INFO: Crawled 4203 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:09:33 [scrapy.extensions.logstats] INFO: Crawled 4210 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:10:39 [scrapy.extensions.logstats] INFO: Crawled 4217 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:11:37 [scrapy.extensions.logstats] INFO: Crawled 4223 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:12:34 [scrapy.extensions.logstats] INFO: Crawled 4229 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:13:30 [scrapy.extensions.logstats] INFO: Crawled 4235 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:14:30 [scrapy.extensions.logstats] INFO: Crawled 4241 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:15:31 [scrapy.extensions.logstats] INFO: Crawled 4247 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:16:38 [scrapy.extensions.logstats] INFO: Crawled 4254 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:17:36 [scrapy.extensions.logstats] INFO: Crawled 4259 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:18:38 [scrapy.extensions.logstats] INFO: Crawled 4266 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:19:39 [scrapy.extensions.logstats] INFO: Crawled 4272 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:20:38 [scrapy.extensions.logstats] INFO: Crawled 4278 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:21:23 [scrapy.core.scraper] ERROR: Error downloading <GET https://blog.lowepro.com/2018/04/23/making-the-climb-with-chris-noble-and-lowepro/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://blog.lowepro.com/2018/04/23/making-the-climb-with-chris-noble-and-lowepro/ took longer than 15.0 seconds..
2019-11-09 01:21:32 [scrapy.extensions.logstats] INFO: Crawled 4284 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:22:37 [scrapy.extensions.logstats] INFO: Crawled 4293 pages (at 9 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:23:32 [scrapy.extensions.logstats] INFO: Crawled 4299 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:24:30 [scrapy.extensions.logstats] INFO: Crawled 4305 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:25:32 [scrapy.extensions.logstats] INFO: Crawled 4311 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:26:30 [scrapy.extensions.logstats] INFO: Crawled 4317 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:27:31 [scrapy.extensions.logstats] INFO: Crawled 4322 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:28:38 [scrapy.extensions.logstats] INFO: Crawled 4330 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:29:34 [scrapy.extensions.logstats] INFO: Crawled 4336 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:30:34 [scrapy.extensions.logstats] INFO: Crawled 4342 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:31:30 [scrapy.extensions.logstats] INFO: Crawled 4348 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:32:33 [scrapy.extensions.logstats] INFO: Crawled 4354 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:33:37 [scrapy.extensions.logstats] INFO: Crawled 4360 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:34:38 [scrapy.extensions.logstats] INFO: Crawled 4366 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:35:36 [scrapy.extensions.logstats] INFO: Crawled 4372 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:36:32 [scrapy.extensions.logstats] INFO: Crawled 4377 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:37:32 [scrapy.extensions.logstats] INFO: Crawled 4383 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:38:32 [scrapy.extensions.logstats] INFO: Crawled 4389 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:39:32 [scrapy.extensions.logstats] INFO: Crawled 4395 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:40:34 [scrapy.extensions.logstats] INFO: Crawled 4401 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:41:30 [scrapy.extensions.logstats] INFO: Crawled 4406 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:42:34 [scrapy.extensions.logstats] INFO: Crawled 4412 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:43:34 [scrapy.extensions.logstats] INFO: Crawled 4417 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:44:42 [scrapy.extensions.logstats] INFO: Crawled 4423 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:45:37 [scrapy.extensions.logstats] INFO: Crawled 4427 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:46:31 [scrapy.extensions.logstats] INFO: Crawled 4433 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:47:39 [scrapy.extensions.logstats] INFO: Crawled 4439 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:48:33 [scrapy.extensions.logstats] INFO: Crawled 4444 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:49:35 [scrapy.extensions.logstats] INFO: Crawled 4449 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:50:31 [scrapy.extensions.logstats] INFO: Crawled 4454 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:51:40 [scrapy.extensions.logstats] INFO: Crawled 4460 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:52:32 [scrapy.extensions.logstats] INFO: Crawled 4465 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:53:41 [scrapy.extensions.logstats] INFO: Crawled 4471 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:54:36 [scrapy.extensions.logstats] INFO: Crawled 4476 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:55:32 [scrapy.extensions.logstats] INFO: Crawled 4481 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:56:32 [scrapy.extensions.logstats] INFO: Crawled 4487 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:57:31 [scrapy.extensions.logstats] INFO: Crawled 4492 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:58:31 [scrapy.extensions.logstats] INFO: Crawled 4497 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 01:59:30 [scrapy.extensions.logstats] INFO: Crawled 4501 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:00:31 [scrapy.extensions.logstats] INFO: Crawled 4507 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:01:38 [scrapy.extensions.logstats] INFO: Crawled 4513 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:02:36 [scrapy.extensions.logstats] INFO: Crawled 4518 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:03:35 [scrapy.extensions.logstats] INFO: Crawled 4523 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:04:35 [scrapy.extensions.logstats] INFO: Crawled 4528 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:05:36 [scrapy.extensions.logstats] INFO: Crawled 4533 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:06:36 [scrapy.extensions.logstats] INFO: Crawled 4538 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:07:37 [scrapy.extensions.logstats] INFO: Crawled 4543 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:08:39 [scrapy.extensions.logstats] INFO: Crawled 4548 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:09:41 [scrapy.extensions.logstats] INFO: Crawled 4553 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:10:30 [scrapy.extensions.logstats] INFO: Crawled 4557 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:11:40 [scrapy.extensions.logstats] INFO: Crawled 4563 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:12:39 [scrapy.extensions.logstats] INFO: Crawled 4569 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:12:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://steamcommunity.com/openid/login?openid.ns=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0&openid.mode=checkid_setup&openid.return_to=https%3A%2F%2Fwww.daysofwonder.com%2F%2Fsignup%2Fsteam_ok%3Freturnto%3D%252Fen%252Fcommunity%252F&openid.realm=https%3A%2F%2Fwww.daysofwonder.com&openid.ns.sreg=http%3A%2F%2Fopenid.net%2Fextensions%2Fsreg%2F1.1&openid.claimed_id=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0%2Fidentifier_select&openid.identity=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0%2Fidentifier_select>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://steamcommunity.com/openid/login?openid.ns=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0&openid.mode=checkid_setup&openid.return_to=https%3A%2F%2Fwww.daysofwonder.com%2F%2Fsignup%2Fsteam_ok%3Freturnto%3D%252Fen%252Fcommunity%252F&openid.realm=https%3A%2F%2Fwww.daysofwonder.com&openid.ns.sreg=http%3A%2F%2Fopenid.net%2Fextensions%2Fsreg%2F1.1&openid.claimed_id=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0%2Fidentifier_select&openid.identity=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0%2Fidentifier_select took longer than 15.0 seconds..
2019-11-09 02:13:41 [scrapy.extensions.logstats] INFO: Crawled 4575 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:14:32 [scrapy.extensions.logstats] INFO: Crawled 4578 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:15:34 [scrapy.extensions.logstats] INFO: Crawled 4583 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:16:44 [scrapy.extensions.logstats] INFO: Crawled 4592 pages (at 9 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:17:43 [scrapy.extensions.logstats] INFO: Crawled 4596 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:18:52 [scrapy.extensions.logstats] INFO: Crawled 4601 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:19:53 [scrapy.extensions.logstats] INFO: Crawled 4606 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:20:43 [scrapy.extensions.logstats] INFO: Crawled 4608 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:21:41 [scrapy.extensions.logstats] INFO: Crawled 4613 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:22:30 [scrapy.extensions.logstats] INFO: Crawled 4618 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:23:19 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET https://my.cybexintl.com/robots.txt>: User timeout caused connection failure.
twisted.internet.error.TimeoutError: User timeout caused connection failure.
2019-11-09 02:23:32 [scrapy.extensions.logstats] INFO: Crawled 4622 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:24:49 [scrapy.extensions.logstats] INFO: Crawled 4629 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:25:38 [scrapy.extensions.logstats] INFO: Crawled 4634 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:26:40 [scrapy.extensions.logstats] INFO: Crawled 4637 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:27:54 [scrapy.extensions.logstats] INFO: Crawled 4644 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:28:51 [scrapy.extensions.logstats] INFO: Crawled 4650 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:29:42 [scrapy.extensions.logstats] INFO: Crawled 4650 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:30:34 [scrapy.extensions.logstats] INFO: Crawled 4658 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:31:53 [scrapy.extensions.logstats] INFO: Crawled 4663 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:32:34 [scrapy.extensions.logstats] INFO: Crawled 4665 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:33:51 [scrapy.extensions.logstats] INFO: Crawled 4673 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:34:42 [scrapy.extensions.logstats] INFO: Crawled 4677 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:35:30 [scrapy.extensions.logstats] INFO: Crawled 4681 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:36:47 [scrapy.extensions.logstats] INFO: Crawled 4687 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:37:31 [scrapy.extensions.logstats] INFO: Crawled 4691 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:38:38 [scrapy.extensions.logstats] INFO: Crawled 4695 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:39:30 [scrapy.extensions.logstats] INFO: Crawled 4698 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:40:34 [scrapy.extensions.logstats] INFO: Crawled 4706 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:41:32 [scrapy.extensions.logstats] INFO: Crawled 4711 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:42:46 [scrapy.extensions.logstats] INFO: Crawled 4713 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:43:39 [scrapy.extensions.logstats] INFO: Crawled 4720 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:44:45 [scrapy.extensions.logstats] INFO: Crawled 4726 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:45:36 [scrapy.extensions.logstats] INFO: Crawled 4730 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:46:31 [scrapy.extensions.logstats] INFO: Crawled 4733 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:47:36 [scrapy.extensions.logstats] INFO: Crawled 4739 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:48:52 [scrapy.extensions.logstats] INFO: Crawled 4741 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:49:37 [scrapy.extensions.logstats] INFO: Crawled 4746 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:50:40 [scrapy.extensions.logstats] INFO: Crawled 4754 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:51:54 [scrapy.extensions.logstats] INFO: Crawled 4756 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:52:33 [scrapy.extensions.logstats] INFO: Crawled 4762 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:53:35 [scrapy.extensions.logstats] INFO: Crawled 4768 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:54:39 [scrapy.extensions.logstats] INFO: Crawled 4773 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:55:30 [scrapy.extensions.logstats] INFO: Crawled 4775 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:56:37 [scrapy.extensions.logstats] INFO: Crawled 4780 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:57:47 [scrapy.extensions.logstats] INFO: Crawled 4788 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:58:46 [scrapy.extensions.logstats] INFO: Crawled 4793 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 02:59:41 [scrapy.extensions.logstats] INFO: Crawled 4799 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:00:41 [scrapy.extensions.logstats] INFO: Crawled 4803 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:01:42 [scrapy.extensions.logstats] INFO: Crawled 4807 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:02:34 [scrapy.extensions.logstats] INFO: Crawled 4810 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:03:38 [scrapy.extensions.logstats] INFO: Crawled 4815 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:04:33 [scrapy.extensions.logstats] INFO: Crawled 4819 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:05:40 [scrapy.extensions.logstats] INFO: Crawled 4824 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:06:35 [scrapy.extensions.logstats] INFO: Crawled 4828 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:07:33 [scrapy.extensions.logstats] INFO: Crawled 4832 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:08:41 [scrapy.extensions.logstats] INFO: Crawled 4837 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:09:37 [scrapy.extensions.logstats] INFO: Crawled 4841 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:10:39 [scrapy.extensions.logstats] INFO: Crawled 4846 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:11:37 [scrapy.extensions.logstats] INFO: Crawled 4852 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:12:31 [scrapy.extensions.logstats] INFO: Crawled 4857 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:13:37 [scrapy.extensions.logstats] INFO: Crawled 4863 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:14:30 [scrapy.extensions.logstats] INFO: Crawled 4868 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:15:34 [scrapy.extensions.logstats] INFO: Crawled 4874 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:16:37 [scrapy.extensions.logstats] INFO: Crawled 4880 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:17:31 [scrapy.extensions.logstats] INFO: Crawled 4885 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:18:36 [scrapy.extensions.logstats] INFO: Crawled 4891 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:19:35 [scrapy.extensions.logstats] INFO: Crawled 4897 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:20:38 [scrapy.extensions.logstats] INFO: Crawled 4903 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:21:31 [scrapy.extensions.logstats] INFO: Crawled 4908 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:22:34 [scrapy.extensions.logstats] INFO: Crawled 4914 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:23:33 [scrapy.extensions.logstats] INFO: Crawled 4919 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:24:35 [scrapy.extensions.logstats] INFO: Crawled 4924 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:25:34 [scrapy.extensions.logstats] INFO: Crawled 4929 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:26:34 [scrapy.extensions.logstats] INFO: Crawled 4934 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:27:33 [scrapy.extensions.logstats] INFO: Crawled 4939 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:28:37 [scrapy.extensions.logstats] INFO: Crawled 4944 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:29:35 [scrapy.extensions.logstats] INFO: Crawled 4948 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:30:32 [scrapy.extensions.logstats] INFO: Crawled 4952 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:31:44 [scrapy.extensions.logstats] INFO: Crawled 4957 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:32:38 [scrapy.extensions.logstats] INFO: Crawled 4961 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:33:35 [scrapy.extensions.logstats] INFO: Crawled 4965 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:34:33 [scrapy.extensions.logstats] INFO: Crawled 4969 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:35:38 [scrapy.extensions.logstats] INFO: Crawled 4974 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:36:34 [scrapy.extensions.logstats] INFO: Crawled 4978 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:37:33 [scrapy.extensions.logstats] INFO: Crawled 4982 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:38:44 [scrapy.extensions.logstats] INFO: Crawled 4987 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:39:38 [scrapy.extensions.logstats] INFO: Crawled 4991 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:40:33 [scrapy.extensions.logstats] INFO: Crawled 4995 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:41:36 [scrapy.extensions.logstats] INFO: Crawled 4999 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:42:32 [scrapy.extensions.logstats] INFO: Crawled 5003 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:43:41 [scrapy.extensions.logstats] INFO: Crawled 5008 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:44:30 [scrapy.extensions.logstats] INFO: Crawled 5011 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:45:32 [scrapy.extensions.logstats] INFO: Crawled 5015 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:46:35 [scrapy.extensions.logstats] INFO: Crawled 5019 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:47:36 [scrapy.extensions.logstats] INFO: Crawled 5023 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:48:36 [scrapy.extensions.logstats] INFO: Crawled 5027 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:49:37 [scrapy.extensions.logstats] INFO: Crawled 5031 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:50:34 [scrapy.extensions.logstats] INFO: Crawled 5035 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:51:30 [scrapy.extensions.logstats] INFO: Crawled 5040 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:52:34 [scrapy.extensions.logstats] INFO: Crawled 5046 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:53:40 [scrapy.extensions.logstats] INFO: Crawled 5052 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:54:36 [scrapy.extensions.logstats] INFO: Crawled 5057 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:55:31 [scrapy.extensions.logstats] INFO: Crawled 5062 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:56:36 [scrapy.extensions.logstats] INFO: Crawled 5068 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:57:33 [scrapy.extensions.logstats] INFO: Crawled 5073 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:58:33 [scrapy.extensions.logstats] INFO: Crawled 5078 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 03:59:30 [scrapy.extensions.logstats] INFO: Crawled 5083 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:00:35 [scrapy.extensions.logstats] INFO: Crawled 5089 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:01:31 [scrapy.extensions.logstats] INFO: Crawled 5094 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:02:38 [scrapy.extensions.logstats] INFO: Crawled 5100 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:03:36 [scrapy.extensions.logstats] INFO: Crawled 5105 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:04:30 [scrapy.extensions.logstats] INFO: Crawled 5110 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:05:36 [scrapy.extensions.logstats] INFO: Crawled 5116 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:06:38 [scrapy.extensions.logstats] INFO: Crawled 5121 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:07:30 [scrapy.extensions.logstats] INFO: Crawled 5125 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:08:36 [scrapy.extensions.logstats] INFO: Crawled 5131 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:09:34 [scrapy.extensions.logstats] INFO: Crawled 5136 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:10:32 [scrapy.extensions.logstats] INFO: Crawled 5141 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:11:39 [scrapy.extensions.logstats] INFO: Crawled 5147 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:12:45 [scrapy.extensions.logstats] INFO: Crawled 5153 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:13:34 [scrapy.extensions.logstats] INFO: Crawled 5155 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:14:32 [scrapy.extensions.logstats] INFO: Crawled 5159 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:15:35 [scrapy.extensions.logstats] INFO: Crawled 5163 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:16:38 [scrapy.extensions.logstats] INFO: Crawled 5167 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:17:42 [scrapy.extensions.logstats] INFO: Crawled 5171 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:18:41 [scrapy.extensions.logstats] INFO: Crawled 5175 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:19:37 [scrapy.extensions.logstats] INFO: Crawled 5179 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:20:38 [scrapy.extensions.logstats] INFO: Crawled 5183 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:21:39 [scrapy.extensions.logstats] INFO: Crawled 5187 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:22:37 [scrapy.extensions.logstats] INFO: Crawled 5191 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:23:42 [scrapy.extensions.logstats] INFO: Crawled 5195 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:24:47 [scrapy.extensions.logstats] INFO: Crawled 5199 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:25:37 [scrapy.extensions.logstats] INFO: Crawled 5202 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:26:43 [scrapy.extensions.logstats] INFO: Crawled 5206 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:27:44 [scrapy.extensions.logstats] INFO: Crawled 5210 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:28:35 [scrapy.extensions.logstats] INFO: Crawled 5213 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:29:38 [scrapy.extensions.logstats] INFO: Crawled 5217 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:30:31 [scrapy.extensions.logstats] INFO: Crawled 5221 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:31:38 [scrapy.extensions.logstats] INFO: Crawled 5226 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:32:31 [scrapy.extensions.logstats] INFO: Crawled 5230 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:33:33 [scrapy.extensions.logstats] INFO: Crawled 5235 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:34:40 [scrapy.extensions.logstats] INFO: Crawled 5239 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:35:36 [scrapy.extensions.logstats] INFO: Crawled 5242 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:36:35 [scrapy.extensions.logstats] INFO: Crawled 5246 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:37:35 [scrapy.extensions.logstats] INFO: Crawled 5250 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:38:37 [scrapy.extensions.logstats] INFO: Crawled 5255 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:39:45 [scrapy.extensions.logstats] INFO: Crawled 5260 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:40:31 [scrapy.extensions.logstats] INFO: Crawled 5263 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:41:36 [scrapy.extensions.logstats] INFO: Crawled 5267 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:42:39 [scrapy.extensions.logstats] INFO: Crawled 5271 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:43:31 [scrapy.extensions.logstats] INFO: Crawled 5274 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:44:34 [scrapy.extensions.logstats] INFO: Crawled 5278 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:45:40 [scrapy.extensions.logstats] INFO: Crawled 5282 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:46:43 [scrapy.extensions.logstats] INFO: Crawled 5286 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:47:30 [scrapy.extensions.logstats] INFO: Crawled 5289 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:48:31 [scrapy.extensions.logstats] INFO: Crawled 5293 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:49:37 [scrapy.extensions.logstats] INFO: Crawled 5297 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:50:45 [scrapy.extensions.logstats] INFO: Crawled 5301 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:51:31 [scrapy.extensions.logstats] INFO: Crawled 5304 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:52:37 [scrapy.extensions.logstats] INFO: Crawled 5308 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:53:43 [scrapy.extensions.logstats] INFO: Crawled 5312 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:54:36 [scrapy.extensions.logstats] INFO: Crawled 5315 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:55:40 [scrapy.extensions.logstats] INFO: Crawled 5319 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:56:32 [scrapy.extensions.logstats] INFO: Crawled 5325 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:57:07 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://da.cybexintl.com/robots.txt>: User timeout caused connection failure.
twisted.internet.error.TimeoutError: User timeout caused connection failure.
2019-11-09 04:57:42 [scrapy.extensions.logstats] INFO: Crawled 5328 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:58:35 [scrapy.extensions.logstats] INFO: Crawled 5331 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 04:59:41 [scrapy.extensions.logstats] INFO: Crawled 5337 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 05:00:51 [scrapy.extensions.logstats] INFO: Crawled 5341 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 05:02:00 [scrapy.extensions.logstats] INFO: Crawled 5342 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 05:02:33 [scrapy.extensions.logstats] INFO: Crawled 5346 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 05:04:02 [scrapy.extensions.logstats] INFO: Crawled 5352 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 05:04:37 [scrapy.extensions.logstats] INFO: Crawled 5353 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 05:05:30 [scrapy.extensions.logstats] INFO: Crawled 5354 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 05:06:38 [scrapy.extensions.logstats] INFO: Crawled 5358 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 05:07:32 [scrapy.extensions.logstats] INFO: Crawled 5361 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 05:09:03 [scrapy.extensions.logstats] INFO: Crawled 5369 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 05:09:37 [scrapy.extensions.logstats] INFO: Crawled 5371 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 05:10:44 [scrapy.extensions.logstats] INFO: Crawled 5373 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 05:11:36 [scrapy.extensions.logstats] INFO: Crawled 5376 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 05:12:32 [scrapy.extensions.logstats] INFO: Crawled 5378 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 05:13:32 [scrapy.extensions.logstats] INFO: Crawled 5383 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 05:14:36 [scrapy.extensions.logstats] INFO: Crawled 5389 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 05:15:42 [scrapy.extensions.logstats] INFO: Crawled 5393 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 05:16:49 [scrapy.extensions.logstats] INFO: Crawled 5395 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 05:17:38 [scrapy.extensions.logstats] INFO: Crawled 5397 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 05:18:47 [scrapy.extensions.logstats] INFO: Crawled 5402 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 05:19:58 [scrapy.extensions.logstats] INFO: Crawled 5407 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 05:20:43 [scrapy.extensions.logstats] INFO: Crawled 5410 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 05:21:37 [scrapy.extensions.logstats] INFO: Crawled 5412 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 05:22:42 [scrapy.extensions.logstats] INFO: Crawled 5415 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 05:23:33 [scrapy.extensions.logstats] INFO: Crawled 5421 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 05:24:42 [scrapy.extensions.logstats] INFO: Crawled 5425 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 05:25:49 [scrapy.extensions.logstats] INFO: Crawled 5429 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 05:26:58 [scrapy.extensions.logstats] INFO: Crawled 5429 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 05:27:45 [scrapy.extensions.logstats] INFO: Crawled 5444 pages (at 15 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 05:29:08 [scrapy.extensions.logstats] INFO: Crawled 5444 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 05:30:34 [scrapy.extensions.logstats] INFO: Crawled 5444 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 05:31:47 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://wwww.dermaflash.com/robots.txt>: DNS lookup failed: no results for hostname lookup: wwww.dermaflash.com.
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: wwww.dermaflash.com.
2019-11-09 05:31:47 [scrapy.extensions.logstats] INFO: Crawled 5452 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 05:33:01 [scrapy.extensions.logstats] INFO: Crawled 5460 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 05:34:12 [scrapy.extensions.logstats] INFO: Crawled 5460 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 05:35:18 [scrapy.extensions.logstats] INFO: Crawled 5460 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 05:35:47 [scrapy.extensions.logstats] INFO: Crawled 5469 pages (at 9 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 05:36:40 [scrapy.extensions.logstats] INFO: Crawled 5473 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 05:37:51 [scrapy.extensions.logstats] INFO: Crawled 5477 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 05:38:57 [scrapy.extensions.logstats] INFO: Crawled 5477 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 05:40:10 [scrapy.extensions.logstats] INFO: Crawled 5477 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 05:40:43 [scrapy.extensions.logstats] INFO: Crawled 5483 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 05:41:51 [scrapy.extensions.logstats] INFO: Crawled 5486 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 05:42:43 [scrapy.extensions.logstats] INFO: Crawled 5486 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 05:43:49 [scrapy.extensions.logstats] INFO: Crawled 5498 pages (at 12 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 05:45:02 [scrapy.extensions.logstats] INFO: Crawled 5498 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 05:46:17 [scrapy.extensions.logstats] INFO: Crawled 5498 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 05:46:36 [scrapy.extensions.logstats] INFO: Crawled 5501 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 05:47:54 [scrapy.extensions.logstats] INFO: Crawled 5503 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 05:48:32 [scrapy.extensions.logstats] INFO: Crawled 5509 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 05:49:48 [scrapy.extensions.logstats] INFO: Crawled 5514 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 05:51:23 [scrapy.extensions.logstats] INFO: Crawled 5517 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 05:51:59 [scrapy.extensions.logstats] INFO: Crawled 5519 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 05:52:43 [scrapy.extensions.logstats] INFO: Crawled 5522 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 05:53:39 [scrapy.extensions.logstats] INFO: Crawled 5522 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 05:54:35 [scrapy.extensions.logstats] INFO: Crawled 5526 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 05:55:46 [scrapy.extensions.logstats] INFO: Crawled 5530 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 05:56:40 [scrapy.extensions.logstats] INFO: Crawled 5536 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 05:57:55 [scrapy.extensions.logstats] INFO: Crawled 5540 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 05:58:31 [scrapy.extensions.logstats] INFO: Crawled 5540 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 05:59:48 [scrapy.extensions.logstats] INFO: Crawled 5545 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:00:47 [scrapy.extensions.logstats] INFO: Crawled 5545 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:01:42 [scrapy.extensions.logstats] INFO: Crawled 5554 pages (at 9 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:02:39 [scrapy.extensions.logstats] INFO: Crawled 5557 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:03:33 [scrapy.extensions.logstats] INFO: Crawled 5557 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:04:31 [scrapy.extensions.logstats] INFO: Crawled 5557 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:06:04 [scrapy.extensions.logstats] INFO: Crawled 5565 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:06:55 [scrapy.extensions.logstats] INFO: Crawled 5565 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:08:13 [scrapy.extensions.logstats] INFO: Crawled 5572 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:08:41 [scrapy.extensions.logstats] INFO: Crawled 5572 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:09:31 [scrapy.extensions.logstats] INFO: Crawled 5576 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:10:44 [scrapy.extensions.logstats] INFO: Crawled 5581 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:11:43 [scrapy.extensions.logstats] INFO: Crawled 5584 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:12:38 [scrapy.extensions.logstats] INFO: Crawled 5588 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:13:36 [scrapy.extensions.logstats] INFO: Crawled 5591 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:14:38 [scrapy.extensions.logstats] INFO: Crawled 5596 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:15:32 [scrapy.extensions.logstats] INFO: Crawled 5601 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:16:35 [scrapy.extensions.logstats] INFO: Crawled 5603 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:17:30 [scrapy.extensions.logstats] INFO: Crawled 5607 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:18:37 [scrapy.extensions.logstats] INFO: Crawled 5611 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:19:31 [scrapy.extensions.logstats] INFO: Crawled 5617 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:20:40 [scrapy.extensions.logstats] INFO: Crawled 5622 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:21:49 [scrapy.extensions.logstats] INFO: Crawled 5625 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:22:46 [scrapy.extensions.logstats] INFO: Crawled 5627 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:24:06 [scrapy.extensions.logstats] INFO: Crawled 5635 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:24:35 [scrapy.extensions.logstats] INFO: Crawled 5637 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:25:31 [scrapy.extensions.logstats] INFO: Crawled 5637 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:25:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cybexintl.com/products/pwrplay/attached-high-low.aspx?err=ctrl-not-found>: User timeout caused connection failure.
2019-11-09 06:26:41 [scrapy.extensions.logstats] INFO: Crawled 5644 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:27:37 [scrapy.extensions.logstats] INFO: Crawled 5648 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:28:35 [scrapy.extensions.logstats] INFO: Crawled 5649 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:29:48 [scrapy.extensions.logstats] INFO: Crawled 5655 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:30:45 [scrapy.extensions.logstats] INFO: Crawled 5658 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:31:39 [scrapy.extensions.logstats] INFO: Crawled 5659 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:31:58 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET https://asmodee.helpshift.com/robots.txt>: User timeout caused connection failure.
twisted.internet.error.TimeoutError: User timeout caused connection failure.
2019-11-09 06:32:35 [scrapy.extensions.logstats] INFO: Crawled 5664 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:33:45 [scrapy.extensions.logstats] INFO: Crawled 5666 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:34:44 [scrapy.extensions.logstats] INFO: Crawled 5670 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:35:40 [scrapy.extensions.logstats] INFO: Crawled 5673 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:35:56 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET https://account.asmodee.net/robots.txt>: User timeout caused connection failure: Getting https://account.asmodee.net/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://account.asmodee.net/robots.txt took longer than 15.0 seconds..
2019-11-09 06:36:14 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET https://warranty.dacor.com/robots.txt>: User timeout caused connection failure: Getting https://warranty.dacor.com/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://warranty.dacor.com/robots.txt took longer than 15.0 seconds..
2019-11-09 06:36:51 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET https://rebate.dacor.com/robots.txt>: User timeout caused connection failure: Getting https://rebate.dacor.com/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://rebate.dacor.com/robots.txt took longer than 15.0 seconds..
2019-11-09 06:36:51 [scrapy.extensions.logstats] INFO: Crawled 5677 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:37:47 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://dacor.com/robots.txt>: User timeout caused connection failure: Getting http://dacor.com/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://dacor.com/robots.txt took longer than 15.0 seconds..
2019-11-09 06:37:47 [scrapy.extensions.logstats] INFO: Crawled 5680 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:38:38 [scrapy.extensions.logstats] INFO: Crawled 5685 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:39:14 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.dacor.com>: User timeout caused connection failure.
2019-11-09 06:39:31 [scrapy.extensions.logstats] INFO: Crawled 5686 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:41:20 [scrapy.extensions.logstats] INFO: Crawled 5695 pages (at 9 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:41:57 [scrapy.extensions.logstats] INFO: Crawled 5697 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:42:35 [scrapy.extensions.logstats] INFO: Crawled 5700 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:42:54 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://downloads.contour.com/robots.txt>: User timeout caused connection failure: Getting http://downloads.contour.com/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://downloads.contour.com/robots.txt took longer than 15.0 seconds..
2019-11-09 06:42:54 [scrapy.core.downloader.handlers.http11] ERROR: Cancelling download of http://downloads.contour.com/storyteller/Contour-Storyteller-Installer.dmg: expected response size (23467841) larger than download max size (5242880).
2019-11-09 06:42:54 [scrapy.core.scraper] ERROR: Error downloading <GET http://downloads.contour.com/storyteller/Contour-Storyteller-Installer.dmg>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 343, in _cb_bodyready
    raise defer.CancelledError(error_msg % error_args)
twisted.internet.defer.CancelledError: Cancelling download of http://downloads.contour.com/storyteller/Contour-Storyteller-Installer.dmg: expected response size (23467841) larger than download max size (5242880).
2019-11-09 06:43:52 [scrapy.extensions.logstats] INFO: Crawled 5707 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:44:31 [scrapy.extensions.logstats] INFO: Crawled 5707 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:45:52 [scrapy.extensions.logstats] INFO: Crawled 5717 pages (at 10 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:46:32 [scrapy.extensions.logstats] INFO: Crawled 5718 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:48:01 [scrapy.extensions.logstats] INFO: Crawled 5728 pages (at 10 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:49:00 [scrapy.extensions.logstats] INFO: Crawled 5730 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:49:39 [scrapy.extensions.logstats] INFO: Crawled 5731 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:50:31 [scrapy.extensions.logstats] INFO: Crawled 5734 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:51:43 [scrapy.extensions.logstats] INFO: Crawled 5738 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:52:40 [scrapy.extensions.logstats] INFO: Crawled 5741 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:53:36 [scrapy.extensions.logstats] INFO: Crawled 5744 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:54:33 [scrapy.extensions.logstats] INFO: Crawled 5747 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:56:02 [scrapy.extensions.logstats] INFO: Crawled 5757 pages (at 10 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:56:31 [scrapy.extensions.logstats] INFO: Crawled 5760 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:57:30 [scrapy.extensions.logstats] INFO: Crawled 5766 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:58:34 [scrapy.extensions.logstats] INFO: Crawled 5772 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 06:59:34 [scrapy.extensions.logstats] INFO: Crawled 5778 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 07:00:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.dacor.com/about-us/news-room/kbis-2019>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.dacor.com/about-us/news-room/kbis-2019 took longer than 15.0 seconds..
2019-11-09 07:00:46 [scrapy.extensions.logstats] INFO: Crawled 5778 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 07:00:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.dacor.com/about-us/news-room/national-kitchen-design-contest>: User timeout caused connection failure.
2019-11-09 07:01:56 [scrapy.extensions.logstats] INFO: Crawled 5786 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 07:02:34 [scrapy.extensions.logstats] INFO: Crawled 5786 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 07:04:47 [scrapy.extensions.logstats] INFO: Crawled 5795 pages (at 9 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 07:05:44 [scrapy.extensions.logstats] INFO: Crawled 5797 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 07:07:01 [scrapy.extensions.logstats] INFO: Crawled 5800 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 07:07:41 [scrapy.extensions.logstats] INFO: Crawled 5802 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 07:08:31 [scrapy.extensions.logstats] INFO: Crawled 5807 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 07:09:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://cnd.com/pro-products/enhancements/liquid-powder-system/sealebond>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://cnd.com/pro-products/enhancements/liquid-powder-system/sealebond took longer than 15.0 seconds..
2019-11-09 07:09:54 [scrapy.extensions.logstats] INFO: Crawled 5811 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 07:10:35 [scrapy.extensions.logstats] INFO: Crawled 5826 pages (at 15 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 07:12:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.daysofwonder.com/findplayers/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.daysofwonder.com/findplayers/ took longer than 15.0 seconds..
2019-11-09 07:12:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://account.asmodee.net/profile/subscriptions>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://account.asmodee.net/profile/subscriptions took longer than 15.0 seconds..
2019-11-09 07:12:25 [scrapy.extensions.logstats] INFO: Crawled 5829 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 07:13:07 [scrapy.core.scraper] ERROR: Error downloading <GET https://account.asmodee.net/profile/password>: User timeout caused connection failure.
2019-11-09 07:13:07 [scrapy.extensions.logstats] INFO: Crawled 5831 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 07:13:35 [scrapy.extensions.logstats] INFO: Crawled 5837 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 07:14:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://steamcommunity.com/openid/login?openid.ns=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0&openid.mode=checkid_setup&openid.return_to=https%3A%2F%2Fwww.daysofwonder.com%2F%2Fsignup%2Fsteam_ok%3Freturnto%3D%252Fshadowsovercamelot%252Fen%252F&openid.realm=https%3A%2F%2Fwww.daysofwonder.com&openid.ns.sreg=http%3A%2F%2Fopenid.net%2Fextensions%2Fsreg%2F1.1&openid.claimed_id=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0%2Fidentifier_select&openid.identity=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0%2Fidentifier_select>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://steamcommunity.com/openid/login?openid.ns=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0&openid.mode=checkid_setup&openid.return_to=https%3A%2F%2Fwww.daysofwonder.com%2F%2Fsignup%2Fsteam_ok%3Freturnto%3D%252Fshadowsovercamelot%252Fen%252F&openid.realm=https%3A%2F%2Fwww.daysofwonder.com&openid.ns.sreg=http%3A%2F%2Fopenid.net%2Fextensions%2Fsreg%2F1.1&openid.claimed_id=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0%2Fidentifier_select&openid.identity=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0%2Fidentifier_select took longer than 15.0 seconds..
2019-11-09 07:14:57 [scrapy.extensions.logstats] INFO: Crawled 5840 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 07:15:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.daysofwonder.com/en/signup/steam?returnto=%2Fen%2Fdow-account%2F>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.daysofwonder.com/en/signup/steam?returnto=%2Fen%2Fdow-account%2F took longer than 15.0 seconds..
2019-11-09 07:15:38 [scrapy.extensions.logstats] INFO: Crawled 5840 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 07:15:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.daysofwonder.com/en/login?returnto=myprofile>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.daysofwonder.com/en/login?returnto=myprofile took longer than 15.0 seconds..
2019-11-09 07:17:02 [scrapy.extensions.logstats] INFO: Crawled 5855 pages (at 15 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 07:17:44 [scrapy.extensions.logstats] INFO: Crawled 5858 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 07:18:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.daysofwonder.com/en/store/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.daysofwonder.com/en/store/ took longer than 15.0 seconds..
2019-11-09 07:19:07 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.daysofwonder.com/en/about/distribution/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.daysofwonder.com/en/about/distribution/ took longer than 15.0 seconds..
2019-11-09 07:19:07 [scrapy.extensions.logstats] INFO: Crawled 5858 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 07:19:07 [scrapy.core.scraper] ERROR: Error downloading <GET https://account.asmodee.net/en/profile/identity>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://account.asmodee.net/en/profile/identity took longer than 15.0 seconds..
2019-11-09 07:19:35 [scrapy.extensions.logstats] INFO: Crawled 5869 pages (at 11 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 07:21:26 [scrapy.extensions.logstats] INFO: Crawled 5877 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 07:22:26 [scrapy.extensions.logstats] INFO: Crawled 5880 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 07:23:25 [scrapy.extensions.logstats] INFO: Crawled 5880 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 07:24:11 [scrapy.extensions.logstats] INFO: Crawled 5880 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 07:24:11 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://education.dermalogica.com/robots.txt>: User timeout caused connection failure: Getting http://education.dermalogica.com/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://education.dermalogica.com/robots.txt took longer than 15.0 seconds..
2019-11-09 07:24:11 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET https://service.dermalogica.com/robots.txt>: User timeout caused connection failure.
twisted.internet.error.TimeoutError: User timeout caused connection failure.
2019-11-09 07:24:40 [scrapy.extensions.logstats] INFO: Crawled 5890 pages (at 10 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 07:25:40 [scrapy.extensions.logstats] INFO: Crawled 5894 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 07:26:46 [scrapy.extensions.logstats] INFO: Crawled 5894 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 07:28:08 [scrapy.extensions.logstats] INFO: Crawled 5898 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 07:29:21 [scrapy.extensions.logstats] INFO: Crawled 5902 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 07:30:41 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://ir.comstockcompanies.com/resources/contacts/tel:7032301985>: HTTP status code is not handled or not allowed
2019-11-09 07:30:41 [scrapy.extensions.logstats] INFO: Crawled 5906 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 07:31:37 [scrapy.extensions.logstats] INFO: Crawled 5910 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 07:32:52 [scrapy.extensions.logstats] INFO: Crawled 5914 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 07:34:10 [scrapy.extensions.logstats] INFO: Crawled 5914 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 07:35:44 [scrapy.extensions.logstats] INFO: Crawled 5923 pages (at 9 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 07:37:02 [scrapy.extensions.logstats] INFO: Crawled 5927 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 07:37:58 [scrapy.extensions.logstats] INFO: Crawled 5930 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 07:38:40 [scrapy.extensions.logstats] INFO: Crawled 5933 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 07:39:31 [scrapy.extensions.logstats] INFO: Crawled 5936 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 07:40:42 [scrapy.extensions.logstats] INFO: Crawled 5942 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 07:41:52 [scrapy.extensions.logstats] INFO: Crawled 5942 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 07:42:34 [scrapy.extensions.logstats] INFO: Crawled 5951 pages (at 9 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 07:43:59 [scrapy.extensions.logstats] INFO: Crawled 5958 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 07:44:56 [scrapy.extensions.logstats] INFO: Crawled 5962 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 07:45:38 [scrapy.extensions.logstats] INFO: Crawled 5965 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 07:46:34 [scrapy.extensions.logstats] INFO: Crawled 5965 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 07:47:41 [scrapy.extensions.logstats] INFO: Crawled 5969 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 07:48:45 [scrapy.extensions.logstats] INFO: Crawled 5976 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 07:50:03 [scrapy.extensions.logstats] INFO: Crawled 5979 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 07:50:52 [scrapy.extensions.logstats] INFO: Crawled 5979 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 07:51:35 [scrapy.extensions.logstats] INFO: Crawled 5979 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 07:52:59 [scrapy.extensions.logstats] INFO: Crawled 5990 pages (at 11 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 07:54:19 [scrapy.extensions.logstats] INFO: Crawled 5994 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 07:55:03 [scrapy.extensions.logstats] INFO: Crawled 5994 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 07:55:32 [scrapy.extensions.logstats] INFO: Crawled 5994 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 07:56:44 [scrapy.extensions.logstats] INFO: Crawled 6000 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 07:57:41 [scrapy.extensions.logstats] INFO: Crawled 6006 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 07:58:39 [scrapy.extensions.logstats] INFO: Crawled 6010 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 07:59:50 [scrapy.extensions.logstats] INFO: Crawled 6015 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:00:33 [scrapy.extensions.logstats] INFO: Crawled 6018 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:01:58 [scrapy.extensions.logstats] INFO: Crawled 6024 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:02:41 [scrapy.extensions.logstats] INFO: Crawled 6027 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:03:38 [scrapy.extensions.logstats] INFO: Crawled 6028 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:04:51 [scrapy.extensions.logstats] INFO: Crawled 6038 pages (at 10 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:06:11 [scrapy.extensions.logstats] INFO: Crawled 6043 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:06:49 [scrapy.extensions.logstats] INFO: Crawled 6043 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:07:40 [scrapy.extensions.logstats] INFO: Crawled 6045 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:09:18 [scrapy.extensions.logstats] INFO: Crawled 6050 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:09:59 [scrapy.extensions.logstats] INFO: Crawled 6053 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:10:58 [scrapy.extensions.logstats] INFO: Crawled 6055 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:11:40 [scrapy.extensions.logstats] INFO: Crawled 6058 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:12:41 [scrapy.extensions.logstats] INFO: Crawled 6060 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:14:25 [scrapy.extensions.logstats] INFO: Crawled 6065 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:15:05 [scrapy.extensions.logstats] INFO: Crawled 6068 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:16:00 [scrapy.extensions.logstats] INFO: Crawled 6070 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:16:44 [scrapy.extensions.logstats] INFO: Crawled 6073 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:17:46 [scrapy.extensions.logstats] INFO: Crawled 6075 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:19:25 [scrapy.extensions.logstats] INFO: Crawled 6080 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:20:08 [scrapy.extensions.logstats] INFO: Crawled 6083 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:21:07 [scrapy.extensions.logstats] INFO: Crawled 6085 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:21:47 [scrapy.extensions.logstats] INFO: Crawled 6088 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:22:54 [scrapy.extensions.logstats] INFO: Crawled 6090 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:24:07 [scrapy.extensions.logstats] INFO: Crawled 6095 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:24:37 [scrapy.extensions.logstats] INFO: Crawled 6098 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:25:48 [scrapy.extensions.logstats] INFO: Crawled 6105 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:26:32 [scrapy.extensions.logstats] INFO: Crawled 6107 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:27:30 [scrapy.extensions.logstats] INFO: Crawled 6107 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:28:38 [scrapy.extensions.logstats] INFO: Crawled 6116 pages (at 9 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:29:36 [scrapy.extensions.logstats] INFO: Crawled 6119 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:30:32 [scrapy.extensions.logstats] INFO: Crawled 6119 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:31:31 [scrapy.extensions.logstats] INFO: Crawled 6119 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:32:51 [scrapy.extensions.logstats] INFO: Crawled 6126 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:33:56 [scrapy.extensions.logstats] INFO: Crawled 6126 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:34:37 [scrapy.extensions.logstats] INFO: Crawled 6131 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:35:35 [scrapy.extensions.logstats] INFO: Crawled 6136 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:37:23 [scrapy.extensions.logstats] INFO: Crawled 6138 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:38:11 [scrapy.extensions.logstats] INFO: Crawled 6138 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:38:47 [scrapy.extensions.logstats] INFO: Crawled 6143 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:39:49 [scrapy.extensions.logstats] INFO: Crawled 6145 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:40:30 [scrapy.extensions.logstats] INFO: Crawled 6147 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:41:34 [scrapy.extensions.logstats] INFO: Crawled 6149 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:42:35 [scrapy.extensions.logstats] INFO: Crawled 6154 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:43:16 [scrapy.core.scraper] ERROR: Spider error processing <GET http://tech.d-box.com?wpdmdl=22325> (referer: http://tech.d-box.com/corporate-page/investors-information/)
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\root\Desktop\GitHub\innovScraping\innovationScraping\innovScrapyTools\innovScrapyCode\spiders\customized_web_crawler.py", line 67, in parse_item
    insert_into_mongo(response.url, response.text, self.coll)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\http\response\__init__.py", line 93, in text
    raise AttributeError("Response content isn't text")
AttributeError: Response content isn't text
2019-11-09 08:43:56 [scrapy.extensions.logstats] INFO: Crawled 6158 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:44:33 [scrapy.extensions.logstats] INFO: Crawled 6160 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:45:35 [scrapy.extensions.logstats] INFO: Crawled 6164 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:46:38 [scrapy.extensions.logstats] INFO: Crawled 6164 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:46:52 [scrapy.core.scraper] ERROR: Spider error processing <GET http://tech.d-box.com?wpdmdl=23223> (referer: http://tech.d-box.com/corporate-page/investors-information/)
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\root\Desktop\GitHub\innovScraping\innovationScraping\innovScrapyTools\innovScrapyCode\spiders\customized_web_crawler.py", line 67, in parse_item
    insert_into_mongo(response.url, response.text, self.coll)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\http\response\__init__.py", line 93, in text
    raise AttributeError("Response content isn't text")
AttributeError: Response content isn't text
2019-11-09 08:47:51 [scrapy.extensions.logstats] INFO: Crawled 6176 pages (at 12 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:48:06 [scrapy.core.scraper] ERROR: Spider error processing <GET http://tech.d-box.com?wpdmdl=7035> (referer: http://tech.d-box.com/corporate-page/investors-information/)
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\root\Desktop\GitHub\innovScraping\innovationScraping\innovScrapyTools\innovScrapyCode\spiders\customized_web_crawler.py", line 67, in parse_item
    insert_into_mongo(response.url, response.text, self.coll)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\http\response\__init__.py", line 93, in text
    raise AttributeError("Response content isn't text")
AttributeError: Response content isn't text
2019-11-09 08:49:06 [scrapy.extensions.logstats] INFO: Crawled 6181 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:49:50 [scrapy.extensions.logstats] INFO: Crawled 6181 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:50:34 [scrapy.extensions.logstats] INFO: Crawled 6185 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:50:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://tech.d-box.com?wpdmdl=7053> (referer: http://tech.d-box.com/corporate-page/investors-information/)
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\root\Desktop\GitHub\innovScraping\innovationScraping\innovScrapyTools\innovScrapyCode\spiders\customized_web_crawler.py", line 67, in parse_item
    insert_into_mongo(response.url, response.text, self.coll)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\http\response\__init__.py", line 93, in text
    raise AttributeError("Response content isn't text")
AttributeError: Response content isn't text
2019-11-09 08:51:02 [scrapy.core.scraper] ERROR: Spider error processing <GET http://tech.d-box.com?wpdmdl=7055> (referer: http://tech.d-box.com/corporate-page/investors-information/)
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\root\Desktop\GitHub\innovScraping\innovationScraping\innovScrapyTools\innovScrapyCode\spiders\customized_web_crawler.py", line 67, in parse_item
    insert_into_mongo(response.url, response.text, self.coll)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\http\response\__init__.py", line 93, in text
    raise AttributeError("Response content isn't text")
AttributeError: Response content isn't text
2019-11-09 08:51:32 [scrapy.extensions.logstats] INFO: Crawled 6191 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:52:44 [scrapy.extensions.logstats] INFO: Crawled 6196 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:53:56 [scrapy.extensions.logstats] INFO: Crawled 6201 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:54:10 [scrapy.core.scraper] ERROR: Spider error processing <GET http://tech.d-box.com?wpdmdl=7067> (referer: http://tech.d-box.com/corporate-page/investors-information/)
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\root\Desktop\GitHub\innovScraping\innovationScraping\innovScrapyTools\innovScrapyCode\spiders\customized_web_crawler.py", line 67, in parse_item
    insert_into_mongo(response.url, response.text, self.coll)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\http\response\__init__.py", line 93, in text
    raise AttributeError("Response content isn't text")
AttributeError: Response content isn't text
2019-11-09 08:54:51 [scrapy.extensions.logstats] INFO: Crawled 6205 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:55:36 [scrapy.extensions.logstats] INFO: Crawled 6207 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:55:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://tech.d-box.com?wpdmdl=12889> (referer: http://tech.d-box.com/corporate-page/investors-information/)
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\root\Desktop\GitHub\innovScraping\innovationScraping\innovScrapyTools\innovScrapyCode\spiders\customized_web_crawler.py", line 67, in parse_item
    insert_into_mongo(response.url, response.text, self.coll)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\http\response\__init__.py", line 93, in text
    raise AttributeError("Response content isn't text")
AttributeError: Response content isn't text
2019-11-09 08:55:54 [scrapy.core.scraper] ERROR: Spider error processing <GET http://tech.d-box.com?wpdmdl=13073> (referer: http://tech.d-box.com/corporate-page/investors-information/)
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\root\Desktop\GitHub\innovScraping\innovationScraping\innovScrapyTools\innovScrapyCode\spiders\customized_web_crawler.py", line 67, in parse_item
    insert_into_mongo(response.url, response.text, self.coll)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\http\response\__init__.py", line 93, in text
    raise AttributeError("Response content isn't text")
AttributeError: Response content isn't text
2019-11-09 08:55:55 [scrapy.core.scraper] ERROR: Spider error processing <GET http://tech.d-box.com?wpdmdl=13120> (referer: http://tech.d-box.com/corporate-page/investors-information/)
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\root\Desktop\GitHub\innovScraping\innovationScraping\innovScrapyTools\innovScrapyCode\spiders\customized_web_crawler.py", line 67, in parse_item
    insert_into_mongo(response.url, response.text, self.coll)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\http\response\__init__.py", line 93, in text
    raise AttributeError("Response content isn't text")
AttributeError: Response content isn't text
2019-11-09 08:55:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://tech.d-box.com?wpdmdl=13281> (referer: http://tech.d-box.com/corporate-page/investors-information/)
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\root\Desktop\GitHub\innovScraping\innovationScraping\innovScrapyTools\innovScrapyCode\spiders\customized_web_crawler.py", line 67, in parse_item
    insert_into_mongo(response.url, response.text, self.coll)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\http\response\__init__.py", line 93, in text
    raise AttributeError("Response content isn't text")
AttributeError: Response content isn't text
2019-11-09 08:55:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://tech.d-box.com?wpdmdl=13305> (referer: http://tech.d-box.com/corporate-page/investors-information/)
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\root\Desktop\GitHub\innovScraping\innovationScraping\innovScrapyTools\innovScrapyCode\spiders\customized_web_crawler.py", line 67, in parse_item
    insert_into_mongo(response.url, response.text, self.coll)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\http\response\__init__.py", line 93, in text
    raise AttributeError("Response content isn't text")
AttributeError: Response content isn't text
2019-11-09 08:56:31 [scrapy.extensions.logstats] INFO: Crawled 6214 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:56:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://tech.d-box.com?wpdmdl=13523> (referer: http://tech.d-box.com/corporate-page/investors-information/)
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\root\Desktop\GitHub\innovScraping\innovationScraping\innovScrapyTools\innovScrapyCode\spiders\customized_web_crawler.py", line 67, in parse_item
    insert_into_mongo(response.url, response.text, self.coll)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\http\response\__init__.py", line 93, in text
    raise AttributeError("Response content isn't text")
AttributeError: Response content isn't text
2019-11-09 08:56:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://tech.d-box.com?wpdmdl=19102> (referer: http://tech.d-box.com/corporate-page/investors-information/)
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\root\Desktop\GitHub\innovScraping\innovationScraping\innovScrapyTools\innovScrapyCode\spiders\customized_web_crawler.py", line 67, in parse_item
    insert_into_mongo(response.url, response.text, self.coll)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\http\response\__init__.py", line 93, in text
    raise AttributeError("Response content isn't text")
AttributeError: Response content isn't text
2019-11-09 08:56:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://tech.d-box.com?wpdmdl=16214> (referer: http://tech.d-box.com/corporate-page/investors-information/)
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\root\Desktop\GitHub\innovScraping\innovationScraping\innovScrapyTools\innovScrapyCode\spiders\customized_web_crawler.py", line 67, in parse_item
    insert_into_mongo(response.url, response.text, self.coll)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\http\response\__init__.py", line 93, in text
    raise AttributeError("Response content isn't text")
AttributeError: Response content isn't text
2019-11-09 08:57:05 [scrapy.core.scraper] ERROR: Spider error processing <GET http://tech.d-box.com?wpdmdl=16324> (referer: http://tech.d-box.com/corporate-page/investors-information/)
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\root\Desktop\GitHub\innovScraping\innovationScraping\innovScrapyTools\innovScrapyCode\spiders\customized_web_crawler.py", line 67, in parse_item
    insert_into_mongo(response.url, response.text, self.coll)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\http\response\__init__.py", line 93, in text
    raise AttributeError("Response content isn't text")
AttributeError: Response content isn't text
2019-11-09 08:57:32 [scrapy.extensions.logstats] INFO: Crawled 6222 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:57:32 [scrapy.core.scraper] ERROR: Spider error processing <GET http://tech.d-box.com?wpdmdl=18005> (referer: http://tech.d-box.com/corporate-page/investors-information/)
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\root\Desktop\GitHub\innovScraping\innovationScraping\innovScrapyTools\innovScrapyCode\spiders\customized_web_crawler.py", line 67, in parse_item
    insert_into_mongo(response.url, response.text, self.coll)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\http\response\__init__.py", line 93, in text
    raise AttributeError("Response content isn't text")
AttributeError: Response content isn't text
2019-11-09 08:57:32 [scrapy.core.scraper] ERROR: Spider error processing <GET http://tech.d-box.com?wpdmdl=19097> (referer: http://tech.d-box.com/corporate-page/investors-information/)
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\root\Desktop\GitHub\innovScraping\innovationScraping\innovScrapyTools\innovScrapyCode\spiders\customized_web_crawler.py", line 67, in parse_item
    insert_into_mongo(response.url, response.text, self.coll)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\http\response\__init__.py", line 93, in text
    raise AttributeError("Response content isn't text")
AttributeError: Response content isn't text
2019-11-09 08:57:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://tech.d-box.com?wpdmdl=18505> (referer: http://tech.d-box.com/corporate-page/investors-information/)
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\root\Desktop\GitHub\innovScraping\innovationScraping\innovScrapyTools\innovScrapyCode\spiders\customized_web_crawler.py", line 67, in parse_item
    insert_into_mongo(response.url, response.text, self.coll)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\http\response\__init__.py", line 93, in text
    raise AttributeError("Response content isn't text")
AttributeError: Response content isn't text
2019-11-09 08:58:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://tech.d-box.com?wpdmdl=18689> (referer: http://tech.d-box.com/corporate-page/investors-information/)
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\root\Desktop\GitHub\innovScraping\innovationScraping\innovScrapyTools\innovScrapyCode\spiders\customized_web_crawler.py", line 67, in parse_item
    insert_into_mongo(response.url, response.text, self.coll)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\http\response\__init__.py", line 93, in text
    raise AttributeError("Response content isn't text")
AttributeError: Response content isn't text
2019-11-09 08:58:13 [scrapy.core.scraper] ERROR: Spider error processing <GET http://tech.d-box.com?wpdmdl=18716> (referer: http://tech.d-box.com/corporate-page/investors-information/)
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\root\Desktop\GitHub\innovScraping\innovationScraping\innovScrapyTools\innovScrapyCode\spiders\customized_web_crawler.py", line 67, in parse_item
    insert_into_mongo(response.url, response.text, self.coll)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\http\response\__init__.py", line 93, in text
    raise AttributeError("Response content isn't text")
AttributeError: Response content isn't text
2019-11-09 08:58:16 [scrapy.core.scraper] ERROR: Spider error processing <GET http://tech.d-box.com?wpdmdl=18783> (referer: http://tech.d-box.com/corporate-page/investors-information/)
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\root\Desktop\GitHub\innovScraping\innovationScraping\innovScrapyTools\innovScrapyCode\spiders\customized_web_crawler.py", line 67, in parse_item
    insert_into_mongo(response.url, response.text, self.coll)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\http\response\__init__.py", line 93, in text
    raise AttributeError("Response content isn't text")
AttributeError: Response content isn't text
2019-11-09 08:58:30 [scrapy.extensions.logstats] INFO: Crawled 6230 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:58:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://tech.d-box.com?wpdmdl=19066> (referer: http://tech.d-box.com/corporate-page/investors-information/)
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\root\Desktop\GitHub\innovScraping\innovationScraping\innovScrapyTools\innovScrapyCode\spiders\customized_web_crawler.py", line 67, in parse_item
    insert_into_mongo(response.url, response.text, self.coll)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\http\response\__init__.py", line 93, in text
    raise AttributeError("Response content isn't text")
AttributeError: Response content isn't text
2019-11-09 08:58:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://tech.d-box.com?wpdmdl=18952> (referer: http://tech.d-box.com/corporate-page/investors-information/)
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\root\Desktop\GitHub\innovScraping\innovationScraping\innovScrapyTools\innovScrapyCode\spiders\customized_web_crawler.py", line 67, in parse_item
    insert_into_mongo(response.url, response.text, self.coll)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\http\response\__init__.py", line 93, in text
    raise AttributeError("Response content isn't text")
AttributeError: Response content isn't text
2019-11-09 08:58:54 [scrapy.core.scraper] ERROR: Spider error processing <GET http://tech.d-box.com?wpdmdl=18967> (referer: http://tech.d-box.com/corporate-page/investors-information/)
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\root\Desktop\GitHub\innovScraping\innovationScraping\innovScrapyTools\innovScrapyCode\spiders\customized_web_crawler.py", line 67, in parse_item
    insert_into_mongo(response.url, response.text, self.coll)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\http\response\__init__.py", line 93, in text
    raise AttributeError("Response content isn't text")
AttributeError: Response content isn't text
2019-11-09 08:58:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://tech.d-box.com?wpdmdl=18998> (referer: http://tech.d-box.com/corporate-page/investors-information/)
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\root\Desktop\GitHub\innovScraping\innovationScraping\innovScrapyTools\innovScrapyCode\spiders\customized_web_crawler.py", line 67, in parse_item
    insert_into_mongo(response.url, response.text, self.coll)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\http\response\__init__.py", line 93, in text
    raise AttributeError("Response content isn't text")
AttributeError: Response content isn't text
2019-11-09 08:59:31 [scrapy.extensions.logstats] INFO: Crawled 6237 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 08:59:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://tech.d-box.com?wpdmdl=19058> (referer: http://tech.d-box.com/corporate-page/investors-information/)
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\root\Desktop\GitHub\innovScraping\innovationScraping\innovScrapyTools\innovScrapyCode\spiders\customized_web_crawler.py", line 67, in parse_item
    insert_into_mongo(response.url, response.text, self.coll)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\http\response\__init__.py", line 93, in text
    raise AttributeError("Response content isn't text")
AttributeError: Response content isn't text
2019-11-09 08:59:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://tech.d-box.com?wpdmdl=19085> (referer: http://tech.d-box.com/corporate-page/investors-information/)
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\root\Desktop\GitHub\innovScraping\innovationScraping\innovScrapyTools\innovScrapyCode\spiders\customized_web_crawler.py", line 67, in parse_item
    insert_into_mongo(response.url, response.text, self.coll)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\http\response\__init__.py", line 93, in text
    raise AttributeError("Response content isn't text")
AttributeError: Response content isn't text
2019-11-09 09:00:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://tech.d-box.com?wpdmdl=19167> (referer: http://tech.d-box.com/corporate-page/investors-information/)
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\root\Desktop\GitHub\innovScraping\innovationScraping\innovScrapyTools\innovScrapyCode\spiders\customized_web_crawler.py", line 67, in parse_item
    insert_into_mongo(response.url, response.text, self.coll)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\http\response\__init__.py", line 93, in text
    raise AttributeError("Response content isn't text")
AttributeError: Response content isn't text
2019-11-09 09:00:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://tech.d-box.com?wpdmdl=19188> (referer: http://tech.d-box.com/corporate-page/investors-information/)
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\root\Desktop\GitHub\innovScraping\innovationScraping\innovScrapyTools\innovScrapyCode\spiders\customized_web_crawler.py", line 67, in parse_item
    insert_into_mongo(response.url, response.text, self.coll)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\http\response\__init__.py", line 93, in text
    raise AttributeError("Response content isn't text")
AttributeError: Response content isn't text
2019-11-09 09:00:20 [scrapy.core.scraper] ERROR: Spider error processing <GET http://tech.d-box.com?wpdmdl=19242> (referer: http://tech.d-box.com/corporate-page/investors-information/)
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\root\Desktop\GitHub\innovScraping\innovationScraping\innovScrapyTools\innovScrapyCode\spiders\customized_web_crawler.py", line 67, in parse_item
    insert_into_mongo(response.url, response.text, self.coll)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\http\response\__init__.py", line 93, in text
    raise AttributeError("Response content isn't text")
AttributeError: Response content isn't text
2019-11-09 09:00:35 [scrapy.extensions.logstats] INFO: Crawled 6245 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 09:00:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://tech.d-box.com?wpdmdl=19271> (referer: http://tech.d-box.com/corporate-page/investors-information/)
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\root\Desktop\GitHub\innovScraping\innovationScraping\innovScrapyTools\innovScrapyCode\spiders\customized_web_crawler.py", line 67, in parse_item
    insert_into_mongo(response.url, response.text, self.coll)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\http\response\__init__.py", line 93, in text
    raise AttributeError("Response content isn't text")
AttributeError: Response content isn't text
2019-11-09 09:01:03 [scrapy.core.scraper] ERROR: Spider error processing <GET http://tech.d-box.com?wpdmdl=19326> (referer: http://tech.d-box.com/corporate-page/investors-information/)
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\root\Desktop\GitHub\innovScraping\innovationScraping\innovScrapyTools\innovScrapyCode\spiders\customized_web_crawler.py", line 67, in parse_item
    insert_into_mongo(response.url, response.text, self.coll)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\http\response\__init__.py", line 93, in text
    raise AttributeError("Response content isn't text")
AttributeError: Response content isn't text
2019-11-09 09:01:34 [scrapy.extensions.logstats] INFO: Crawled 6251 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 09:02:04 [scrapy.core.scraper] ERROR: Spider error processing <GET http://tech.d-box.com?wpdmdl=19539> (referer: http://tech.d-box.com/corporate-page/investors-information/)
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\root\Desktop\GitHub\innovScraping\innovationScraping\innovScrapyTools\innovScrapyCode\spiders\customized_web_crawler.py", line 67, in parse_item
    insert_into_mongo(response.url, response.text, self.coll)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\http\response\__init__.py", line 93, in text
    raise AttributeError("Response content isn't text")
AttributeError: Response content isn't text
2019-11-09 09:02:33 [scrapy.extensions.logstats] INFO: Crawled 6256 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 09:02:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://tech.d-box.com?wpdmdl=19577> (referer: http://tech.d-box.com/corporate-page/investors-information/)
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\root\Desktop\GitHub\innovScraping\innovationScraping\innovScrapyTools\innovScrapyCode\spiders\customized_web_crawler.py", line 67, in parse_item
    insert_into_mongo(response.url, response.text, self.coll)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\http\response\__init__.py", line 93, in text
    raise AttributeError("Response content isn't text")
AttributeError: Response content isn't text
2019-11-09 09:02:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://tech.d-box.com?wpdmdl=19617> (referer: http://tech.d-box.com/corporate-page/investors-information/)
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\root\Desktop\GitHub\innovScraping\innovationScraping\innovScrapyTools\innovScrapyCode\spiders\customized_web_crawler.py", line 67, in parse_item
    insert_into_mongo(response.url, response.text, self.coll)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\http\response\__init__.py", line 93, in text
    raise AttributeError("Response content isn't text")
AttributeError: Response content isn't text
2019-11-09 09:03:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://tech.d-box.com?wpdmdl=19625> (referer: http://tech.d-box.com/corporate-page/investors-information/)
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\root\Desktop\GitHub\innovScraping\innovationScraping\innovScrapyTools\innovScrapyCode\spiders\customized_web_crawler.py", line 67, in parse_item
    insert_into_mongo(response.url, response.text, self.coll)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\http\response\__init__.py", line 93, in text
    raise AttributeError("Response content isn't text")
AttributeError: Response content isn't text
2019-11-09 09:03:34 [scrapy.extensions.logstats] INFO: Crawled 6263 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 09:04:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://tech.d-box.com?wpdmdl=19800> (referer: http://tech.d-box.com/corporate-page/investors-information/)
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\root\Desktop\GitHub\innovScraping\innovationScraping\innovScrapyTools\innovScrapyCode\spiders\customized_web_crawler.py", line 67, in parse_item
    insert_into_mongo(response.url, response.text, self.coll)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\http\response\__init__.py", line 93, in text
    raise AttributeError("Response content isn't text")
AttributeError: Response content isn't text
2019-11-09 09:04:34 [scrapy.extensions.logstats] INFO: Crawled 6270 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 09:05:36 [scrapy.extensions.logstats] INFO: Crawled 6273 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 09:06:52 [scrapy.extensions.logstats] INFO: Crawled 6279 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 09:07:38 [scrapy.extensions.logstats] INFO: Crawled 6281 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 09:08:08 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.dinancars.com/social-media/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.dinancars.com/social-media/ took longer than 15.0 seconds..
2019-11-09 09:08:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://tech.d-box.com?wpdmdl=22159> (referer: http://tech.d-box.com/corporate-page/investors-information/)
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\root\Desktop\GitHub\innovScraping\innovationScraping\innovScrapyTools\innovScrapyCode\spiders\customized_web_crawler.py", line 67, in parse_item
    insert_into_mongo(response.url, response.text, self.coll)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\http\response\__init__.py", line 93, in text
    raise AttributeError("Response content isn't text")
AttributeError: Response content isn't text
2019-11-09 09:08:37 [scrapy.extensions.logstats] INFO: Crawled 6287 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 09:09:37 [scrapy.extensions.logstats] INFO: Crawled 6289 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 09:10:06 [scrapy.core.scraper] ERROR: Spider error processing <GET http://tech.d-box.com?wpdmdl=22218> (referer: http://tech.d-box.com/corporate-page/investors-information/)
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\root\Desktop\GitHub\innovScraping\innovationScraping\innovScrapyTools\innovScrapyCode\spiders\customized_web_crawler.py", line 67, in parse_item
    insert_into_mongo(response.url, response.text, self.coll)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\http\response\__init__.py", line 93, in text
    raise AttributeError("Response content isn't text")
AttributeError: Response content isn't text
2019-11-09 09:10:36 [scrapy.extensions.logstats] INFO: Crawled 6294 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 09:11:35 [scrapy.extensions.logstats] INFO: Crawled 6301 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 09:12:27 [scrapy.core.scraper] ERROR: Spider error processing <GET http://tech.d-box.com?wpdmdl=22898> (referer: http://tech.d-box.com/corporate-page/investors-information/)
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\root\Desktop\GitHub\innovScraping\innovationScraping\innovScrapyTools\innovScrapyCode\spiders\customized_web_crawler.py", line 67, in parse_item
    insert_into_mongo(response.url, response.text, self.coll)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\http\response\__init__.py", line 93, in text
    raise AttributeError("Response content isn't text")
AttributeError: Response content isn't text
2019-11-09 09:12:48 [scrapy.extensions.logstats] INFO: Crawled 6303 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 09:13:46 [scrapy.extensions.logstats] INFO: Crawled 6306 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 09:14:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://tech.d-box.com?wpdmdl=22981> (referer: http://tech.d-box.com/corporate-page/investors-information/)
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\root\Desktop\GitHub\innovScraping\innovationScraping\innovScrapyTools\innovScrapyCode\spiders\customized_web_crawler.py", line 67, in parse_item
    insert_into_mongo(response.url, response.text, self.coll)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\http\response\__init__.py", line 93, in text
    raise AttributeError("Response content isn't text")
AttributeError: Response content isn't text
2019-11-09 09:14:30 [scrapy.extensions.logstats] INFO: Crawled 6311 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 09:15:30 [scrapy.extensions.logstats] INFO: Crawled 6316 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 09:16:01 [scrapy.core.scraper] ERROR: Error downloading <GET https://daymak.com/about.html>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://daymak.com/about.html took longer than 15.0 seconds..
2019-11-09 09:16:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://daymak.com/store-locator.html>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://daymak.com/store-locator.html took longer than 15.0 seconds..
2019-11-09 09:16:26 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://curaegis.com/robots.txt>: User timeout caused connection failure: Getting http://curaegis.com/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://curaegis.com/robots.txt took longer than 15.0 seconds..
2019-11-09 09:16:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://daymak.com/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://daymak.com/ took longer than 15.0 seconds..
2019-11-09 09:16:47 [scrapy.extensions.logstats] INFO: Crawled 6320 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 09:17:50 [scrapy.extensions.logstats] INFO: Crawled 6322 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 09:18:44 [scrapy.extensions.logstats] INFO: Crawled 6328 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 09:19:53 [scrapy.extensions.logstats] INFO: Crawled 6332 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 09:20:31 [scrapy.extensions.logstats] INFO: Crawled 6334 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 09:21:43 [scrapy.extensions.logstats] INFO: Crawled 6334 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 09:23:06 [scrapy.extensions.logstats] INFO: Crawled 6341 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 09:24:12 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET https://investors.crocs.com/robots.txt>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-09 09:24:12 [scrapy.extensions.logstats] INFO: Crawled 6345 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 09:25:40 [scrapy.extensions.logstats] INFO: Crawled 6347 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 09:27:05 [scrapy.extensions.logstats] INFO: Crawled 6350 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 09:27:49 [scrapy.extensions.logstats] INFO: Crawled 6352 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 09:28:31 [scrapy.extensions.logstats] INFO: Crawled 6354 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 09:29:37 [scrapy.extensions.logstats] INFO: Crawled 6358 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 09:30:46 [scrapy.extensions.logstats] INFO: Crawled 6361 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 09:31:49 [scrapy.extensions.logstats] INFO: Crawled 6363 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 09:33:07 [scrapy.extensions.logstats] INFO: Crawled 6367 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 09:33:31 [scrapy.extensions.logstats] INFO: Crawled 6368 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 09:34:35 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/section-16-filings>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/section-16-filings took longer than 15.0 seconds..
2019-11-09 09:34:35 [scrapy.extensions.logstats] INFO: Crawled 6371 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 09:35:37 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/quarterly-reports>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/quarterly-reports took longer than 15.0 seconds..
2019-11-09 09:35:37 [scrapy.extensions.logstats] INFO: Crawled 6374 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 09:35:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/annual-reports>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/annual-reports took longer than 15.0 seconds..
2019-11-09 09:36:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/historical-data>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/historical-data took longer than 15.0 seconds..
2019-11-09 09:36:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/charts>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/charts took longer than 15.0 seconds..
2019-11-09 09:36:39 [scrapy.extensions.logstats] INFO: Crawled 6380 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 09:37:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/financial-results>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/financial-results took longer than 15.0 seconds..
2019-11-09 09:38:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/cash-flow>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/cash-flow took longer than 15.0 seconds..
2019-11-09 09:38:02 [scrapy.extensions.logstats] INFO: Crawled 6380 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 09:38:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/balance-sheet>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/balance-sheet took longer than 15.0 seconds..
2019-11-09 09:38:41 [scrapy.extensions.logstats] INFO: Crawled 6391 pages (at 11 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 09:40:33 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/profile>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/profile took longer than 15.0 seconds..
2019-11-09 09:40:34 [scrapy.extensions.logstats] INFO: Crawled 6391 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 09:41:53 [scrapy.extensions.logstats] INFO: Crawled 6391 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 09:42:37 [scrapy.extensions.logstats] INFO: Crawled 6398 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 09:44:16 [scrapy.extensions.logstats] INFO: Crawled 6399 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 09:44:36 [scrapy.extensions.logstats] INFO: Crawled 6399 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 09:46:01 [scrapy.extensions.logstats] INFO: Crawled 6409 pages (at 10 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 09:46:59 [scrapy.extensions.logstats] INFO: Crawled 6412 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 09:48:06 [scrapy.extensions.logstats] INFO: Crawled 6412 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 09:49:07 [scrapy.extensions.logstats] INFO: Crawled 6412 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 09:49:48 [scrapy.extensions.logstats] INFO: Crawled 6421 pages (at 9 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 09:50:33 [scrapy.extensions.logstats] INFO: Crawled 6424 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 09:52:22 [scrapy.extensions.logstats] INFO: Crawled 6424 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 09:53:26 [scrapy.extensions.logstats] INFO: Crawled 6424 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 09:53:47 [scrapy.extensions.logstats] INFO: Crawled 6428 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 09:54:50 [scrapy.extensions.logstats] INFO: Crawled 6432 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 09:56:16 [scrapy.extensions.logstats] INFO: Crawled 6440 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 09:57:39 [scrapy.extensions.logstats] INFO: Crawled 6440 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 09:59:03 [scrapy.extensions.logstats] INFO: Crawled 6440 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 10:00:06 [scrapy.extensions.logstats] INFO: Crawled 6450 pages (at 10 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 10:00:51 [scrapy.extensions.logstats] INFO: Crawled 6450 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 10:02:36 [scrapy.extensions.logstats] INFO: Crawled 6450 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 10:04:01 [scrapy.extensions.logstats] INFO: Crawled 6461 pages (at 11 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 10:05:07 [scrapy.extensions.logstats] INFO: Crawled 6464 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 10:06:10 [scrapy.extensions.logstats] INFO: Crawled 6464 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 10:07:14 [scrapy.extensions.logstats] INFO: Crawled 6464 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 10:07:37 [scrapy.extensions.logstats] INFO: Crawled 6469 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 10:09:01 [scrapy.extensions.logstats] INFO: Crawled 6479 pages (at 10 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 10:10:47 [scrapy.extensions.logstats] INFO: Crawled 6479 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 10:12:38 [scrapy.extensions.logstats] INFO: Crawled 6479 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 10:14:26 [scrapy.extensions.logstats] INFO: Crawled 6489 pages (at 10 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 10:16:18 [scrapy.extensions.logstats] INFO: Crawled 6489 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 10:16:33 [scrapy.extensions.logstats] INFO: Crawled 6493 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 10:18:47 [scrapy.extensions.logstats] INFO: Crawled 6507 pages (at 14 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 10:19:56 [scrapy.extensions.logstats] INFO: Crawled 6512 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 10:21:11 [scrapy.extensions.logstats] INFO: Crawled 6512 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 10:22:30 [scrapy.extensions.logstats] INFO: Crawled 6512 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 10:24:27 [scrapy.extensions.logstats] INFO: Crawled 6527 pages (at 15 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 10:26:15 [scrapy.extensions.logstats] INFO: Crawled 6527 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 10:28:03 [scrapy.extensions.logstats] INFO: Crawled 6527 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 10:28:45 [scrapy.extensions.logstats] INFO: Crawled 6536 pages (at 9 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 10:29:50 [scrapy.extensions.logstats] INFO: Crawled 6536 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 10:31:16 [scrapy.extensions.logstats] INFO: Crawled 6536 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 10:31:38 [scrapy.extensions.logstats] INFO: Crawled 6541 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 10:33:01 [scrapy.extensions.logstats] INFO: Crawled 6546 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 10:34:50 [scrapy.extensions.logstats] INFO: Crawled 6546 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 10:35:34 [scrapy.extensions.logstats] INFO: Crawled 6556 pages (at 10 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 10:36:40 [scrapy.extensions.logstats] INFO: Crawled 6556 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 10:38:10 [scrapy.extensions.logstats] INFO: Crawled 6556 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 10:38:32 [scrapy.extensions.logstats] INFO: Crawled 6562 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 10:39:52 [scrapy.extensions.logstats] INFO: Crawled 6567 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 10:41:32 [scrapy.extensions.logstats] INFO: Crawled 6567 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 10:43:01 [scrapy.extensions.logstats] INFO: Crawled 6577 pages (at 10 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 10:44:39 [scrapy.extensions.logstats] INFO: Crawled 6577 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 10:46:20 [scrapy.extensions.logstats] INFO: Crawled 6592 pages (at 15 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 10:48:13 [scrapy.extensions.logstats] INFO: Crawled 6592 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 10:50:07 [scrapy.extensions.logstats] INFO: Crawled 6592 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 10:50:32 [scrapy.extensions.logstats] INFO: Crawled 6597 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 10:51:59 [scrapy.extensions.logstats] INFO: Crawled 6601 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 10:53:25 [scrapy.extensions.logstats] INFO: Crawled 6601 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 10:53:47 [scrapy.extensions.logstats] INFO: Crawled 6606 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 10:54:44 [scrapy.extensions.logstats] INFO: Crawled 6614 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 10:56:16 [scrapy.extensions.logstats] INFO: Crawled 6618 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 10:57:26 [scrapy.extensions.logstats] INFO: Crawled 6618 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 10:58:58 [scrapy.extensions.logstats] INFO: Crawled 6618 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 11:00:23 [scrapy.extensions.logstats] INFO: Crawled 6626 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 11:01:24 [scrapy.extensions.logstats] INFO: Crawled 6630 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 11:02:25 [scrapy.extensions.logstats] INFO: Crawled 6634 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 11:03:31 [scrapy.extensions.logstats] INFO: Crawled 6638 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 11:04:56 [scrapy.extensions.logstats] INFO: Crawled 6642 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 11:06:32 [scrapy.extensions.logstats] INFO: Crawled 6645 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 11:08:22 [scrapy.extensions.logstats] INFO: Crawled 6653 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 11:09:24 [scrapy.extensions.logstats] INFO: Crawled 6657 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 11:10:26 [scrapy.extensions.logstats] INFO: Crawled 6661 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 11:11:28 [scrapy.extensions.logstats] INFO: Crawled 6665 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 11:12:30 [scrapy.extensions.logstats] INFO: Crawled 6669 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 11:13:42 [scrapy.extensions.logstats] INFO: Crawled 6673 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 11:15:05 [scrapy.extensions.logstats] INFO: Crawled 6677 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 11:16:36 [scrapy.extensions.logstats] INFO: Crawled 6680 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 11:18:35 [scrapy.extensions.logstats] INFO: Crawled 6686 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 11:20:10 [scrapy.extensions.logstats] INFO: Crawled 6693 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 11:20:58 [scrapy.extensions.logstats] INFO: Crawled 6697 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 11:22:24 [scrapy.extensions.logstats] INFO: Crawled 6705 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 11:23:28 [scrapy.extensions.logstats] INFO: Crawled 6709 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 11:24:54 [scrapy.extensions.logstats] INFO: Crawled 6709 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 11:26:25 [scrapy.extensions.logstats] INFO: Crawled 6709 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 11:26:43 [scrapy.extensions.logstats] INFO: Crawled 6714 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 11:28:09 [scrapy.extensions.logstats] INFO: Crawled 6715 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 11:28:30 [scrapy.extensions.logstats] INFO: Crawled 6715 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 11:29:33 [scrapy.extensions.logstats] INFO: Crawled 6721 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 11:30:40 [scrapy.extensions.logstats] INFO: Crawled 6721 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 11:32:09 [scrapy.extensions.logstats] INFO: Crawled 6730 pages (at 9 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 11:32:57 [scrapy.extensions.logstats] INFO: Crawled 6733 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 11:33:43 [scrapy.extensions.logstats] INFO: Crawled 6735 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 11:35:08 [scrapy.extensions.logstats] INFO: Crawled 6739 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 11:35:54 [scrapy.extensions.logstats] INFO: Crawled 6741 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 11:36:39 [scrapy.extensions.logstats] INFO: Crawled 6743 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 11:37:54 [scrapy.extensions.logstats] INFO: Crawled 6747 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 11:38:36 [scrapy.extensions.logstats] INFO: Crawled 6749 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 11:40:03 [scrapy.extensions.logstats] INFO: Crawled 6753 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 11:40:47 [scrapy.extensions.logstats] INFO: Crawled 6755 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 11:42:13 [scrapy.extensions.logstats] INFO: Crawled 6759 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 11:42:58 [scrapy.extensions.logstats] INFO: Crawled 6761 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 11:43:43 [scrapy.extensions.logstats] INFO: Crawled 6763 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 11:45:12 [scrapy.extensions.logstats] INFO: Crawled 6767 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 11:45:56 [scrapy.extensions.logstats] INFO: Crawled 6769 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 11:46:39 [scrapy.extensions.logstats] INFO: Crawled 6770 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 11:47:48 [scrapy.extensions.logstats] INFO: Crawled 6773 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 11:48:32 [scrapy.extensions.logstats] INFO: Crawled 6777 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 11:49:46 [scrapy.extensions.logstats] INFO: Crawled 6783 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 11:50:57 [scrapy.extensions.logstats] INFO: Crawled 6783 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 11:51:42 [scrapy.extensions.logstats] INFO: Crawled 6787 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 11:53:03 [scrapy.extensions.logstats] INFO: Crawled 6793 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 11:53:41 [scrapy.extensions.logstats] INFO: Crawled 6793 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 11:54:46 [scrapy.extensions.logstats] INFO: Crawled 6801 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 11:55:51 [scrapy.extensions.logstats] INFO: Crawled 6804 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 11:56:33 [scrapy.extensions.logstats] INFO: Crawled 6807 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 11:57:37 [scrapy.extensions.logstats] INFO: Crawled 6807 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 11:58:39 [scrapy.extensions.logstats] INFO: Crawled 6807 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 11:58:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.deltachildren.com/products/sesame-street-deluxe-multi-bin-toy-organizer>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.deltachildren.com/products/sesame-street-deluxe-multi-bin-toy-organizer took longer than 15.0 seconds..
2019-11-09 11:59:46 [scrapy.extensions.logstats] INFO: Crawled 6814 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 12:01:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.deltachildren.com/products/avery-upholstered-glider?variant=15947860995>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.deltachildren.com/products/avery-upholstered-glider?variant=15947860995 took longer than 15.0 seconds..
2019-11-09 12:01:14 [scrapy.extensions.logstats] INFO: Crawled 6814 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 12:01:35 [scrapy.extensions.logstats] INFO: Crawled 6818 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 12:02:41 [scrapy.extensions.logstats] INFO: Crawled 6826 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 12:04:06 [scrapy.extensions.logstats] INFO: Crawled 6826 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 12:05:31 [scrapy.extensions.logstats] INFO: Crawled 6826 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 12:07:00 [scrapy.extensions.logstats] INFO: Crawled 6835 pages (at 9 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 12:08:51 [scrapy.extensions.logstats] INFO: Crawled 6835 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 12:10:43 [scrapy.extensions.logstats] INFO: Crawled 6845 pages (at 10 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 12:12:34 [scrapy.extensions.logstats] INFO: Crawled 6848 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 12:13:39 [scrapy.extensions.logstats] INFO: Crawled 6851 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 12:14:48 [scrapy.extensions.logstats] INFO: Crawled 6854 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 12:15:56 [scrapy.extensions.logstats] INFO: Crawled 6857 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 12:17:06 [scrapy.extensions.logstats] INFO: Crawled 6860 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 12:18:12 [scrapy.extensions.logstats] INFO: Crawled 6863 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 12:19:20 [scrapy.extensions.logstats] INFO: Crawled 6866 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 12:20:26 [scrapy.extensions.logstats] INFO: Crawled 6868 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 12:21:04 [scrapy.extensions.logstats] INFO: Crawled 6870 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 12:21:51 [scrapy.extensions.logstats] INFO: Crawled 6872 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 12:22:38 [scrapy.extensions.logstats] INFO: Crawled 6874 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 12:24:09 [scrapy.extensions.logstats] INFO: Crawled 6878 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 12:24:55 [scrapy.extensions.logstats] INFO: Crawled 6880 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 12:25:44 [scrapy.extensions.logstats] INFO: Crawled 6882 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 12:27:16 [scrapy.extensions.logstats] INFO: Crawled 6886 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 12:28:01 [scrapy.extensions.logstats] INFO: Crawled 6888 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 12:28:46 [scrapy.extensions.logstats] INFO: Crawled 6889 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 12:29:32 [scrapy.extensions.logstats] INFO: Crawled 6893 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 12:30:42 [scrapy.extensions.logstats] INFO: Crawled 6896 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 12:31:47 [scrapy.extensions.logstats] INFO: Crawled 6899 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 12:32:53 [scrapy.extensions.logstats] INFO: Crawled 6902 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 12:34:00 [scrapy.extensions.logstats] INFO: Crawled 6905 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 12:35:07 [scrapy.extensions.logstats] INFO: Crawled 6908 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 12:36:13 [scrapy.extensions.logstats] INFO: Crawled 6911 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 12:37:19 [scrapy.extensions.logstats] INFO: Crawled 6914 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 12:38:26 [scrapy.extensions.logstats] INFO: Crawled 6917 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 12:39:33 [scrapy.extensions.logstats] INFO: Crawled 6920 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 12:40:30 [scrapy.extensions.logstats] INFO: Crawled 6923 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 12:41:47 [scrapy.extensions.logstats] INFO: Crawled 6926 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 12:42:54 [scrapy.extensions.logstats] INFO: Crawled 6929 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 12:43:47 [scrapy.extensions.logstats] INFO: Crawled 6932 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 12:44:58 [scrapy.extensions.logstats] INFO: Crawled 6935 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 12:46:07 [scrapy.extensions.logstats] INFO: Crawled 6938 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 12:47:16 [scrapy.extensions.logstats] INFO: Crawled 6941 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 12:48:18 [scrapy.extensions.logstats] INFO: Crawled 6944 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 12:49:29 [scrapy.extensions.logstats] INFO: Crawled 6947 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 12:50:38 [scrapy.extensions.logstats] INFO: Crawled 6950 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 12:51:45 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://demarini.com/robots.txt>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2019-11-09 12:51:45 [scrapy.extensions.logstats] INFO: Crawled 6953 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 12:52:45 [scrapy.extensions.logstats] INFO: Crawled 6956 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 12:53:33 [scrapy.extensions.logstats] INFO: Crawled 6959 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 12:54:36 [scrapy.extensions.logstats] INFO: Crawled 6962 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 12:55:46 [scrapy.extensions.logstats] INFO: Crawled 6965 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 12:56:43 [scrapy.extensions.logstats] INFO: Crawled 6968 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 12:57:40 [scrapy.extensions.logstats] INFO: Crawled 6971 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 12:58:50 [scrapy.extensions.logstats] INFO: Crawled 6974 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 12:59:52 [scrapy.extensions.logstats] INFO: Crawled 6977 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 13:00:44 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://ch.coopertire.com/robots.txt>: DNS lookup failed: no results for hostname lookup: ch.coopertire.com.
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: ch.coopertire.com.
2019-11-09 13:00:44 [scrapy.extensions.logstats] INFO: Crawled 6980 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 13:01:36 [scrapy.extensions.logstats] INFO: Crawled 6983 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 13:02:38 [scrapy.extensions.logstats] INFO: Crawled 6986 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 13:03:43 [scrapy.extensions.logstats] INFO: Crawled 6989 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 13:04:47 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://br.coopertire.com/robots.txt>: User timeout caused connection failure: Getting http://br.coopertire.com/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://br.coopertire.com/robots.txt took longer than 15.0 seconds..
2019-11-09 13:04:47 [scrapy.extensions.logstats] INFO: Crawled 6992 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 13:05:57 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://esmx.coopertire.com/robots.txt>: User timeout caused connection failure: Getting http://esmx.coopertire.com/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://esmx.coopertire.com/robots.txt took longer than 15.0 seconds..
2019-11-09 13:05:57 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://es-co.coopertire.com/robots.txt>: User timeout caused connection failure: Getting http://es-co.coopertire.com/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://es-co.coopertire.com/robots.txt took longer than 15.0 seconds..
2019-11-09 13:05:57 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://es-cl.coopertire.com/robots.txt>: User timeout caused connection failure: Getting http://es-cl.coopertire.com/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://es-cl.coopertire.com/robots.txt took longer than 15.0 seconds..
2019-11-09 13:05:57 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://pt-br.coopertire.com/robots.txt>: User timeout caused connection failure: Getting http://pt-br.coopertire.com/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://pt-br.coopertire.com/robots.txt took longer than 15.0 seconds..
2019-11-09 13:05:57 [scrapy.extensions.logstats] INFO: Crawled 6995 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 13:07:07 [scrapy.extensions.logstats] INFO: Crawled 6998 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 13:08:11 [scrapy.extensions.logstats] INFO: Crawled 7001 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 13:09:18 [scrapy.extensions.logstats] INFO: Crawled 7004 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 13:10:30 [scrapy.extensions.logstats] INFO: Crawled 7006 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 13:11:59 [scrapy.extensions.logstats] INFO: Crawled 7010 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 13:12:45 [scrapy.extensions.logstats] INFO: Crawled 7012 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 13:14:13 [scrapy.extensions.logstats] INFO: Crawled 7016 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 13:14:57 [scrapy.extensions.logstats] INFO: Crawled 7018 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 13:15:40 [scrapy.extensions.logstats] INFO: Crawled 7020 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 13:17:06 [scrapy.extensions.logstats] INFO: Crawled 7024 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 13:17:50 [scrapy.extensions.logstats] INFO: Crawled 7025 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 13:18:36 [scrapy.extensions.logstats] INFO: Crawled 7027 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 13:19:40 [scrapy.extensions.logstats] INFO: Crawled 7030 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 13:20:03 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://jobs.dana.com/robots.txt>: User timeout caused connection failure: Getting http://jobs.dana.com/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://jobs.dana.com/robots.txt took longer than 15.0 seconds..
2019-11-09 13:20:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://ca.denon.com/ca/home>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ca.denon.com/ca/home took longer than 15.0 seconds..
2019-11-09 13:20:47 [scrapy.extensions.logstats] INFO: Crawled 7033 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 13:21:30 [scrapy.extensions.logstats] INFO: Crawled 7036 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 13:22:36 [scrapy.extensions.logstats] INFO: Crawled 7045 pages (at 9 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 13:23:43 [scrapy.extensions.logstats] INFO: Crawled 7045 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 13:25:40 [scrapy.extensions.logstats] INFO: Crawled 7045 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 13:27:10 [scrapy.extensions.logstats] INFO: Crawled 7053 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 13:28:37 [scrapy.extensions.logstats] INFO: Crawled 7056 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 13:29:47 [scrapy.extensions.logstats] INFO: Crawled 7059 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 13:31:05 [scrapy.extensions.logstats] INFO: Crawled 7062 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 13:32:12 [scrapy.extensions.logstats] INFO: Crawled 7065 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 13:33:20 [scrapy.extensions.logstats] INFO: Crawled 7068 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 13:34:32 [scrapy.extensions.logstats] INFO: Crawled 7071 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 13:35:43 [scrapy.extensions.logstats] INFO: Crawled 7074 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 13:36:51 [scrapy.extensions.logstats] INFO: Crawled 7077 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 13:38:03 [scrapy.extensions.logstats] INFO: Crawled 7078 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 13:38:52 [scrapy.extensions.logstats] INFO: Crawled 7081 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 13:39:37 [scrapy.extensions.logstats] INFO: Crawled 7082 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 13:40:44 [scrapy.extensions.logstats] INFO: Crawled 7085 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 13:41:30 [scrapy.extensions.logstats] INFO: Crawled 7087 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 13:42:34 [scrapy.extensions.logstats] INFO: Crawled 7090 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 13:43:42 [scrapy.extensions.logstats] INFO: Crawled 7093 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 13:44:50 [scrapy.extensions.logstats] INFO: Crawled 7096 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 13:45:35 [scrapy.extensions.logstats] INFO: Crawled 7098 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 13:46:43 [scrapy.extensions.logstats] INFO: Crawled 7101 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 13:47:51 [scrapy.extensions.logstats] INFO: Crawled 7104 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 13:48:36 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://cozziausa.com/robots.txt>: User timeout caused connection failure: Getting http://cozziausa.com/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://cozziausa.com/robots.txt took longer than 15.0 seconds..
2019-11-09 13:48:36 [scrapy.extensions.logstats] INFO: Crawled 7106 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 13:49:42 [scrapy.extensions.logstats] INFO: Crawled 7109 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 13:50:50 [scrapy.extensions.logstats] INFO: Crawled 7112 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 13:51:36 [scrapy.extensions.logstats] INFO: Crawled 7114 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 13:52:45 [scrapy.extensions.logstats] INFO: Crawled 7117 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 13:53:53 [scrapy.extensions.logstats] INFO: Crawled 7120 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 13:54:37 [scrapy.extensions.logstats] INFO: Crawled 7122 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 13:55:39 [scrapy.extensions.logstats] INFO: Crawled 7125 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 13:56:42 [scrapy.extensions.logstats] INFO: Crawled 7129 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 13:57:15 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.iam.delphi.com/en-us>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: www.iam.delphi.com.
2019-11-09 13:57:37 [scrapy.extensions.logstats] INFO: Crawled 7132 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 13:58:39 [scrapy.extensions.logstats] INFO: Crawled 7135 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 13:59:43 [scrapy.extensions.logstats] INFO: Crawled 7139 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 14:00:15 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.coscojuvenile.com>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: www.coscojuvenile.com.
2019-11-09 14:00:31 [scrapy.extensions.logstats] INFO: Crawled 7142 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 14:01:36 [scrapy.extensions.logstats] INFO: Crawled 7146 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 14:01:36 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.global.dcshoes.com/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: www.global.dcshoes.com.
2019-11-09 14:02:41 [scrapy.extensions.logstats] INFO: Crawled 7150 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 14:03:45 [scrapy.extensions.logstats] INFO: Crawled 7154 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 14:04:33 [scrapy.extensions.logstats] INFO: Crawled 7157 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 14:05:46 [scrapy.extensions.logstats] INFO: Crawled 7161 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 14:06:36 [scrapy.extensions.logstats] INFO: Crawled 7163 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 14:07:32 [scrapy.extensions.logstats] INFO: Crawled 7166 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 14:08:36 [scrapy.extensions.logstats] INFO: Crawled 7170 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 14:09:40 [scrapy.extensions.logstats] INFO: Crawled 7174 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 14:10:49 [scrapy.extensions.logstats] INFO: Crawled 7177 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 14:11:35 [scrapy.extensions.logstats] INFO: Crawled 7179 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 14:12:39 [scrapy.extensions.logstats] INFO: Crawled 7183 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 14:13:44 [scrapy.extensions.logstats] INFO: Crawled 7187 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 14:14:33 [scrapy.extensions.logstats] INFO: Crawled 7195 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 14:15:53 [scrapy.extensions.logstats] INFO: Crawled 7199 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 14:16:57 [scrapy.extensions.logstats] INFO: Crawled 7203 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 14:17:58 [scrapy.extensions.logstats] INFO: Crawled 7205 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 14:18:30 [scrapy.extensions.logstats] INFO: Crawled 7208 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 14:19:34 [scrapy.extensions.logstats] INFO: Crawled 7212 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 14:19:34 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.danryanbuilders.com/homeowner-resources/customer-service/tel:8003349143>: HTTP status code is not handled or not allowed
2019-11-09 14:20:07 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.danryanbuilders.com/homeowner-resources/customer-service/tel:8662719897>: HTTP status code is not handled or not allowed
2019-11-09 14:20:23 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.danryanbuilders.com/homeowner-resources/customer-service/tel:8005147133>: HTTP status code is not handled or not allowed
2019-11-09 14:20:56 [scrapy.extensions.logstats] INFO: Crawled 7218 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 14:20:56 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.danryanbuilders.com/homeowner-resources/customer-service/tel:4122756617>: HTTP status code is not handled or not allowed
2019-11-09 14:21:12 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.danryanbuilders.com/homeowner-resources/customer-service/tel:8664235676>: HTTP status code is not handled or not allowed
2019-11-09 14:22:49 [scrapy.extensions.logstats] INFO: Crawled 7231 pages (at 13 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 14:22:49 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.danryanbuilders.com/homeowner-resources/customer-service/tel:8667444034>: HTTP status code is not handled or not allowed
2019-11-09 14:24:08 [scrapy.extensions.logstats] INFO: Crawled 7235 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 14:24:08 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.danryanbuilders.com/homeowner-resources/customer-service/tel:8004432119>: HTTP status code is not handled or not allowed
2019-11-09 14:24:08 [scrapy.core.scraper] ERROR: Error downloading <GET http://comfortresearch.com/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://comfortresearch.com/ took longer than 15.0 seconds..
2019-11-09 14:25:10 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.danryanbuilders.com/homeowner-resources/customer-service/tel:8438202506>: HTTP status code is not handled or not allowed
2019-11-09 14:25:10 [scrapy.extensions.logstats] INFO: Crawled 7239 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 14:25:58 [scrapy.extensions.logstats] INFO: Crawled 7243 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 14:25:58 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.danryanbuilders.com/the-dan-ryan-builders-difference/contact-us/tel:9197474970>: HTTP status code is not handled or not allowed
2019-11-09 14:26:47 [scrapy.extensions.logstats] INFO: Crawled 7247 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 14:26:47 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.danryanbuilders.com/the-dan-ryan-builders-difference/contact-us/tel:7042009730>: HTTP status code is not handled or not allowed
2019-11-09 14:27:54 [scrapy.extensions.logstats] INFO: Crawled 7250 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 14:27:54 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.danryanbuilders.com/the-dan-ryan-builders-difference/contact-us/tel:8642147440>: HTTP status code is not handled or not allowed
2019-11-09 14:28:36 [scrapy.extensions.logstats] INFO: Crawled 7253 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 14:28:37 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.danryanbuilders.com/the-dan-ryan-builders-difference/contact-us/tel:7249391015>: HTTP status code is not handled or not allowed
2019-11-09 14:29:24 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.danryanbuilders.com/the-dan-ryan-builders-difference/contact-us/tel:2404206046>: HTTP status code is not handled or not allowed
2019-11-09 14:30:08 [scrapy.extensions.logstats] INFO: Crawled 7259 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 14:30:08 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.danryanbuilders.com/the-dan-ryan-builders-difference/contact-us/tel:8438202505>: HTTP status code is not handled or not allowed
2019-11-09 14:30:54 [scrapy.extensions.logstats] INFO: Crawled 7262 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 14:30:54 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.danryanbuilders.com/the-dan-ryan-builders-difference/contact-us/tel:2404206050>: HTTP status code is not handled or not allowed
2019-11-09 14:31:43 [scrapy.extensions.logstats] INFO: Crawled 7264 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 14:33:36 [scrapy.extensions.logstats] INFO: Crawled 7270 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 14:34:46 [scrapy.extensions.logstats] INFO: Crawled 7273 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 14:35:48 [scrapy.extensions.logstats] INFO: Crawled 7276 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 14:36:37 [scrapy.extensions.logstats] INFO: Crawled 7279 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 14:38:14 [scrapy.extensions.logstats] INFO: Crawled 7285 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 14:39:03 [scrapy.extensions.logstats] INFO: Crawled 7288 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 14:40:11 [scrapy.extensions.logstats] INFO: Crawled 7291 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 14:40:33 [scrapy.extensions.logstats] INFO: Crawled 7294 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 14:42:09 [scrapy.extensions.logstats] INFO: Crawled 7294 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 14:42:42 [scrapy.extensions.logstats] INFO: Crawled 7310 pages (at 16 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 14:45:08 [scrapy.extensions.logstats] INFO: Crawled 7310 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 14:48:18 [scrapy.extensions.logstats] INFO: Crawled 7310 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 14:48:39 [scrapy.extensions.logstats] INFO: Crawled 7318 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 14:50:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.dinancars.com/products/?category=signature-packages>: User timeout caused connection failure.
2019-11-09 14:50:58 [scrapy.extensions.logstats] INFO: Crawled 7324 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 14:53:19 [scrapy.extensions.logstats] INFO: Crawled 7324 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 14:53:40 [scrapy.extensions.logstats] INFO: Crawled 7329 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 14:55:08 [scrapy.extensions.logstats] INFO: Crawled 7335 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 14:57:29 [scrapy.extensions.logstats] INFO: Crawled 7338 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 14:58:36 [scrapy.extensions.logstats] INFO: Crawled 7341 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 14:59:43 [scrapy.extensions.logstats] INFO: Crawled 7344 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 15:00:41 [scrapy.extensions.logstats] INFO: Crawled 7347 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 15:01:31 [scrapy.extensions.logstats] INFO: Crawled 7347 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 15:03:17 [scrapy.extensions.logstats] INFO: Crawled 7357 pages (at 10 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 15:04:59 [scrapy.extensions.logstats] INFO: Crawled 7357 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 15:06:50 [scrapy.extensions.logstats] INFO: Crawled 7368 pages (at 11 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 15:08:10 [scrapy.extensions.logstats] INFO: Crawled 7373 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 15:09:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.jobs.net/jobs/danryanbuilders/en-us/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.jobs.net/jobs/danryanbuilders/en-us/ took longer than 15.0 seconds..
2019-11-09 15:09:31 [scrapy.extensions.logstats] INFO: Crawled 7377 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 15:10:36 [scrapy.extensions.logstats] INFO: Crawled 7380 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 15:11:45 [scrapy.extensions.logstats] INFO: Crawled 7383 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 15:12:44 [scrapy.extensions.logstats] INFO: Crawled 7386 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 15:13:52 [scrapy.extensions.logstats] INFO: Crawled 7389 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 15:14:52 [scrapy.extensions.logstats] INFO: Crawled 7392 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 15:15:52 [scrapy.extensions.logstats] INFO: Crawled 7395 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 15:16:45 [scrapy.extensions.logstats] INFO: Crawled 7398 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 15:17:50 [scrapy.extensions.logstats] INFO: Crawled 7401 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 15:19:09 [scrapy.extensions.logstats] INFO: Crawled 7404 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 15:20:19 [scrapy.extensions.logstats] INFO: Crawled 7407 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 15:21:09 [scrapy.extensions.logstats] INFO: Crawled 7410 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 15:21:42 [scrapy.extensions.logstats] INFO: Crawled 7413 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 15:23:03 [scrapy.extensions.logstats] INFO: Crawled 7417 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 15:23:42 [scrapy.extensions.logstats] INFO: Crawled 7419 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 15:24:31 [scrapy.extensions.logstats] INFO: Crawled 7421 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 15:25:44 [scrapy.extensions.logstats] INFO: Crawled 7425 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 15:26:35 [scrapy.extensions.logstats] INFO: Crawled 7427 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 15:28:17 [scrapy.extensions.logstats] INFO: Crawled 7430 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 15:28:42 [scrapy.extensions.logstats] INFO: Crawled 7431 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 15:29:30 [scrapy.extensions.logstats] INFO: Crawled 7433 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 15:30:44 [scrapy.extensions.logstats] INFO: Crawled 7436 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 15:31:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.denovahomes.com/privacy-policy/tel/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.denovahomes.com/privacy-policy/tel/ took longer than 15.0 seconds..
2019-11-09 15:31:34 [scrapy.extensions.logstats] INFO: Crawled 7438 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 15:32:48 [scrapy.extensions.logstats] INFO: Crawled 7441 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 15:33:33 [scrapy.extensions.logstats] INFO: Crawled 7443 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 15:34:43 [scrapy.extensions.logstats] INFO: Crawled 7446 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 15:35:46 [scrapy.extensions.logstats] INFO: Crawled 7449 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 15:36:36 [scrapy.extensions.logstats] INFO: Crawled 7452 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 15:37:41 [scrapy.extensions.logstats] INFO: Crawled 7458 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 15:38:46 [scrapy.extensions.logstats] INFO: Crawled 7462 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 15:39:36 [scrapy.extensions.logstats] INFO: Crawled 7464 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 15:40:41 [scrapy.extensions.logstats] INFO: Crawled 7470 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 15:41:31 [scrapy.extensions.logstats] INFO: Crawled 7470 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 15:42:39 [scrapy.extensions.logstats] INFO: Crawled 7479 pages (at 9 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 15:43:47 [scrapy.extensions.logstats] INFO: Crawled 7482 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 15:44:58 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://locations.crocs.com/robots.txt>: User timeout caused connection failure: Getting http://locations.crocs.com/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://locations.crocs.com/robots.txt took longer than 15.0 seconds..
2019-11-09 15:44:58 [scrapy.extensions.logstats] INFO: Crawled 7482 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 15:46:09 [scrapy.extensions.logstats] INFO: Crawled 7482 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 15:46:34 [scrapy.extensions.logstats] INFO: Crawled 7487 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 15:46:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://tech.d-box.com?wpdmdl=22010> (referer: http://tech.d-box.com/corporate-page/investors-information/)
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\root\Desktop\GitHub\innovScraping\innovationScraping\innovScrapyTools\innovScrapyCode\spiders\customized_web_crawler.py", line 67, in parse_item
    insert_into_mongo(response.url, response.text, self.coll)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\http\response\__init__.py", line 93, in text
    raise AttributeError("Response content isn't text")
AttributeError: Response content isn't text
2019-11-09 15:47:44 [scrapy.extensions.logstats] INFO: Crawled 7494 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 15:48:53 [scrapy.extensions.logstats] INFO: Crawled 7494 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 15:50:10 [scrapy.extensions.logstats] INFO: Crawled 7494 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 15:50:43 [scrapy.extensions.logstats] INFO: Crawled 7509 pages (at 15 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 15:52:20 [scrapy.extensions.logstats] INFO: Crawled 7509 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 15:54:52 [scrapy.extensions.logstats] INFO: Crawled 7509 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 15:54:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/faq>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/faq took longer than 15.0 seconds..
2019-11-09 15:56:03 [scrapy.extensions.logstats] INFO: Crawled 7519 pages (at 10 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 15:56:47 [scrapy.extensions.logstats] INFO: Crawled 7519 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 15:58:07 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.columbia.com>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.columbia.com took longer than 15.0 seconds..
2019-11-09 15:58:07 [scrapy.extensions.logstats] INFO: Crawled 7519 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 15:58:07 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/governance-docs>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/governance-docs took longer than 15.0 seconds..
2019-11-09 15:58:07 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.columbia.com>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.columbia.com took longer than 15.0 seconds..
2019-11-09 15:58:51 [scrapy.extensions.logstats] INFO: Crawled 7525 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 16:00:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.columbia.com>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.columbia.com took longer than 15.0 seconds..
2019-11-09 16:00:25 [scrapy.extensions.logstats] INFO: Crawled 7525 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 16:00:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.columbia.com>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.columbia.com took longer than 15.0 seconds..
2019-11-09 16:00:50 [scrapy.extensions.logstats] INFO: Crawled 7529 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 16:01:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.dinancars.com/warranty/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.dinancars.com/warranty/ took longer than 15.0 seconds..
2019-11-09 16:02:05 [scrapy.extensions.logstats] INFO: Crawled 7531 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 16:02:53 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.columbia.com>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.columbia.com took longer than 15.0 seconds..
2019-11-09 16:02:53 [scrapy.core.scraper] ERROR: Error downloading <GET https://daymak.com/warranty.html>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://daymak.com/warranty.html took longer than 15.0 seconds..
2019-11-09 16:02:53 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/press-releases/detail/300>: User timeout caused connection failure.
2019-11-09 16:02:53 [scrapy.extensions.logstats] INFO: Crawled 7531 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 16:02:53 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.columbia.com>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.columbia.com took longer than 15.0 seconds..
2019-11-09 16:03:43 [scrapy.extensions.logstats] INFO: Crawled 7540 pages (at 9 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 16:04:59 [scrapy.extensions.logstats] INFO: Crawled 7542 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 16:06:41 [scrapy.extensions.logstats] INFO: Crawled 7544 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 16:08:16 [scrapy.extensions.logstats] INFO: Crawled 7544 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 16:08:43 [scrapy.extensions.logstats] INFO: Crawled 7548 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 16:09:33 [scrapy.extensions.logstats] INFO: Crawled 7551 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 16:11:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://usa.denon.com/us/heos-3-small-powered-speakers>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://usa.denon.com/us/heos-3-small-powered-speakers took longer than 15.0 seconds..
2019-11-09 16:11:11 [scrapy.extensions.logstats] INFO: Crawled 7551 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 16:11:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://usa.denon.com/us/wireless-audio-quality-review>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://usa.denon.com/us/wireless-audio-quality-review took longer than 15.0 seconds..
2019-11-09 16:11:34 [scrapy.extensions.logstats] INFO: Crawled 7557 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 16:13:44 [scrapy.extensions.logstats] INFO: Crawled 7560 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 16:14:32 [scrapy.extensions.logstats] INFO: Crawled 7560 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 16:14:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/press-releases/detail/142/delta-apparel-reports-fiscal-2016-second-quarter-and>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/press-releases/detail/142/delta-apparel-reports-fiscal-2016-second-quarter-and took longer than 15.0 seconds..
2019-11-09 16:15:38 [scrapy.extensions.logstats] INFO: Crawled 7569 pages (at 9 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 16:17:05 [scrapy.extensions.logstats] INFO: Crawled 7570 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 16:17:30 [scrapy.extensions.logstats] INFO: Crawled 7570 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 16:18:38 [scrapy.extensions.logstats] INFO: Crawled 7573 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 16:19:53 [scrapy.extensions.logstats] INFO: Crawled 7577 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 16:20:43 [scrapy.extensions.logstats] INFO: Crawled 7581 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 16:21:31 [scrapy.extensions.logstats] INFO: Crawled 7582 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 16:22:45 [scrapy.extensions.logstats] INFO: Crawled 7584 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 16:23:38 [scrapy.extensions.logstats] INFO: Crawled 7584 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 16:24:59 [scrapy.extensions.logstats] INFO: Crawled 7590 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 16:25:59 [scrapy.extensions.logstats] INFO: Crawled 7592 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 16:26:46 [scrapy.extensions.logstats] INFO: Crawled 7592 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 16:28:02 [scrapy.extensions.logstats] INFO: Crawled 7603 pages (at 11 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 16:30:29 [scrapy.extensions.logstats] INFO: Crawled 7606 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 16:30:30 [scrapy.core.scraper] ERROR: Error downloading <GET http://ca.coopertire.com/where-to-start/tire-maintenance>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://ca.coopertire.com/where-to-start/tire-maintenance took longer than 15.0 seconds..
2019-11-09 16:31:42 [scrapy.extensions.logstats] INFO: Crawled 7609 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 16:32:46 [scrapy.extensions.logstats] INFO: Crawled 7613 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 16:33:52 [scrapy.extensions.logstats] INFO: Crawled 7616 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 16:34:40 [scrapy.extensions.logstats] INFO: Crawled 7619 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 16:36:03 [scrapy.extensions.logstats] INFO: Crawled 7621 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 16:36:55 [scrapy.extensions.logstats] INFO: Crawled 7623 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 16:37:39 [scrapy.extensions.logstats] INFO: Crawled 7626 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 16:38:54 [scrapy.extensions.logstats] INFO: Crawled 7628 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 16:39:43 [scrapy.extensions.logstats] INFO: Crawled 7631 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 16:40:55 [scrapy.extensions.logstats] INFO: Crawled 7633 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 16:41:46 [scrapy.extensions.logstats] INFO: Crawled 7635 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 16:42:39 [scrapy.extensions.logstats] INFO: Crawled 7636 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 16:43:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://tech.d-box.com?wpdmdl=23286> (referer: http://tech.d-box.com/corporate-page/investors-information/)
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\root\Desktop\GitHub\innovScraping\innovationScraping\innovScrapyTools\innovScrapyCode\spiders\customized_web_crawler.py", line 67, in parse_item
    insert_into_mongo(response.url, response.text, self.coll)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\http\response\__init__.py", line 93, in text
    raise AttributeError("Response content isn't text")
AttributeError: Response content isn't text
2019-11-09 16:44:21 [scrapy.extensions.logstats] INFO: Crawled 7643 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 16:44:48 [scrapy.extensions.logstats] INFO: Crawled 7645 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 16:46:06 [scrapy.extensions.logstats] INFO: Crawled 7647 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 16:46:38 [scrapy.extensions.logstats] INFO: Crawled 7647 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 16:46:55 [scrapy.core.scraper] ERROR: Spider error processing <GET http://tech.d-box.com?wpdmdl=23151> (referer: http://tech.d-box.com/corporate-page/investors-information/)
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\root\Desktop\GitHub\innovScraping\innovationScraping\innovScrapyTools\innovScrapyCode\spiders\customized_web_crawler.py", line 67, in parse_item
    insert_into_mongo(response.url, response.text, self.coll)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\http\response\__init__.py", line 93, in text
    raise AttributeError("Response content isn't text")
AttributeError: Response content isn't text
2019-11-09 16:48:17 [scrapy.extensions.logstats] INFO: Crawled 7657 pages (at 10 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 16:49:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/press-releases/detail/113/delta-apparel-reports-fiscal-2014-second-quarter-and-six>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/press-releases/detail/113/delta-apparel-reports-fiscal-2014-second-quarter-and-six took longer than 15.0 seconds..
2019-11-09 16:49:06 [scrapy.extensions.logstats] INFO: Crawled 7657 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 16:49:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/press-releases/detail/110/delta-apparel-reports-fiscal-2014-first-quarter-results>: User timeout caused connection failure.
2019-11-09 16:49:39 [scrapy.extensions.logstats] INFO: Crawled 7664 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 16:51:02 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://ir.comstockcompanies.com/news/2010/tel:7032301985>: HTTP status code is not handled or not allowed
2019-11-09 16:51:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/press-releases/detail/107/delta-apparel-reports-results-of-transition-period-ended>: User timeout caused connection failure.
2019-11-09 16:51:02 [scrapy.extensions.logstats] INFO: Crawled 7666 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 16:51:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/press-releases/detail/105/delta-apparel-reports-fy13-fourth-quarter-and-year-end>: User timeout caused connection failure.
2019-11-09 16:51:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/press-releases/detail/74/delta-apparel-reports-fy12-third-quarter-and-ytd-results>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/press-releases/detail/74/delta-apparel-reports-fy12-third-quarter-and-ytd-results took longer than 15.0 seconds..
2019-11-09 16:51:18 [scrapy.core.scraper] ERROR: Spider error processing <GET http://tech.d-box.com?wpdmdl=22901> (referer: http://tech.d-box.com/corporate-page/investors-information/)
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\root\Desktop\GitHub\innovScraping\innovationScraping\innovScrapyTools\innovScrapyCode\spiders\customized_web_crawler.py", line 67, in parse_item
    insert_into_mongo(response.url, response.text, self.coll)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\http\response\__init__.py", line 93, in text
    raise AttributeError("Response content isn't text")
AttributeError: Response content isn't text
2019-11-09 16:51:35 [scrapy.extensions.logstats] INFO: Crawled 7668 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 16:51:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://tech.d-box.com?wpdmdl=22466> (referer: http://tech.d-box.com/corporate-page/investors-information/)
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\root\Desktop\GitHub\innovScraping\innovationScraping\innovScrapyTools\innovScrapyCode\spiders\customized_web_crawler.py", line 67, in parse_item
    insert_into_mongo(response.url, response.text, self.coll)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\http\response\__init__.py", line 93, in text
    raise AttributeError("Response content isn't text")
AttributeError: Response content isn't text
2019-11-09 16:52:41 [scrapy.extensions.logstats] INFO: Crawled 7677 pages (at 9 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 16:54:11 [scrapy.extensions.logstats] INFO: Crawled 7682 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 16:54:54 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://ir.comstockcompanies.com/news/2009/tel:7032301985>: HTTP status code is not handled or not allowed
2019-11-09 16:54:54 [scrapy.extensions.logstats] INFO: Crawled 7684 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 16:56:00 [scrapy.extensions.logstats] INFO: Crawled 7686 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 16:56:40 [scrapy.extensions.logstats] INFO: Crawled 7686 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 16:56:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://tech.d-box.com?wpdmdl=22165> (referer: http://tech.d-box.com/corporate-page/investors-information/)
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\root\Desktop\GitHub\innovScraping\innovationScraping\innovScrapyTools\innovScrapyCode\spiders\customized_web_crawler.py", line 67, in parse_item
    insert_into_mongo(response.url, response.text, self.coll)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\http\response\__init__.py", line 93, in text
    raise AttributeError("Response content isn't text")
AttributeError: Response content isn't text
2019-11-09 16:59:29 [scrapy.extensions.logstats] INFO: Crawled 7699 pages (at 13 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 17:00:20 [scrapy.extensions.logstats] INFO: Crawled 7699 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 17:01:11 [scrapy.extensions.logstats] INFO: Crawled 7700 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 17:01:36 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.dermalogica.com>: User timeout caused connection failure.
2019-11-09 17:01:36 [scrapy.extensions.logstats] INFO: Crawled 7700 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 17:01:36 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.dermalogica.com>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.dermalogica.com took longer than 15.0 seconds..
2019-11-09 17:01:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://tech.d-box.com?wpdmdl=21689> (referer: http://tech.d-box.com/corporate-page/investors-information/)
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\root\Desktop\GitHub\innovScraping\innovationScraping\innovScrapyTools\innovScrapyCode\spiders\customized_web_crawler.py", line 67, in parse_item
    insert_into_mongo(response.url, response.text, self.coll)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\http\response\__init__.py", line 93, in text
    raise AttributeError("Response content isn't text")
AttributeError: Response content isn't text
2019-11-09 17:03:17 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://mailto;strauner@comstockcompanies.com/robots.txt>: invalid hostname: mailto;strauner@comstockcompanies.com
ValueError: invalid hostname: mailto;strauner@comstockcompanies.com
2019-11-09 17:03:17 [scrapy.extensions.logstats] INFO: Crawled 7711 pages (at 11 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 17:04:30 [scrapy.extensions.logstats] INFO: Crawled 7711 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 17:05:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://tech.d-box.com?wpdmdl=21143> (referer: http://tech.d-box.com/corporate-page/investors-information/)
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\root\Desktop\GitHub\innovScraping\innovationScraping\innovScrapyTools\innovScrapyCode\spiders\customized_web_crawler.py", line 67, in parse_item
    insert_into_mongo(response.url, response.text, self.coll)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\http\response\__init__.py", line 93, in text
    raise AttributeError("Response content isn't text")
AttributeError: Response content isn't text
2019-11-09 17:05:46 [scrapy.extensions.logstats] INFO: Crawled 7718 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 17:06:59 [scrapy.extensions.logstats] INFO: Crawled 7721 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 17:08:13 [scrapy.extensions.logstats] INFO: Crawled 7721 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 17:08:40 [scrapy.extensions.logstats] INFO: Crawled 7726 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 17:09:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://mailto;strauner@comstockcompanies.com>: invalid hostname: mailto;strauner@comstockcompanies.com
2019-11-09 17:09:59 [scrapy.extensions.logstats] INFO: Crawled 7733 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 17:11:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://comstockcompanies.com/residential/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://comstockcompanies.com/residential/ took longer than 15.0 seconds..
2019-11-09 17:11:17 [scrapy.extensions.logstats] INFO: Crawled 7733 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 17:12:32 [scrapy.extensions.logstats] INFO: Crawled 7733 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 17:13:38 [scrapy.extensions.logstats] INFO: Crawled 7741 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 17:15:15 [scrapy.extensions.logstats] INFO: Crawled 7741 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 17:15:37 [scrapy.extensions.logstats] INFO: Crawled 7747 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 17:16:00 [scrapy.core.scraper] ERROR: Spider error processing <GET http://tech.d-box.com?wpdmdl=12888> (referer: http://tech.d-box.com/corporate-page/investors-information/)
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\root\Desktop\GitHub\innovScraping\innovationScraping\innovScrapyTools\innovScrapyCode\spiders\customized_web_crawler.py", line 67, in parse_item
    insert_into_mongo(response.url, response.text, self.coll)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\http\response\__init__.py", line 93, in text
    raise AttributeError("Response content isn't text")
AttributeError: Response content isn't text
2019-11-09 17:16:48 [scrapy.extensions.logstats] INFO: Crawled 7755 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 17:18:01 [scrapy.extensions.logstats] INFO: Crawled 7755 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 17:19:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.daysofwonder.com/en/contact/digital/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.daysofwonder.com/en/contact/digital/ took longer than 15.0 seconds..
2019-11-09 17:19:18 [scrapy.extensions.logstats] INFO: Crawled 7755 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 17:19:18 [scrapy.core.scraper] ERROR: Spider error processing <GET http://tech.d-box.com?wpdmdl=12539> (referer: http://tech.d-box.com/corporate-page/investors-information/)
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\root\Desktop\GitHub\innovScraping\innovationScraping\innovScrapyTools\innovScrapyCode\spiders\customized_web_crawler.py", line 67, in parse_item
    insert_into_mongo(response.url, response.text, self.coll)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\http\response\__init__.py", line 93, in text
    raise AttributeError("Response content isn't text")
AttributeError: Response content isn't text
2019-11-09 17:19:39 [scrapy.extensions.logstats] INFO: Crawled 7761 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 17:20:34 [scrapy.extensions.logstats] INFO: Crawled 7763 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 17:21:45 [scrapy.extensions.logstats] INFO: Crawled 7768 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 17:22:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://tech.d-box.com?wpdmdl=7061> (referer: http://tech.d-box.com/corporate-page/investors-information/)
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\root\Desktop\GitHub\innovScraping\innovationScraping\innovScrapyTools\innovScrapyCode\spiders\customized_web_crawler.py", line 67, in parse_item
    insert_into_mongo(response.url, response.text, self.coll)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\http\response\__init__.py", line 93, in text
    raise AttributeError("Response content isn't text")
AttributeError: Response content isn't text
2019-11-09 17:22:33 [scrapy.extensions.logstats] INFO: Crawled 7772 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 17:23:45 [scrapy.extensions.logstats] INFO: Crawled 7776 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 17:24:56 [scrapy.extensions.logstats] INFO: Crawled 7776 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 17:25:19 [scrapy.core.scraper] ERROR: Spider error processing <GET http://tech.d-box.com?wpdmdl=7043> (referer: http://tech.d-box.com/corporate-page/investors-information/)
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\root\Desktop\GitHub\innovScraping\innovationScraping\innovScrapyTools\innovScrapyCode\spiders\customized_web_crawler.py", line 67, in parse_item
    insert_into_mongo(response.url, response.text, self.coll)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\http\response\__init__.py", line 93, in text
    raise AttributeError("Response content isn't text")
AttributeError: Response content isn't text
2019-11-09 17:25:42 [scrapy.extensions.logstats] INFO: Crawled 7782 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 17:26:56 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://ir.comstockcompanies.com/news/2005/tel:7032301985>: HTTP status code is not handled or not allowed
2019-11-09 17:26:56 [scrapy.extensions.logstats] INFO: Crawled 7787 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 17:28:30 [scrapy.core.scraper] ERROR: Error downloading <GET https://asmodee.helpshift.com/a/asmodee-net/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://asmodee.helpshift.com/a/asmodee-net/ took longer than 15.0 seconds..
2019-11-09 17:28:30 [scrapy.extensions.logstats] INFO: Crawled 7788 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 17:28:55 [scrapy.core.scraper] ERROR: Spider error processing <GET http://tech.d-box.com?wpdmdl=23205> (referer: http://tech.d-box.com/corporate-page/investors-information/)
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\root\Desktop\GitHub\innovScraping\innovationScraping\innovScrapyTools\innovScrapyCode\spiders\customized_web_crawler.py", line 67, in parse_item
    insert_into_mongo(response.url, response.text, self.coll)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\http\response\__init__.py", line 93, in text
    raise AttributeError("Response content isn't text")
AttributeError: Response content isn't text
2019-11-09 17:29:44 [scrapy.extensions.logstats] INFO: Crawled 7794 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 17:30:13 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.daysofwonder.com/en/about/children-privacy>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.daysofwonder.com/en/about/children-privacy took longer than 15.0 seconds..
2019-11-09 17:30:40 [scrapy.extensions.logstats] INFO: Crawled 7800 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 17:31:53 [scrapy.core.scraper] ERROR: Error downloading <GET https://steamcommunity.com/openid/login?openid.ns=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0&openid.mode=checkid_setup&openid.return_to=https%3A%2F%2Fwww.daysofwonder.com%2F%2Fsignup%2Fsteam_ok%3Freturnto%3D%252Fen%252Fabout%252Fchildren-privacy%252F&openid.realm=https%3A%2F%2Fwww.daysofwonder.com&openid.ns.sreg=http%3A%2F%2Fopenid.net%2Fextensions%2Fsreg%2F1.1&openid.claimed_id=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0%2Fidentifier_select&openid.identity=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0%2Fidentifier_select>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://steamcommunity.com/openid/login?openid.ns=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0&openid.mode=checkid_setup&openid.return_to=https%3A%2F%2Fwww.daysofwonder.com%2F%2Fsignup%2Fsteam_ok%3Freturnto%3D%252Fen%252Fabout%252Fchildren-privacy%252F&openid.realm=https%3A%2F%2Fwww.daysofwonder.com&openid.ns.sreg=http%3A%2F%2Fopenid.net%2Fextensions%2Fsreg%2F1.1&openid.claimed_id=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0%2Fidentifier_select&openid.identity=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0%2Fidentifier_select took longer than 15.0 seconds..
2019-11-09 17:31:53 [scrapy.extensions.logstats] INFO: Crawled 7802 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 17:32:43 [scrapy.extensions.logstats] INFO: Crawled 7808 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 17:34:18 [scrapy.extensions.logstats] INFO: Crawled 7812 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 17:35:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://curtisindustries.net/product-pages/utility-vehicle-cabs/%7B%7B%20x.link>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://curtisindustries.net/product-pages/utility-vehicle-cabs/%7B%7B%20x.link took longer than 15.0 seconds..
2019-11-09 17:35:29 [scrapy.extensions.logstats] INFO: Crawled 7812 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 17:35:56 [scrapy.extensions.logstats] INFO: Crawled 7818 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 17:37:38 [scrapy.extensions.logstats] INFO: Crawled 7821 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 17:38:44 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.delsol.com/blog/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.delsol.com/blog/ took longer than 15.0 seconds..
2019-11-09 17:38:44 [scrapy.extensions.logstats] INFO: Crawled 7822 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 17:39:51 [scrapy.extensions.logstats] INFO: Crawled 7825 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 17:40:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.daysofwonder.com/play/karma/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.daysofwonder.com/play/karma/ took longer than 15.0 seconds..
2019-11-09 17:40:42 [scrapy.extensions.logstats] INFO: Crawled 7827 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 17:41:08 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cybexintl.com/blog>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.cybexintl.com/blog took longer than 15.0 seconds..
2019-11-09 17:41:34 [scrapy.extensions.logstats] INFO: Crawled 7829 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 17:42:47 [scrapy.extensions.logstats] INFO: Crawled 7832 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 17:43:16 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://ir.comstockcompanies.com/news/news-details/2019/Comstock-Leases-Full-Building-at-Reston-Station-to-ICF/tel:7032301985>: HTTP status code is not handled or not allowed
2019-11-09 17:43:43 [scrapy.extensions.logstats] INFO: Crawled 7839 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 17:45:43 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://ir.comstockcompanies.com/news/news-details/2019/Rolls-Royce-North-America-Moving-Corporate-Headquarters-to-Comstocks-Reston-Station/tel:7032301985>: HTTP status code is not handled or not allowed
2019-11-09 17:45:43 [scrapy.extensions.logstats] INFO: Crawled 7844 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 17:47:06 [scrapy.extensions.logstats] INFO: Crawled 7844 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 17:49:25 [scrapy.extensions.logstats] INFO: Crawled 7852 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 17:49:25 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://ir.comstockcompanies.com/news/news-details/2019/Comstock-Announces-Update-of-its-Investor-Presentation/tel:7032301985>: HTTP status code is not handled or not allowed
2019-11-09 17:49:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.dermaflash.com/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.dermaflash.com/ took longer than 15.0 seconds..
2019-11-09 17:49:50 [scrapy.extensions.logstats] INFO: Crawled 7853 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 17:49:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.dermaflash.com/order>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-09 17:50:17 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://ir.comstockcompanies.com/news/news-details/2019/Comstock-Announces-Leases-with-matchbox-and-Big-Buns-for-Reston-Station/tel:7032301985>: HTTP status code is not handled or not allowed
2019-11-09 17:50:17 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://ir.comstockcompanies.com/news/news-details/2019/Comstock-Holding-Companies-Reports-First-Quarter-2019-Results/tel:7032301985>: HTTP status code is not handled or not allowed
2019-11-09 17:50:41 [scrapy.extensions.logstats] INFO: Crawled 7862 pages (at 9 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 17:51:34 [scrapy.extensions.logstats] INFO: Crawled 7866 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 17:53:12 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://ir.comstockcompanies.com/news/news-details/2019/Comstock-Holding-Announces-Balance-Sheet-Recapitalizationand-Completion-of-Platform-Transition/tel:7032301985>: HTTP status code is not handled or not allowed
2019-11-09 17:53:13 [scrapy.extensions.logstats] INFO: Crawled 7866 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 17:54:21 [scrapy.extensions.logstats] INFO: Crawled 7866 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 17:54:44 [scrapy.extensions.logstats] INFO: Crawled 7870 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 17:54:44 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://ir.comstockcompanies.com/news/news-details/2019/Comstock-Holding-Companies-Reports-2018-Results/tel:7032301985>: HTTP status code is not handled or not allowed
2019-11-09 17:55:35 [scrapy.extensions.logstats] INFO: Crawled 7874 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 17:55:35 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://ir.comstockcompanies.com/news/news-details/2019/Comstock-Adds-Portfolio-of-3-Stabilized-Buildings-and-11M-Square-Feet-of-Additional-Density-to-its-Assets-Under-Management/tel:7032301985>: HTTP status code is not handled or not allowed
2019-11-09 17:56:40 [scrapy.extensions.logstats] INFO: Crawled 7877 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 17:56:40 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://ir.comstockcompanies.com/news/tel:7032301985>: HTTP status code is not handled or not allowed
2019-11-09 17:57:32 [scrapy.extensions.logstats] INFO: Crawled 7879 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 17:57:32 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://ir.comstockcompanies.com/overview/tel:7032301985>: HTTP status code is not handled or not allowed
2019-11-09 17:58:42 [scrapy.extensions.logstats] INFO: Crawled 7882 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 17:59:33 [scrapy.extensions.logstats] INFO: Crawled 7884 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:00:49 [scrapy.extensions.logstats] INFO: Crawled 7893 pages (at 9 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:01:37 [scrapy.core.scraper] ERROR: Error downloading <GET https://cybexworld.cybexintl.com>: User timeout caused connection failure.
2019-11-09 18:01:37 [scrapy.extensions.logstats] INFO: Crawled 7893 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:03:21 [scrapy.extensions.logstats] INFO: Crawled 7893 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:03:45 [scrapy.extensions.logstats] INFO: Crawled 7900 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:04:32 [scrapy.extensions.logstats] INFO: Crawled 7903 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:06:00 [scrapy.extensions.logstats] INFO: Crawled 7903 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:07:12 [scrapy.extensions.logstats] INFO: Crawled 7903 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:07:32 [scrapy.extensions.logstats] INFO: Crawled 7909 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:09:38 [scrapy.extensions.logstats] INFO: Crawled 7911 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:10:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://d1io3yog0oux5.cloudfront.net/_b9e40ab5bf67df15aa3bc2e23d8c21dd/conversionlabs/db/235/875/pdf/CVLB+One+Pager+Q4+2018.pdf>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://d1io3yog0oux5.cloudfront.net/_b9e40ab5bf67df15aa3bc2e23d8c21dd/conversionlabs/db/235/875/pdf/CVLB+One+Pager+Q4+2018.pdf took longer than 15.0 seconds..
2019-11-09 18:11:03 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: innovScrapyCode)
2019-11-09 18:11:03 [scrapy.utils.log] INFO: Overridden settings: {'AJAXCRAWL_ENABLED': True, 'BOT_NAME': 'innovScrapyCode', 'CONCURRENT_REQUESTS': 160, 'CONCURRENT_REQUESTS_PER_DOMAIN': 32, 'DEPTH_LIMIT': 5, 'DEPTH_PRIORITY': 1, 'DOWNLOAD_DELAY': 2, 'DOWNLOAD_MAXSIZE': 5242880, 'DOWNLOAD_TIMEOUT': 15, 'LOG_FILE': 'NAICS01P4.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'innovationScraping.innovScrapyTools.innovScrapyCode.spiders', 'REACTOR_THREADPOOL_MAXSIZE': 100, 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['innovationScraping.innovScrapyTools.innovScrapyCode.spiders'], 'TELNETCONSOLE_PORT': None}
2019-11-09 18:11:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats', 'scrapy.extensions.logstats.LogStats']
2019-11-09 18:11:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy_fake_useragent.middleware.RandomUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.ajaxcrawl.AjaxCrawlMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-09 18:11:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-09 18:11:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-11-09 18:11:04 [scrapy.core.engine] INFO: Spider opened
2019-11-09 18:11:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:11:04 [root] INFO: spider 4 start
2019-11-09 18:11:24 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://www.coscojuvenile.com/robots.txt>: DNS lookup failed: no results for hostname lookup: www.coscojuvenile.com.
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: www.coscojuvenile.com.
2019-11-09 18:11:24 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://www.iam.delphi.com/robots.txt>: DNS lookup failed: no results for hostname lookup: www.iam.delphi.com.
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: www.iam.delphi.com.
2019-11-09 18:11:24 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://www.global.dcshoes.com/robots.txt>: DNS lookup failed: no results for hostname lookup: www.global.dcshoes.com.
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: www.global.dcshoes.com.
2019-11-09 18:11:47 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://www.countryhomeproducts.com/robots.txt>: User timeout caused connection failure: Getting https://www.countryhomeproducts.com/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.countryhomeproducts.com/robots.txt took longer than 15.0 seconds..
2019-11-09 18:13:10 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://www.combatbaseball.com/robots.txt>: User timeout caused connection failure: Getting https://www.combatbaseball.com/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.combatbaseball.com/robots.txt took longer than 15.0 seconds..
2019-11-09 18:13:10 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://www.cnd.com/robots.txt>: User timeout caused connection failure: Getting https://cnd.com/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://cnd.com/robots.txt took longer than 15.0 seconds..
2019-11-09 18:13:10 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://comfortresearch.com/robots.txt>: User timeout caused connection failure: Getting http://comfortresearch.com/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://comfortresearch.com/robots.txt took longer than 15.0 seconds..
2019-11-09 18:13:10 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET https://cvsciences.com/robots.txt>: User timeout caused connection failure: Getting https://cvsciences.com/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://cvsciences.com/robots.txt took longer than 15.0 seconds..
2019-11-09 18:13:10 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://dana.com/robots.txt>: User timeout caused connection failure.
twisted.internet.error.TimeoutError: User timeout caused connection failure.
2019-11-09 18:13:10 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://www.definitivetech.com/robots.txt>: User timeout caused connection failure: Getting https://www.definitivetechnology.com/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.definitivetechnology.com/robots.txt took longer than 15.0 seconds..
2019-11-09 18:13:10 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://www.usa.denon.com/robots.txt>: User timeout caused connection failure: Getting http://usa.denon.com/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://usa.denon.com/robots.txt took longer than 15.0 seconds..
2019-11-09 18:13:10 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://www.designerwhey.com/robots.txt>: User timeout caused connection failure: Getting https://designerprotein.com/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://designerprotein.com/robots.txt took longer than 15.0 seconds..
2019-11-09 18:13:10 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://www.daymak.com/robots.txt>: User timeout caused connection failure: Getting http://daymak.com/ took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://daymak.com/ took longer than 15.0 seconds..
2019-11-09 18:13:10 [scrapy.extensions.logstats] INFO: Crawled 92 pages (at 92 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:16:22 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET https://delta-q.com/robots.txt>: User timeout caused connection failure: Getting https://delta-q.com/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://delta-q.com/robots.txt took longer than 15.0 seconds..
2019-11-09 18:16:22 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://www.coopertire.com/robots.txt>: User timeout caused connection failure: Getting http://ca.coopertire.com took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://ca.coopertire.com took longer than 15.0 seconds..
2019-11-09 18:16:22 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://www.dinancars.com/robots.txt>: User timeout caused connection failure: Getting https://www.dinancars.com/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.dinancars.com/robots.txt took longer than 15.0 seconds..
2019-11-09 18:16:22 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://www.darlinghomes.com/robots.txt>: User timeout caused connection failure: Getting https://www.taylormorrison.com/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.taylormorrison.com/robots.txt took longer than 15.0 seconds..
2019-11-09 18:16:22 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET https://cooltechnologiesinc.com/robots.txt>: User timeout caused connection failure: Getting https://cooltechnologiesinc.com/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://cooltechnologiesinc.com/robots.txt took longer than 15.0 seconds..
2019-11-09 18:16:22 [scrapy.extensions.logstats] INFO: Crawled 106 pages (at 14 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:17:51 [scrapy.extensions.logstats] INFO: Crawled 109 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:18:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://corellebrands.com/>: User timeout caused connection failure.
2019-11-09 18:18:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://naturalskincare.com/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://naturalskincare.com/ took longer than 15.0 seconds..
2019-11-09 18:18:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.crestliner.com/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.crestliner.com/ took longer than 15.0 seconds..
2019-11-09 18:18:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.delsol.com/>: User timeout caused connection failure.
2019-11-09 18:18:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cozziausa.com/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.cozziausa.com/ took longer than 15.0 seconds..
2019-11-09 18:18:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cumminswestport.com/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.cumminswestport.com/ took longer than 15.0 seconds..
2019-11-09 18:18:21 [scrapy.extensions.logstats] INFO: Crawled 109 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:18:21 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET https://curtisindustries.net/robots.txt>: User timeout caused connection failure: Getting https://curtisindustries.net/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://curtisindustries.net/robots.txt took longer than 15.0 seconds..
2019-11-09 18:18:21 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://www.crocs.ca/robots.txt>: User timeout caused connection failure: Getting http://www.crocs.ca/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.crocs.ca/robots.txt took longer than 15.0 seconds..
2019-11-09 18:18:21 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET https://comstockcompanies.com/robots.txt>: User timeout caused connection failure: Getting https://comstockcompanies.com/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://comstockcompanies.com/robots.txt took longer than 15.0 seconds..
2019-11-09 18:18:21 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://contour.com/robots.txt>: User timeout caused connection failure: Getting http://contour.com/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://contour.com/robots.txt took longer than 15.0 seconds..
2019-11-09 18:18:47 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET https://www.dermalogica.ca/robots.txt>: User timeout caused connection failure: Getting https://www.dermalogica.ca/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.dermalogica.ca/robots.txt took longer than 15.0 seconds..
2019-11-09 18:18:47 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET https://world.dvf.com/robots.txt>: User timeout caused connection failure: Getting https://world.dvf.com/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://world.dvf.com/robots.txt took longer than 15.0 seconds..
2019-11-09 18:18:47 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET https://designerprotein.com/robots.txt>: User timeout caused connection failure: Getting https://designerprotein.com/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://designerprotein.com/robots.txt took longer than 15.0 seconds..
2019-11-09 18:18:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://ctiindustries.com/>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-09 18:18:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://conedenim.com/>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-09 18:18:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.drhorton.com/>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-09 18:18:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.daysofwonder.com/en/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.daysofwonder.com/en/ took longer than 15.0 seconds..
2019-11-09 18:18:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cybexintl.com/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.cybexintl.com/ took longer than 15.0 seconds..
2019-11-09 18:18:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.lowepro.com/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.lowepro.com/ took longer than 15.0 seconds..
2019-11-09 18:18:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://cvsciences.com/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://cvsciences.com/ took longer than 15.0 seconds..
2019-11-09 18:18:47 [scrapy.core.scraper] ERROR: Error downloading <GET http://comfortresearch.com/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://comfortresearch.com/ took longer than 15.0 seconds..
2019-11-09 18:18:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.combatbaseball.com/>: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'ssl3_read_bytes', 'sslv3 alert handshake failure')]>]
2019-11-09 18:19:17 [scrapy.extensions.logstats] INFO: Crawled 121 pages (at 12 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:20:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://cooltechnologiesinc.com/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://cooltechnologiesinc.com/ took longer than 15.0 seconds..
2019-11-09 18:20:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://delta-q.com/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://delta-q.com/ took longer than 15.0 seconds..
2019-11-09 18:20:40 [scrapy.extensions.logstats] INFO: Crawled 128 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:22:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://comstockcompanies.com/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://comstockcompanies.com/ took longer than 15.0 seconds..
2019-11-09 18:22:34 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET https://producttesting.columbia.com/robots.txt>: User timeout caused connection failure.
twisted.internet.error.TimeoutError: User timeout caused connection failure.
2019-11-09 18:22:34 [scrapy.extensions.logstats] INFO: Crawled 128 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:25:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.crocs.ca/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.crocs.ca/ took longer than 15.0 seconds..
2019-11-09 18:25:13 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET https://www.taylormorrison.com/robots.txt>: User timeout caused connection failure: Getting https://www.taylormorrison.com/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.taylormorrison.com/robots.txt took longer than 15.0 seconds..
2019-11-09 18:25:13 [scrapy.extensions.logstats] INFO: Crawled 128 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:27:04 [scrapy.extensions.logstats] INFO: Crawled 136 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:27:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.taylormorrison.com/discover-darling>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.taylormorrison.com/discover-darling took longer than 15.0 seconds..
2019-11-09 18:28:48 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://store.contour.com/robots.txt>: User timeout caused connection failure: Getting https://store.contour.com/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://store.contour.com/robots.txt took longer than 15.0 seconds..
2019-11-09 18:28:48 [scrapy.extensions.logstats] INFO: Crawled 140 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:30:44 [scrapy.extensions.logstats] INFO: Crawled 140 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:31:05 [scrapy.extensions.logstats] INFO: Crawled 146 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:33:12 [scrapy.extensions.logstats] INFO: Crawled 155 pages (at 9 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:34:46 [scrapy.extensions.logstats] INFO: Crawled 159 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:36:02 [scrapy.extensions.logstats] INFO: Crawled 159 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:37:23 [scrapy.extensions.logstats] INFO: Crawled 159 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:38:44 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://www.columbiasportswear.ca/robots.txt>: User timeout caused connection failure: Getting https://www.columbiasportswear.ca/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.columbiasportswear.ca/robots.txt took longer than 15.0 seconds..
2019-11-09 18:38:44 [scrapy.extensions.logstats] INFO: Crawled 169 pages (at 10 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:40:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://store.contour.com/collections/accessories/products/contour-battery>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://store.contour.com/collections/accessories/products/contour-battery took longer than 15.0 seconds..
2019-11-09 18:40:38 [scrapy.extensions.logstats] INFO: Crawled 169 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:41:06 [scrapy.extensions.logstats] INFO: Crawled 172 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:42:52 [scrapy.extensions.logstats] INFO: Crawled 176 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:43:39 [scrapy.extensions.logstats] INFO: Crawled 178 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:44:29 [scrapy.extensions.logstats] INFO: Crawled 179 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:45:28 [scrapy.extensions.logstats] INFO: Crawled 182 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:45:58 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET https://www.fieldinghomes.com/robots.txt>: User timeout caused connection failure: Getting https://www.fieldinghomes.com/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.fieldinghomes.com/robots.txt took longer than 15.0 seconds..
2019-11-09 18:46:29 [scrapy.extensions.logstats] INFO: Crawled 185 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:46:29 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://www.elevate-homes.com/robots.txt>: User timeout caused connection failure.
twisted.internet.error.TimeoutError: User timeout caused connection failure.
2019-11-09 18:47:49 [scrapy.extensions.logstats] INFO: Crawled 185 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:48:13 [scrapy.extensions.logstats] INFO: Crawled 188 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:49:09 [scrapy.extensions.logstats] INFO: Crawled 192 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:49:35 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.elevate-homes.com/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.elevate-homes.com/ took longer than 15.0 seconds..
2019-11-09 18:50:31 [scrapy.extensions.logstats] INFO: Crawled 194 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:51:24 [scrapy.extensions.logstats] INFO: Crawled 198 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:52:17 [scrapy.extensions.logstats] INFO: Crawled 200 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:53:15 [scrapy.extensions.logstats] INFO: Crawled 202 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:54:12 [scrapy.extensions.logstats] INFO: Crawled 202 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:55:11 [scrapy.extensions.logstats] INFO: Crawled 202 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:56:30 [scrapy.extensions.logstats] INFO: Crawled 208 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:57:51 [scrapy.extensions.logstats] INFO: Crawled 211 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:59:14 [scrapy.extensions.logstats] INFO: Crawled 213 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 18:59:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://store.contour.com/collections/parts>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://store.contour.com/collections/parts took longer than 15.0 seconds..
2019-11-09 19:00:08 [scrapy.extensions.logstats] INFO: Crawled 215 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:01:28 [scrapy.extensions.logstats] INFO: Crawled 219 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:02:50 [scrapy.extensions.logstats] INFO: Crawled 219 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:02:50 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET https://uk.dvf.com/robots.txt>: User timeout caused connection failure: Getting https://uk.dvf.com/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uk.dvf.com/robots.txt took longer than 15.0 seconds..
2019-11-09 19:03:14 [scrapy.extensions.logstats] INFO: Crawled 221 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:04:07 [scrapy.extensions.logstats] INFO: Crawled 226 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:04:34 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://help.contour.com/robots.txt>: User timeout caused connection failure: Getting http://help.contour.com/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://help.contour.com/robots.txt took longer than 15.0 seconds..
2019-11-09 19:05:57 [scrapy.extensions.logstats] INFO: Crawled 229 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:07:23 [scrapy.extensions.logstats] INFO: Crawled 229 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:08:59 [scrapy.extensions.logstats] INFO: Crawled 237 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:10:35 [scrapy.extensions.logstats] INFO: Crawled 241 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:11:42 [scrapy.extensions.logstats] INFO: Crawled 244 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:12:37 [scrapy.extensions.logstats] INFO: Crawled 248 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:13:58 [scrapy.extensions.logstats] INFO: Crawled 252 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:15:17 [scrapy.extensions.logstats] INFO: Crawled 256 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:16:58 [scrapy.extensions.logstats] INFO: Crawled 257 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:17:26 [scrapy.extensions.logstats] INFO: Crawled 259 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:18:18 [scrapy.extensions.logstats] INFO: Crawled 261 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:19:13 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET https://assets.curtmfg.com/robots.txt>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-09 19:19:13 [scrapy.extensions.logstats] INFO: Crawled 263 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:20:14 [scrapy.extensions.logstats] INFO: Crawled 265 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:21:30 [scrapy.extensions.logstats] INFO: Crawled 268 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:22:21 [scrapy.extensions.logstats] INFO: Crawled 270 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:23:12 [scrapy.extensions.logstats] INFO: Crawled 272 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:24:38 [scrapy.extensions.logstats] INFO: Crawled 274 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:25:16 [scrapy.extensions.logstats] INFO: Crawled 278 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:26:13 [scrapy.extensions.logstats] INFO: Crawled 282 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:26:13 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET https://hk.dvf.com/robots.txt>: User timeout caused connection failure.
twisted.internet.error.TimeoutError: User timeout caused connection failure.
2019-11-09 19:27:10 [scrapy.extensions.logstats] INFO: Crawled 285 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:28:08 [scrapy.extensions.logstats] INFO: Crawled 286 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:29:32 [scrapy.extensions.logstats] INFO: Crawled 291 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:30:32 [scrapy.extensions.logstats] INFO: Crawled 296 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:30:58 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET https://blog.columbia.com/robots.txt>: User timeout caused connection failure: Getting https://blog.columbia.com/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://blog.columbia.com/robots.txt took longer than 15.0 seconds..
2019-11-09 19:32:11 [scrapy.extensions.logstats] INFO: Crawled 297 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:33:07 [scrapy.extensions.logstats] INFO: Crawled 299 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:34:05 [scrapy.extensions.logstats] INFO: Crawled 301 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:35:24 [scrapy.extensions.logstats] INFO: Crawled 304 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:36:16 [scrapy.extensions.logstats] INFO: Crawled 306 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:37:09 [scrapy.extensions.logstats] INFO: Crawled 308 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:38:23 [scrapy.extensions.logstats] INFO: Crawled 311 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:39:17 [scrapy.extensions.logstats] INFO: Crawled 313 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:40:12 [scrapy.extensions.logstats] INFO: Crawled 317 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:41:30 [scrapy.extensions.logstats] INFO: Crawled 320 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:42:23 [scrapy.extensions.logstats] INFO: Crawled 321 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:43:23 [scrapy.extensions.logstats] INFO: Crawled 326 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:44:13 [scrapy.extensions.logstats] INFO: Crawled 326 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:45:30 [scrapy.extensions.logstats] INFO: Crawled 326 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:46:09 [scrapy.extensions.logstats] INFO: Crawled 330 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:47:58 [scrapy.extensions.logstats] INFO: Crawled 336 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:48:46 [scrapy.extensions.logstats] INFO: Crawled 336 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:49:41 [scrapy.extensions.logstats] INFO: Crawled 336 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:50:05 [scrapy.extensions.logstats] INFO: Crawled 339 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:53:09 [scrapy.extensions.logstats] INFO: Crawled 348 pages (at 9 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:54:52 [scrapy.extensions.logstats] INFO: Crawled 351 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:56:12 [scrapy.extensions.logstats] INFO: Crawled 351 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:57:35 [scrapy.extensions.logstats] INFO: Crawled 357 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 19:59:00 [scrapy.extensions.logstats] INFO: Crawled 360 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:00:30 [scrapy.extensions.logstats] INFO: Crawled 363 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:01:42 [scrapy.extensions.logstats] INFO: Crawled 365 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:02:19 [scrapy.extensions.logstats] INFO: Crawled 368 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:03:14 [scrapy.extensions.logstats] INFO: Crawled 374 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:04:30 [scrapy.extensions.logstats] INFO: Crawled 377 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:05:54 [scrapy.extensions.logstats] INFO: Crawled 380 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:06:49 [scrapy.extensions.logstats] INFO: Crawled 380 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:07:08 [scrapy.extensions.logstats] INFO: Crawled 382 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:08:21 [scrapy.extensions.logstats] INFO: Crawled 391 pages (at 9 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:09:14 [scrapy.extensions.logstats] INFO: Crawled 391 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:10:10 [scrapy.extensions.logstats] INFO: Crawled 391 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:11:04 [scrapy.extensions.logstats] INFO: Crawled 397 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:12:15 [scrapy.extensions.logstats] INFO: Crawled 400 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:14:50 [scrapy.extensions.logstats] INFO: Crawled 406 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:16:07 [scrapy.extensions.logstats] INFO: Crawled 409 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:17:26 [scrapy.extensions.logstats] INFO: Crawled 411 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:18:17 [scrapy.extensions.logstats] INFO: Crawled 414 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:19:40 [scrapy.extensions.logstats] INFO: Crawled 415 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:20:47 [scrapy.extensions.logstats] INFO: Crawled 419 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:21:38 [scrapy.extensions.logstats] INFO: Crawled 421 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:22:31 [scrapy.extensions.logstats] INFO: Crawled 423 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:23:23 [scrapy.extensions.logstats] INFO: Crawled 425 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:24:16 [scrapy.extensions.logstats] INFO: Crawled 427 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:25:06 [scrapy.extensions.logstats] INFO: Crawled 429 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:26:49 [scrapy.extensions.logstats] INFO: Crawled 433 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:27:44 [scrapy.extensions.logstats] INFO: Crawled 434 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:28:09 [scrapy.extensions.logstats] INFO: Crawled 435 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:28:36 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.columbiasportswear.ca/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.columbiasportswear.ca/ took longer than 15.0 seconds..
2019-11-09 20:29:59 [scrapy.extensions.logstats] INFO: Crawled 439 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:30:27 [scrapy.extensions.logstats] INFO: Crawled 440 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:31:12 [scrapy.extensions.logstats] INFO: Crawled 442 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:31:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.dvf.com/philanthropy/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.dvf.com/philanthropy/ took longer than 15.0 seconds..
2019-11-09 20:32:07 [scrapy.extensions.logstats] INFO: Crawled 447 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:32:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://uk.dvf.com/on/demandware.store/Sites-DvF_UK-Site/default/Home-Page>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uk.dvf.com/on/demandware.store/Sites-DvF_UK-Site/default/Home-Page took longer than 15.0 seconds..
2019-11-09 20:33:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://hk.dvf.com/on/demandware.store/Sites-DvF_HK-Site/default/Home-Page>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://hk.dvf.com/on/demandware.store/Sites-DvF_HK-Site/default/Home-Page took longer than 15.0 seconds..
2019-11-09 20:33:19 [scrapy.extensions.logstats] INFO: Crawled 449 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:34:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.dvf.com/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.dvf.com/ took longer than 15.0 seconds..
2019-11-09 20:34:10 [scrapy.extensions.logstats] INFO: Crawled 449 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:35:32 [scrapy.extensions.logstats] INFO: Crawled 454 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:36:30 [scrapy.extensions.logstats] INFO: Crawled 456 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:37:25 [scrapy.extensions.logstats] INFO: Crawled 456 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:38:17 [scrapy.extensions.logstats] INFO: Crawled 459 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:39:23 [scrapy.extensions.logstats] INFO: Crawled 463 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:40:37 [scrapy.extensions.logstats] INFO: Crawled 467 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:41:13 [scrapy.extensions.logstats] INFO: Crawled 469 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:42:39 [scrapy.extensions.logstats] INFO: Crawled 473 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:43:38 [scrapy.extensions.logstats] INFO: Crawled 475 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:44:34 [scrapy.extensions.logstats] INFO: Crawled 477 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:45:29 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET https://shop.demarini.com/robots.txt>: User timeout caused connection failure: Getting https://shop.demarini.com/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://shop.demarini.com/robots.txt took longer than 15.0 seconds..
2019-11-09 20:45:29 [scrapy.extensions.logstats] INFO: Crawled 479 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:46:18 [scrapy.extensions.logstats] INFO: Crawled 481 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:47:55 [scrapy.extensions.logstats] INFO: Crawled 485 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:48:50 [scrapy.extensions.logstats] INFO: Crawled 487 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:49:44 [scrapy.extensions.logstats] INFO: Crawled 489 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:50:21 [scrapy.extensions.logstats] INFO: Crawled 491 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:51:20 [scrapy.extensions.logstats] INFO: Crawled 495 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:52:36 [scrapy.extensions.logstats] INFO: Crawled 497 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:53:36 [scrapy.extensions.logstats] INFO: Crawled 497 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:54:29 [scrapy.extensions.logstats] INFO: Crawled 503 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:56:19 [scrapy.extensions.logstats] INFO: Crawled 503 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:57:11 [scrapy.extensions.logstats] INFO: Crawled 509 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:58:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demarini.com/en-us/help/bat-warranty>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demarini.com/en-us/help/bat-warranty took longer than 15.0 seconds..
2019-11-09 20:58:54 [scrapy.extensions.logstats] INFO: Crawled 509 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 20:59:13 [scrapy.extensions.logstats] INFO: Crawled 513 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:00:08 [scrapy.extensions.logstats] INFO: Crawled 519 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:01:56 [scrapy.extensions.logstats] INFO: Crawled 525 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:03:22 [scrapy.extensions.logstats] INFO: Crawled 525 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:04:43 [scrapy.extensions.logstats] INFO: Crawled 525 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:05:11 [scrapy.extensions.logstats] INFO: Crawled 529 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:06:28 [scrapy.extensions.logstats] INFO: Crawled 533 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:08:23 [scrapy.extensions.logstats] INFO: Crawled 533 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:09:16 [scrapy.extensions.logstats] INFO: Crawled 541 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:10:12 [scrapy.extensions.logstats] INFO: Crawled 544 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:12:00 [scrapy.extensions.logstats] INFO: Crawled 547 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:14:10 [scrapy.extensions.logstats] INFO: Crawled 549 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:15:29 [scrapy.extensions.logstats] INFO: Crawled 549 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:16:24 [scrapy.extensions.logstats] INFO: Crawled 554 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:17:45 [scrapy.extensions.logstats] INFO: Crawled 554 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:18:12 [scrapy.extensions.logstats] INFO: Crawled 559 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:19:33 [scrapy.extensions.logstats] INFO: Crawled 564 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:21:44 [scrapy.extensions.logstats] INFO: Crawled 564 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:22:14 [scrapy.extensions.logstats] INFO: Crawled 568 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:23:33 [scrapy.extensions.logstats] INFO: Crawled 571 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:24:56 [scrapy.extensions.logstats] INFO: Crawled 571 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:25:20 [scrapy.extensions.logstats] INFO: Crawled 574 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:26:17 [scrapy.extensions.logstats] INFO: Crawled 577 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:27:19 [scrapy.extensions.logstats] INFO: Crawled 577 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:28:33 [scrapy.extensions.logstats] INFO: Crawled 583 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:29:10 [scrapy.extensions.logstats] INFO: Crawled 583 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:30:04 [scrapy.extensions.logstats] INFO: Crawled 589 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:31:00 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.crabtree-evelyn.com/%redirect_store_url%>: HTTP status code is not handled or not allowed
2019-11-09 21:31:18 [scrapy.extensions.logstats] INFO: Crawled 593 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:32:14 [scrapy.extensions.logstats] INFO: Crawled 599 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:33:09 [scrapy.extensions.logstats] INFO: Crawled 602 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:34:22 [scrapy.extensions.logstats] INFO: Crawled 605 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:35:43 [scrapy.extensions.logstats] INFO: Crawled 605 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:37:10 [scrapy.extensions.logstats] INFO: Crawled 605 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:38:13 [scrapy.extensions.logstats] INFO: Crawled 614 pages (at 9 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:40:33 [scrapy.extensions.logstats] INFO: Crawled 614 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:41:51 [scrapy.extensions.logstats] INFO: Crawled 626 pages (at 12 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:42:44 [scrapy.extensions.logstats] INFO: Crawled 626 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:44:54 [scrapy.extensions.logstats] INFO: Crawled 626 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:45:22 [scrapy.extensions.logstats] INFO: Crawled 632 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:46:45 [scrapy.extensions.logstats] INFO: Crawled 636 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:47:36 [scrapy.extensions.logstats] INFO: Crawled 636 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:49:27 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://shop.deltachildren.com/robots.txt>: User timeout caused connection failure: Getting http://shop.deltachildren.com/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://shop.deltachildren.com/robots.txt took longer than 15.0 seconds..
2019-11-09 21:49:27 [scrapy.extensions.logstats] INFO: Crawled 636 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:50:52 [scrapy.extensions.logstats] INFO: Crawled 644 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:51:21 [scrapy.extensions.logstats] INFO: Crawled 644 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:51:21 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/robots.txt>: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/robots.txt took longer than 15.0 seconds..
2019-11-09 21:53:09 [scrapy.extensions.logstats] INFO: Crawled 644 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:55:04 [scrapy.extensions.logstats] INFO: Crawled 657 pages (at 13 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:55:04 [scrapy.extensions.logstats] INFO: Crawled 657 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:57:02 [scrapy.extensions.logstats] INFO: Crawled 661 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:58:29 [scrapy.extensions.logstats] INFO: Crawled 665 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 21:59:25 [scrapy.extensions.logstats] INFO: Crawled 669 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:00:21 [scrapy.extensions.logstats] INFO: Crawled 669 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:02:08 [scrapy.extensions.logstats] INFO: Crawled 670 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:03:24 [scrapy.extensions.logstats] INFO: Crawled 673 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:04:16 [scrapy.extensions.logstats] INFO: Crawled 675 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:05:07 [scrapy.extensions.logstats] INFO: Crawled 677 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:06:30 [scrapy.extensions.logstats] INFO: Crawled 680 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:07:23 [scrapy.extensions.logstats] INFO: Crawled 682 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:07:23 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://the.dermaflash.com/robots.txt>: User timeout caused connection failure: Getting http://the.dermaflash.com/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/robots.txt took longer than 15.0 seconds..
2019-11-09 22:08:18 [scrapy.extensions.logstats] INFO: Crawled 688 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:09:12 [scrapy.extensions.logstats] INFO: Crawled 695 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:10:34 [scrapy.extensions.logstats] INFO: Crawled 695 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:13:38 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://coopertire.com/robots.txt>: User timeout caused connection failure: Getting http://coopertire.com/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://coopertire.com/robots.txt took longer than 15.0 seconds..
2019-11-09 22:13:38 [scrapy.extensions.logstats] INFO: Crawled 695 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:13:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.columbia.com/outdoor-jackets-coats/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.columbia.com/outdoor-jackets-coats/ took longer than 15.0 seconds..
2019-11-09 22:14:27 [scrapy.extensions.logstats] INFO: Crawled 712 pages (at 17 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:18:09 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://ca.coopertire.com/robots.txt>: User timeout caused connection failure: Getting http://ca.coopertire.com/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://ca.coopertire.com/robots.txt took longer than 15.0 seconds..
2019-11-09 22:18:09 [scrapy.extensions.logstats] INFO: Crawled 712 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:21:23 [scrapy.extensions.logstats] INFO: Crawled 712 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:21:23 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/press/>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2019-11-09 22:22:14 [scrapy.extensions.logstats] INFO: Crawled 729 pages (at 17 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:24:57 [scrapy.extensions.logstats] INFO: Crawled 729 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:28:26 [scrapy.extensions.logstats] INFO: Crawled 729 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:30:44 [scrapy.extensions.logstats] INFO: Crawled 749 pages (at 20 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:32:32 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=16185>: HTTP status code is not handled or not allowed
2019-11-09 22:32:32 [scrapy.extensions.logstats] INFO: Crawled 749 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:36:34 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://us.coopertire.com/robots.txt>: User timeout caused connection failure: Getting http://us.coopertire.com/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://us.coopertire.com/robots.txt took longer than 15.0 seconds..
2019-11-09 22:36:34 [scrapy.extensions.logstats] INFO: Crawled 749 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:36:59 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=16175>: HTTP status code is not handled or not allowed
2019-11-09 22:37:54 [scrapy.extensions.logstats] INFO: Crawled 764 pages (at 15 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:39:40 [scrapy.extensions.logstats] INFO: Crawled 764 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:42:53 [scrapy.extensions.logstats] INFO: Crawled 764 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:43:21 [scrapy.extensions.logstats] INFO: Crawled 772 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:45:37 [scrapy.extensions.logstats] INFO: Crawled 780 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:49:17 [scrapy.extensions.logstats] INFO: Crawled 780 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:50:42 [scrapy.extensions.logstats] INFO: Crawled 788 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:51:11 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=398>: HTTP status code is not handled or not allowed
2019-11-09 22:51:11 [scrapy.extensions.logstats] INFO: Crawled 792 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:52:37 [scrapy.extensions.logstats] INFO: Crawled 792 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:54:30 [scrapy.extensions.logstats] INFO: Crawled 792 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:55:29 [scrapy.extensions.logstats] INFO: Crawled 803 pages (at 11 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:55:49 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET https://cloud.3dissue.net/robots.txt>: User timeout caused connection failure: Getting https://cloud.3dissue.net/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://cloud.3dissue.net/robots.txt took longer than 15.0 seconds..
2019-11-09 22:58:28 [scrapy.extensions.logstats] INFO: Crawled 803 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 22:59:52 [scrapy.extensions.logstats] INFO: Crawled 814 pages (at 11 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:01:14 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=17756>: HTTP status code is not handled or not allowed
2019-11-09 23:01:14 [scrapy.extensions.logstats] INFO: Crawled 814 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:03:06 [scrapy.extensions.logstats] INFO: Crawled 814 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:03:31 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=17752>: HTTP status code is not handled or not allowed
2019-11-09 23:04:55 [scrapy.extensions.logstats] INFO: Crawled 824 pages (at 10 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:06:44 [scrapy.extensions.logstats] INFO: Crawled 824 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:07:11 [scrapy.extensions.logstats] INFO: Crawled 830 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:08:05 [scrapy.extensions.logstats] INFO: Crawled 836 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:09:28 [scrapy.extensions.logstats] INFO: Crawled 836 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:11:52 [scrapy.extensions.logstats] INFO: Crawled 836 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:12:21 [scrapy.extensions.logstats] INFO: Crawled 843 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:14:47 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=17714>: HTTP status code is not handled or not allowed
2019-11-09 23:14:47 [scrapy.extensions.logstats] INFO: Crawled 852 pages (at 9 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:16:41 [scrapy.extensions.logstats] INFO: Crawled 852 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:18:28 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET https://conversionlabs.com/robots.txt>: User timeout caused connection failure: Getting https://conversionlabs.com/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://conversionlabs.com/robots.txt took longer than 15.0 seconds..
2019-11-09 23:18:28 [scrapy.extensions.logstats] INFO: Crawled 852 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:20:47 [scrapy.extensions.logstats] INFO: Crawled 862 pages (at 10 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:22:37 [scrapy.extensions.logstats] INFO: Crawled 867 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:25:00 [scrapy.extensions.logstats] INFO: Crawled 871 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:26:56 [scrapy.extensions.logstats] INFO: Crawled 874 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:28:22 [scrapy.extensions.logstats] INFO: Crawled 878 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:29:53 [scrapy.extensions.logstats] INFO: Crawled 882 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:31:49 [scrapy.extensions.logstats] INFO: Crawled 885 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:33:22 [scrapy.extensions.logstats] INFO: Crawled 889 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:33:22 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://ir.deckers.com/robots.txt>: User timeout caused connection failure: Getting http://ir.deckers.com/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://ir.deckers.com/robots.txt took longer than 15.0 seconds..
2019-11-09 23:35:17 [scrapy.extensions.logstats] INFO: Crawled 893 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:37:12 [scrapy.extensions.logstats] INFO: Crawled 894 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:39:07 [scrapy.extensions.logstats] INFO: Crawled 899 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:40:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://conversionlabs.com/join/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://conversionlabs.com/join/ took longer than 15.0 seconds..
2019-11-09 23:40:51 [scrapy.extensions.logstats] INFO: Crawled 904 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:41:18 [scrapy.extensions.logstats] INFO: Crawled 907 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:42:18 [scrapy.extensions.logstats] INFO: Crawled 907 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:43:12 [scrapy.extensions.logstats] INFO: Crawled 907 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:44:38 [scrapy.extensions.logstats] INFO: Crawled 919 pages (at 12 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:46:42 [scrapy.extensions.logstats] INFO: Crawled 919 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:48:54 [scrapy.extensions.logstats] INFO: Crawled 919 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:49:14 [scrapy.extensions.logstats] INFO: Crawled 924 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:51:07 [scrapy.extensions.logstats] INFO: Crawled 928 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:52:09 [scrapy.extensions.logstats] INFO: Crawled 928 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:54:56 [scrapy.extensions.logstats] INFO: Crawled 944 pages (at 16 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:57:30 [scrapy.extensions.logstats] INFO: Crawled 947 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-09 23:58:56 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://cyanotech.com/robots.txt>: User timeout caused connection failure.
twisted.internet.error.TimeoutError: User timeout caused connection failure.
2019-11-09 23:58:56 [scrapy.extensions.logstats] INFO: Crawled 947 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:00:28 [scrapy.extensions.logstats] INFO: Crawled 947 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:01:54 [scrapy.extensions.logstats] INFO: Crawled 958 pages (at 11 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:03:45 [scrapy.extensions.logstats] INFO: Crawled 963 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:05:23 [scrapy.extensions.logstats] INFO: Crawled 967 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:07:30 [scrapy.extensions.logstats] INFO: Crawled 967 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:08:57 [scrapy.extensions.logstats] INFO: Crawled 967 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:08:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cramco.net/static.aspx?pageId=4>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.cramco.net/static.aspx?pageId=4 took longer than 15.0 seconds..
2019-11-10 00:09:14 [scrapy.extensions.logstats] INFO: Crawled 970 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:09:59 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET https://deckers.wd5.myworkdayjobs.com/robots.txt>: User timeout caused connection failure: Getting https://deckers.wd5.myworkdayjobs.com/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://deckers.wd5.myworkdayjobs.com/robots.txt took longer than 15.0 seconds..
2019-11-10 00:11:39 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.coscojuvenile.com>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: www.coscojuvenile.com.
2019-11-10 00:11:40 [scrapy.extensions.logstats] INFO: Crawled 981 pages (at 11 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:12:53 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.iam.delphi.com/en-us>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: www.iam.delphi.com.
2019-11-10 00:12:53 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.global.dcshoes.com/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: www.global.dcshoes.com.
2019-11-10 00:12:53 [scrapy.extensions.logstats] INFO: Crawled 981 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:14:28 [scrapy.extensions.logstats] INFO: Crawled 981 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:15:27 [scrapy.extensions.logstats] INFO: Crawled 990 pages (at 9 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:16:15 [scrapy.extensions.logstats] INFO: Crawled 990 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:17:45 [scrapy.extensions.logstats] INFO: Crawled 990 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:18:10 [scrapy.extensions.logstats] INFO: Crawled 995 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:19:43 [scrapy.extensions.logstats] INFO: Crawled 1005 pages (at 10 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:22:42 [scrapy.extensions.logstats] INFO: Crawled 1007 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:24:41 [scrapy.extensions.logstats] INFO: Crawled 1009 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:25:39 [scrapy.extensions.logstats] INFO: Crawled 1009 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:26:37 [scrapy.extensions.logstats] INFO: Crawled 1009 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:27:06 [scrapy.extensions.logstats] INFO: Crawled 1014 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:29:00 [scrapy.extensions.logstats] INFO: Crawled 1017 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:30:28 [scrapy.extensions.logstats] INFO: Crawled 1017 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:31:25 [scrapy.extensions.logstats] INFO: Crawled 1031 pages (at 14 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:33:22 [scrapy.extensions.logstats] INFO: Crawled 1031 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:36:50 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET https://d1io3yog0oux5.cloudfront.net/robots.txt>: User timeout caused connection failure: Getting https://d1io3yog0oux5.cloudfront.net/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://d1io3yog0oux5.cloudfront.net/robots.txt took longer than 15.0 seconds..
2019-11-10 00:36:50 [scrapy.extensions.logstats] INFO: Crawled 1031 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:37:11 [scrapy.extensions.logstats] INFO: Crawled 1036 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:38:36 [scrapy.core.scraper] ERROR: Error downloading <GET http://ir.deckers.com>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://ir.deckers.com took longer than 15.0 seconds..
2019-11-10 00:38:37 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET https://www.drpower.com/robots.txt>: User timeout caused connection failure.
twisted.internet.error.TimeoutError: User timeout caused connection failure.
2019-11-10 00:38:37 [scrapy.extensions.logstats] INFO: Crawled 1041 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:40:32 [scrapy.extensions.logstats] INFO: Crawled 1041 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:40:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://cloud.3dissue.net/12234/12202/12250/11205/index.html>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://cloud.3dissue.net/12234/12202/12250/11205/index.html took longer than 15.0 seconds..
2019-11-10 00:40:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://deckers.wd5.myworkdayjobs.com/Deckers>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://deckers.wd5.myworkdayjobs.com/Deckers took longer than 15.0 seconds..
2019-11-10 00:40:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.drpower.com/pages/content/company>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.drpower.com/pages/content/company took longer than 15.0 seconds..
2019-11-10 00:41:31 [scrapy.extensions.logstats] INFO: Crawled 1053 pages (at 12 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:43:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://d1io3yog0oux5.cloudfront.net/_b9e40ab5bf67df15aa3bc2e23d8c21dd/conversionlabs/db/235/875/pdf/CVLB+One+Pager+Q4+2018.pdf>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://d1io3yog0oux5.cloudfront.net/_b9e40ab5bf67df15aa3bc2e23d8c21dd/conversionlabs/db/235/875/pdf/CVLB+One+Pager+Q4+2018.pdf took longer than 15.0 seconds..
2019-11-10 00:43:50 [scrapy.extensions.logstats] INFO: Crawled 1053 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:46:05 [scrapy.extensions.logstats] INFO: Crawled 1054 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:46:46 [scrapy.core.scraper] ERROR: Error downloading <GET http://ca.coopertire.com/where-to-start/help-me-choose>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://ca.coopertire.com/where-to-start/help-me-choose took longer than 15.0 seconds..
2019-11-10 00:47:07 [scrapy.core.scraper] ERROR: Error downloading <GET http://ca.coopertire.com/where-to-start/buying-new-tires>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://ca.coopertire.com/where-to-start/buying-new-tires took longer than 15.0 seconds..
2019-11-10 00:47:07 [scrapy.extensions.logstats] INFO: Crawled 1056 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:48:22 [scrapy.extensions.logstats] INFO: Crawled 1062 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:49:31 [scrapy.extensions.logstats] INFO: Crawled 1065 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:50:56 [scrapy.extensions.logstats] INFO: Crawled 1066 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:51:17 [scrapy.extensions.logstats] INFO: Crawled 1069 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:52:21 [scrapy.extensions.logstats] INFO: Crawled 1071 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:53:18 [scrapy.extensions.logstats] INFO: Crawled 1074 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:54:29 [scrapy.extensions.logstats] INFO: Crawled 1076 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:55:10 [scrapy.extensions.logstats] INFO: Crawled 1081 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:56:11 [scrapy.extensions.logstats] INFO: Crawled 1083 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:57:28 [scrapy.extensions.logstats] INFO: Crawled 1088 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:58:07 [scrapy.extensions.logstats] INFO: Crawled 1090 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 00:59:08 [scrapy.extensions.logstats] INFO: Crawled 1090 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:00:12 [scrapy.extensions.logstats] INFO: Crawled 1091 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:01:08 [scrapy.extensions.logstats] INFO: Crawled 1105 pages (at 14 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:02:29 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=17718>: HTTP status code is not handled or not allowed
2019-11-10 01:02:29 [scrapy.extensions.logstats] INFO: Crawled 1111 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:04:09 [scrapy.extensions.logstats] INFO: Crawled 1111 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:06:07 [scrapy.extensions.logstats] INFO: Crawled 1111 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:06:08 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=16149>: HTTP status code is not handled or not allowed
2019-11-10 01:07:07 [scrapy.extensions.logstats] INFO: Crawled 1122 pages (at 11 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:07:46 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=17754>: HTTP status code is not handled or not allowed
2019-11-10 01:08:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://support.crosman.com/hc>: User timeout caused connection failure.
2019-11-10 01:08:25 [scrapy.extensions.logstats] INFO: Crawled 1128 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:09:25 [scrapy.extensions.logstats] INFO: Crawled 1131 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:10:43 [scrapy.extensions.logstats] INFO: Crawled 1135 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:12:04 [scrapy.extensions.logstats] INFO: Crawled 1137 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:14:06 [scrapy.extensions.logstats] INFO: Crawled 1137 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:15:04 [scrapy.extensions.logstats] INFO: Crawled 1139 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:15:04 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=469>: HTTP status code is not handled or not allowed
2019-11-10 01:16:00 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://investors.coopertire.com/Cache/1001255655.PDF?O=PDF&T=&Y=&D=&FID=1001255655&iid=4008251. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2019-11-10 01:17:34 [scrapy.extensions.logstats] INFO: Crawled 1147 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:18:34 [scrapy.extensions.logstats] INFO: Crawled 1149 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:19:25 [scrapy.extensions.logstats] INFO: Crawled 1155 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:21:22 [scrapy.extensions.logstats] INFO: Crawled 1158 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:22:17 [scrapy.extensions.logstats] INFO: Crawled 1160 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:23:21 [scrapy.extensions.logstats] INFO: Crawled 1164 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:24:05 [scrapy.extensions.logstats] INFO: Crawled 1166 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:25:31 [scrapy.extensions.logstats] INFO: Crawled 1170 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:26:17 [scrapy.extensions.logstats] INFO: Crawled 1172 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:27:28 [scrapy.extensions.logstats] INFO: Crawled 1177 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:28:37 [scrapy.extensions.logstats] INFO: Crawled 1178 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:29:20 [scrapy.extensions.logstats] INFO: Crawled 1180 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:30:29 [scrapy.extensions.logstats] INFO: Crawled 1184 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:30:52 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://es.coopertire.com/robots.txt>: User timeout caused connection failure: Getting http://es.coopertire.com/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://es.coopertire.com/robots.txt took longer than 15.0 seconds..
2019-11-10 01:31:14 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.cnd.com>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.cnd.com took longer than 15.0 seconds..
2019-11-10 01:31:14 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.definitivetech.com>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.definitivetech.com took longer than 15.0 seconds..
2019-11-10 01:31:14 [scrapy.extensions.logstats] INFO: Crawled 1188 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:32:45 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.usa.denon.com/us>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.usa.denon.com/us took longer than 15.0 seconds..
2019-11-10 01:32:45 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.daymak.com>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.daymak.com took longer than 15.0 seconds..
2019-11-10 01:32:45 [scrapy.extensions.logstats] INFO: Crawled 1192 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:33:25 [scrapy.extensions.logstats] INFO: Crawled 1192 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:34:14 [scrapy.extensions.logstats] INFO: Crawled 1201 pages (at 9 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:35:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://investors.coopertire.com/Cache/1001255655.PDF?O=PDF&T=&Y=&D=&FID=1001255655&iid=4008251>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://investors.coopertire.com/Cache/1001255655.PDF?O=PDF&T=&Y=&D=&FID=1001255655&iid=4008251 took longer than 15.0 seconds..
2019-11-10 01:37:17 [scrapy.core.scraper] ERROR: Error downloading <GET http://investors.coopertire.com/Cache/1500124588.PDF?O=PDF&T=&Y=&D=&FID=1500124588&iid=4008251>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://investors.coopertire.com/Cache/1500124588.PDF?O=PDF&T=&Y=&D=&FID=1500124588&iid=4008251 took longer than 15.0 seconds..
2019-11-10 01:37:17 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:38:47 [scrapy.core.scraper] ERROR: Error downloading <GET http://investors.coopertire.com/Cache/397216042.PDF?O=PDF&T=&Y=&D=&FID=397216042&iid=4008251>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://investors.coopertire.com/Cache/397216042.PDF?O=PDF&T=&Y=&D=&FID=397216042&iid=4008251 took longer than 15.0 seconds..
2019-11-10 01:38:47 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:39:48 [scrapy.core.scraper] ERROR: Error downloading <GET http://investors.coopertire.com/Cache/396794591.pdf>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://investors.coopertire.com/Cache/396794591.pdf took longer than 15.0 seconds..
2019-11-10 01:39:48 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:40:32 [scrapy.core.scraper] ERROR: Error downloading <GET http://investors.coopertire.com/Cache/1001250332.PDF?O=PDF&T=&Y=&D=&FID=1001250332&iid=4008251>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://investors.coopertire.com/Cache/1001250332.PDF?O=PDF&T=&Y=&D=&FID=1001250332&iid=4008251 took longer than 15.0 seconds..
2019-11-10 01:40:32 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:41:14 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 10 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:42:36 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:45:06 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:47:09 [scrapy.extensions.logstats] INFO: Crawled 1226 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:48:32 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:50:12 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:51:49 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:53:49 [scrapy.extensions.logstats] INFO: Crawled 1242 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:54:21 [scrapy.extensions.logstats] INFO: Crawled 1246 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:55:29 [scrapy.extensions.logstats] INFO: Crawled 1246 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:57:21 [scrapy.extensions.logstats] INFO: Crawled 1246 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 01:58:20 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://ch.coopertire.com/robots.txt>: DNS lookup failed: no results for hostname lookup: ch.coopertire.com.
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: ch.coopertire.com.
2019-11-10 01:58:21 [scrapy.extensions.logstats] INFO: Crawled 1261 pages (at 15 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:00:25 [scrapy.extensions.logstats] INFO: Crawled 1264 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:03:57 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://es-co.coopertire.com/robots.txt>: User timeout caused connection failure: Getting http://es-co.coopertire.com/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://es-co.coopertire.com/robots.txt took longer than 15.0 seconds..
2019-11-10 02:03:57 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://es-cl.coopertire.com/robots.txt>: User timeout caused connection failure: Getting http://es-cl.coopertire.com/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://es-cl.coopertire.com/robots.txt took longer than 15.0 seconds..
2019-11-10 02:03:57 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://pt-br.coopertire.com/robots.txt>: User timeout caused connection failure.
twisted.internet.error.TimeoutError: User timeout caused connection failure.
2019-11-10 02:03:58 [scrapy.extensions.logstats] INFO: Crawled 1264 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:05:33 [scrapy.extensions.logstats] INFO: Crawled 1264 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:06:09 [scrapy.extensions.logstats] INFO: Crawled 1275 pages (at 11 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:11:25 [scrapy.extensions.logstats] INFO: Crawled 1280 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:14:05 [scrapy.extensions.logstats] INFO: Crawled 1280 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:15:04 [scrapy.extensions.logstats] INFO: Crawled 1290 pages (at 10 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:16:33 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=16186>: HTTP status code is not handled or not allowed
2019-11-10 02:16:33 [scrapy.extensions.logstats] INFO: Crawled 1296 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:18:34 [scrapy.extensions.logstats] INFO: Crawled 1302 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:21:30 [scrapy.extensions.logstats] INFO: Crawled 1304 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:24:34 [scrapy.extensions.logstats] INFO: Crawled 1304 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:25:28 [scrapy.extensions.logstats] INFO: Crawled 1304 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:25:58 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=399>: HTTP status code is not handled or not allowed
2019-11-10 02:26:57 [scrapy.extensions.logstats] INFO: Crawled 1325 pages (at 21 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:31:21 [scrapy.extensions.logstats] INFO: Crawled 1325 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:34:51 [scrapy.core.scraper] ERROR: Error downloading <GET http://coopertire.com/utility/contact-us.aspx>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://coopertire.com/utility/contact-us.aspx took longer than 15.0 seconds..
2019-11-10 02:34:51 [scrapy.extensions.logstats] INFO: Crawled 1325 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:34:51 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://wwww.dermaflash.com/robots.txt>: DNS lookup failed: no results for hostname lookup: wwww.dermaflash.com.
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: wwww.dermaflash.com.
2019-11-10 02:34:52 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=16191>: HTTP status code is not handled or not allowed
2019-11-10 02:35:11 [scrapy.extensions.logstats] INFO: Crawled 1332 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:36:57 [scrapy.extensions.logstats] INFO: Crawled 1339 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:40:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://coopertire.com/corporate-responsibility.aspx>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://coopertire.com/corporate-responsibility.aspx took longer than 15.0 seconds..
2019-11-10 02:40:03 [scrapy.extensions.logstats] INFO: Crawled 1339 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:40:33 [scrapy.extensions.logstats] INFO: Crawled 1350 pages (at 11 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:43:02 [scrapy.extensions.logstats] INFO: Crawled 1355 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:45:33 [scrapy.extensions.logstats] INFO: Crawled 1355 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:47:53 [scrapy.extensions.logstats] INFO: Crawled 1355 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:48:22 [scrapy.extensions.logstats] INFO: Crawled 1362 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:49:22 [scrapy.extensions.logstats] INFO: Crawled 1369 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:51:09 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=16146>: HTTP status code is not handled or not allowed
2019-11-10 02:51:09 [scrapy.extensions.logstats] INFO: Crawled 1369 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:54:09 [scrapy.extensions.logstats] INFO: Crawled 1370 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:54:09 [scrapy.core.scraper] ERROR: Error downloading <GET http://coopertire.com/corporate-responsibility/cooper-tire-rubber-foundation>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://coopertire.com/corporate-responsibility/cooper-tire-rubber-foundation took longer than 15.0 seconds..
2019-11-10 02:55:14 [scrapy.core.scraper] ERROR: Error downloading <GET http://coopertire.com/our-brands>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://coopertire.com/our-brands took longer than 15.0 seconds..
2019-11-10 02:55:14 [scrapy.extensions.logstats] INFO: Crawled 1371 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:55:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demers-ambulances.com/about/videos/archive/2018/October/>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 02:55:14 [scrapy.core.scraper] ERROR: Error downloading <GET http://coopertire.com/about/quality-and-safety>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://coopertire.com/about/quality-and-safety took longer than 15.0 seconds..
2019-11-10 02:57:16 [scrapy.extensions.logstats] INFO: Crawled 1385 pages (at 14 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 02:58:49 [scrapy.extensions.logstats] INFO: Crawled 1385 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:02:14 [scrapy.core.scraper] ERROR: Error downloading <GET http://coopertire.com/careers>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://coopertire.com/careers took longer than 15.0 seconds..
2019-11-10 03:02:14 [scrapy.extensions.logstats] INFO: Crawled 1385 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:04:12 [scrapy.extensions.logstats] INFO: Crawled 1393 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:05:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.deltaapparelinc.com/news-media/overview>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.deltaapparelinc.com/news-media/overview took longer than 15.0 seconds..
2019-11-10 03:05:40 [scrapy.extensions.logstats] INFO: Crawled 1395 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:06:30 [scrapy.extensions.logstats] INFO: Crawled 1395 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:07:04 [scrapy.extensions.logstats] INFO: Crawled 1405 pages (at 10 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:09:34 [scrapy.extensions.logstats] INFO: Crawled 1413 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:11:34 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=17763>: HTTP status code is not handled or not allowed
2019-11-10 03:11:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.dinancars.com/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.dinancars.com/ took longer than 15.0 seconds..
2019-11-10 03:11:34 [scrapy.extensions.logstats] INFO: Crawled 1413 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:14:48 [scrapy.extensions.logstats] INFO: Crawled 1413 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:14:48 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=17799>: HTTP status code is not handled or not allowed
2019-11-10 03:15:16 [scrapy.extensions.logstats] INFO: Crawled 1421 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:18:22 [scrapy.extensions.logstats] INFO: Crawled 1428 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:22:03 [scrapy.extensions.logstats] INFO: Crawled 1428 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:22:04 [scrapy.extensions.logstats] INFO: Crawled 1431 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:22:04 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=16176>: HTTP status code is not handled or not allowed
2019-11-10 03:23:31 [scrapy.extensions.logstats] INFO: Crawled 1443 pages (at 12 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:25:31 [scrapy.extensions.logstats] INFO: Crawled 1443 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:28:58 [scrapy.core.scraper] ERROR: Error downloading <GET http://us.coopertire.com/tires/featured-tires?vehicletype=truck>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://us.coopertire.com/tires/featured-tires?vehicletype=truck took longer than 15.0 seconds..
2019-11-10 03:28:58 [scrapy.extensions.logstats] INFO: Crawled 1443 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:29:24 [scrapy.extensions.logstats] INFO: Crawled 1448 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:30:06 [scrapy.extensions.logstats] INFO: Crawled 1450 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:31:05 [scrapy.extensions.logstats] INFO: Crawled 1452 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:32:49 [scrapy.extensions.logstats] INFO: Crawled 1454 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:33:21 [scrapy.extensions.logstats] INFO: Crawled 1456 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:35:00 [scrapy.extensions.logstats] INFO: Crawled 1456 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:35:31 [scrapy.extensions.logstats] INFO: Crawled 1459 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:36:31 [scrapy.extensions.logstats] INFO: Crawled 1463 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:38:23 [scrapy.extensions.logstats] INFO: Crawled 1467 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:39:23 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=428>: HTTP status code is not handled or not allowed
2019-11-10 03:39:23 [scrapy.extensions.logstats] INFO: Crawled 1468 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:40:24 [scrapy.extensions.logstats] INFO: Crawled 1469 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:41:26 [scrapy.extensions.logstats] INFO: Crawled 1473 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:42:58 [scrapy.extensions.logstats] INFO: Crawled 1477 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:43:58 [scrapy.extensions.logstats] INFO: Crawled 1479 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:45:00 [scrapy.extensions.logstats] INFO: Crawled 1481 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:45:49 [scrapy.extensions.logstats] INFO: Crawled 1483 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:46:48 [scrapy.extensions.logstats] INFO: Crawled 1485 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:47:50 [scrapy.extensions.logstats] INFO: Crawled 1486 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:48:32 [scrapy.extensions.logstats] INFO: Crawled 1487 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:49:12 [scrapy.extensions.logstats] INFO: Crawled 1487 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:50:16 [scrapy.extensions.logstats] INFO: Crawled 1493 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:51:27 [scrapy.extensions.logstats] INFO: Crawled 1496 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:52:30 [scrapy.extensions.logstats] INFO: Crawled 1497 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:53:08 [scrapy.extensions.logstats] INFO: Crawled 1497 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:54:04 [scrapy.extensions.logstats] INFO: Crawled 1499 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:55:35 [scrapy.extensions.logstats] INFO: Crawled 1503 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:56:04 [scrapy.extensions.logstats] INFO: Crawled 1506 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:58:10 [scrapy.extensions.logstats] INFO: Crawled 1508 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 03:59:11 [scrapy.extensions.logstats] INFO: Crawled 1509 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:00:13 [scrapy.extensions.logstats] INFO: Crawled 1511 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:01:39 [scrapy.extensions.logstats] INFO: Crawled 1516 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:02:46 [scrapy.extensions.logstats] INFO: Crawled 1516 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:03:07 [scrapy.extensions.logstats] INFO: Crawled 1516 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:04:08 [scrapy.extensions.logstats] INFO: Crawled 1520 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:05:08 [scrapy.extensions.logstats] INFO: Crawled 1521 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:06:33 [scrapy.extensions.logstats] INFO: Crawled 1525 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:07:04 [scrapy.extensions.logstats] INFO: Crawled 1525 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:08:30 [scrapy.extensions.logstats] INFO: Crawled 1529 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:09:31 [scrapy.extensions.logstats] INFO: Crawled 1531 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:10:08 [scrapy.extensions.logstats] INFO: Crawled 1533 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:11:05 [scrapy.extensions.logstats] INFO: Crawled 1536 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:12:33 [scrapy.extensions.logstats] INFO: Crawled 1538 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:13:30 [scrapy.extensions.logstats] INFO: Crawled 1539 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:15:00 [scrapy.extensions.logstats] INFO: Crawled 1543 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:15:58 [scrapy.extensions.logstats] INFO: Crawled 1545 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:16:59 [scrapy.extensions.logstats] INFO: Crawled 1547 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:17:57 [scrapy.extensions.logstats] INFO: Crawled 1549 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:18:27 [scrapy.extensions.logstats] INFO: Crawled 1551 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:19:58 [scrapy.extensions.logstats] INFO: Crawled 1553 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:20:27 [scrapy.extensions.logstats] INFO: Crawled 1554 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:21:26 [scrapy.extensions.logstats] INFO: Crawled 1556 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:22:26 [scrapy.extensions.logstats] INFO: Crawled 1558 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:23:22 [scrapy.extensions.logstats] INFO: Crawled 1558 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:24:20 [scrapy.extensions.logstats] INFO: Crawled 1560 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:25:15 [scrapy.extensions.logstats] INFO: Crawled 1563 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:26:23 [scrapy.extensions.logstats] INFO: Crawled 1566 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:27:08 [scrapy.extensions.logstats] INFO: Crawled 1568 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:28:29 [scrapy.extensions.logstats] INFO: Crawled 1572 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:29:29 [scrapy.extensions.logstats] INFO: Crawled 1575 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:30:31 [scrapy.extensions.logstats] INFO: Crawled 1576 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:31:04 [scrapy.extensions.logstats] INFO: Crawled 1578 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:32:35 [scrapy.extensions.logstats] INFO: Crawled 1580 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:33:38 [scrapy.extensions.logstats] INFO: Crawled 1580 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:34:09 [scrapy.extensions.logstats] INFO: Crawled 1582 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:35:11 [scrapy.extensions.logstats] INFO: Crawled 1585 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:36:15 [scrapy.extensions.logstats] INFO: Crawled 1588 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:37:52 [scrapy.extensions.logstats] INFO: Crawled 1589 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:38:25 [scrapy.extensions.logstats] INFO: Crawled 1589 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:39:59 [scrapy.extensions.logstats] INFO: Crawled 1594 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:40:29 [scrapy.extensions.logstats] INFO: Crawled 1596 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:41:57 [scrapy.extensions.logstats] INFO: Crawled 1596 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:42:27 [scrapy.extensions.logstats] INFO: Crawled 1598 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:43:27 [scrapy.extensions.logstats] INFO: Crawled 1601 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:44:28 [scrapy.extensions.logstats] INFO: Crawled 1604 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:46:03 [scrapy.extensions.logstats] INFO: Crawled 1606 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:47:02 [scrapy.extensions.logstats] INFO: Crawled 1606 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:47:32 [scrapy.extensions.logstats] INFO: Crawled 1608 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:48:33 [scrapy.extensions.logstats] INFO: Crawled 1612 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:49:42 [scrapy.extensions.logstats] INFO: Crawled 1614 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:50:42 [scrapy.extensions.logstats] INFO: Crawled 1614 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:51:09 [scrapy.extensions.logstats] INFO: Crawled 1616 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:52:11 [scrapy.extensions.logstats] INFO: Crawled 1620 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:53:39 [scrapy.extensions.logstats] INFO: Crawled 1624 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:54:38 [scrapy.extensions.logstats] INFO: Crawled 1624 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:55:43 [scrapy.extensions.logstats] INFO: Crawled 1624 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:56:11 [scrapy.extensions.logstats] INFO: Crawled 1627 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:57:16 [scrapy.extensions.logstats] INFO: Crawled 1633 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 04:58:51 [scrapy.extensions.logstats] INFO: Crawled 1636 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:00:19 [scrapy.extensions.logstats] INFO: Crawled 1636 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:01:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/press-releases/detail/110/delta-apparel-reports-fiscal-2014-first-quarter-results>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/press-releases/detail/110/delta-apparel-reports-fiscal-2014-first-quarter-results took longer than 15.0 seconds..
2019-11-10 05:01:52 [scrapy.extensions.logstats] INFO: Crawled 1636 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:02:22 [scrapy.extensions.logstats] INFO: Crawled 1640 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:03:56 [scrapy.extensions.logstats] INFO: Crawled 1646 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:05:27 [scrapy.extensions.logstats] INFO: Crawled 1646 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:07:01 [scrapy.extensions.logstats] INFO: Crawled 1646 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:07:32 [scrapy.extensions.logstats] INFO: Crawled 1648 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:08:32 [scrapy.extensions.logstats] INFO: Crawled 1652 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:09:34 [scrapy.extensions.logstats] INFO: Crawled 1653 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:10:04 [scrapy.extensions.logstats] INFO: Crawled 1654 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:11:40 [scrapy.extensions.logstats] INFO: Crawled 1655 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:12:11 [scrapy.extensions.logstats] INFO: Crawled 1656 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:13:13 [scrapy.extensions.logstats] INFO: Crawled 1659 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:14:17 [scrapy.extensions.logstats] INFO: Crawled 1663 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:15:19 [scrapy.extensions.logstats] INFO: Crawled 1666 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:16:25 [scrapy.extensions.logstats] INFO: Crawled 1669 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:17:08 [scrapy.extensions.logstats] INFO: Crawled 1671 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:18:09 [scrapy.extensions.logstats] INFO: Crawled 1674 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:19:13 [scrapy.extensions.logstats] INFO: Crawled 1677 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:20:13 [scrapy.extensions.logstats] INFO: Crawled 1679 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:21:13 [scrapy.extensions.logstats] INFO: Crawled 1679 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:22:13 [scrapy.extensions.logstats] INFO: Crawled 1681 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:23:24 [scrapy.extensions.logstats] INFO: Crawled 1683 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:24:26 [scrapy.extensions.logstats] INFO: Crawled 1685 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:25:26 [scrapy.extensions.logstats] INFO: Crawled 1687 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:26:29 [scrapy.extensions.logstats] INFO: Crawled 1690 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:27:28 [scrapy.extensions.logstats] INFO: Crawled 1691 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:28:33 [scrapy.extensions.logstats] INFO: Crawled 1694 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:29:33 [scrapy.extensions.logstats] INFO: Crawled 1696 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:30:38 [scrapy.extensions.logstats] INFO: Crawled 1698 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:31:14 [scrapy.extensions.logstats] INFO: Crawled 1699 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:32:52 [scrapy.extensions.logstats] INFO: Crawled 1702 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:33:25 [scrapy.extensions.logstats] INFO: Crawled 1704 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:34:29 [scrapy.extensions.logstats] INFO: Crawled 1707 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:36:06 [scrapy.extensions.logstats] INFO: Crawled 1710 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:37:38 [scrapy.extensions.logstats] INFO: Crawled 1711 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:38:10 [scrapy.extensions.logstats] INFO: Crawled 1712 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:39:13 [scrapy.extensions.logstats] INFO: Crawled 1715 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:40:14 [scrapy.extensions.logstats] INFO: Crawled 1718 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:41:18 [scrapy.extensions.logstats] INFO: Crawled 1718 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:42:24 [scrapy.extensions.logstats] INFO: Crawled 1724 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:43:24 [scrapy.extensions.logstats] INFO: Crawled 1726 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:44:59 [scrapy.extensions.logstats] INFO: Crawled 1728 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:45:52 [scrapy.extensions.logstats] INFO: Crawled 1728 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:46:38 [scrapy.extensions.logstats] INFO: Crawled 1729 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:47:07 [scrapy.extensions.logstats] INFO: Crawled 1729 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:48:06 [scrapy.extensions.logstats] INFO: Crawled 1733 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:49:07 [scrapy.extensions.logstats] INFO: Crawled 1735 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:50:42 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.crabtree-evelyn.com/pages/%redirect_store_url%>: HTTP status code is not handled or not allowed
2019-11-10 05:50:42 [scrapy.extensions.logstats] INFO: Crawled 1740 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:51:24 [scrapy.extensions.logstats] INFO: Crawled 1740 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:52:50 [scrapy.extensions.logstats] INFO: Crawled 1749 pages (at 9 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:54:16 [scrapy.extensions.logstats] INFO: Crawled 1751 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:55:46 [scrapy.extensions.logstats] INFO: Crawled 1751 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:56:43 [scrapy.extensions.logstats] INFO: Crawled 1751 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:57:06 [scrapy.extensions.logstats] INFO: Crawled 1755 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 05:58:11 [scrapy.extensions.logstats] INFO: Crawled 1760 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:00:12 [scrapy.extensions.logstats] INFO: Crawled 1764 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:01:07 [scrapy.extensions.logstats] INFO: Crawled 1767 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:02:09 [scrapy.extensions.logstats] INFO: Crawled 1767 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:03:43 [scrapy.extensions.logstats] INFO: Crawled 1768 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:04:11 [scrapy.extensions.logstats] INFO: Crawled 1769 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:05:14 [scrapy.extensions.logstats] INFO: Crawled 1771 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:06:16 [scrapy.extensions.logstats] INFO: Crawled 1778 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:08:50 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.crabtree-evelyn.com/collections/%redirect_store_url%>: HTTP status code is not handled or not allowed
2019-11-10 06:08:50 [scrapy.extensions.logstats] INFO: Crawled 1784 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:11:17 [scrapy.extensions.logstats] INFO: Crawled 1784 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:11:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://dcloud.demers-ambulances.com:883/dcloud/index.php/login>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://dcloud.demers-ambulances.com:883/dcloud/index.php/login took longer than 15.0 seconds..
2019-11-10 06:12:25 [scrapy.extensions.logstats] INFO: Crawled 1796 pages (at 12 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:13:50 [scrapy.extensions.logstats] INFO: Crawled 1800 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:15:39 [scrapy.extensions.logstats] INFO: Crawled 1800 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:17:26 [scrapy.extensions.logstats] INFO: Crawled 1800 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:18:09 [scrapy.extensions.logstats] INFO: Crawled 1806 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:20:20 [scrapy.extensions.logstats] INFO: Crawled 1812 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:21:26 [scrapy.extensions.logstats] INFO: Crawled 1812 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:23:02 [scrapy.extensions.logstats] INFO: Crawled 1812 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:23:30 [scrapy.extensions.logstats] INFO: Crawled 1815 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:24:30 [scrapy.extensions.logstats] INFO: Crawled 1821 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:26:03 [scrapy.extensions.logstats] INFO: Crawled 1821 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:27:35 [scrapy.extensions.logstats] INFO: Crawled 1821 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:28:32 [scrapy.extensions.logstats] INFO: Crawled 1827 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:29:06 [scrapy.extensions.logstats] INFO: Crawled 1830 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:30:42 [scrapy.extensions.logstats] INFO: Crawled 1830 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:32:21 [scrapy.extensions.logstats] INFO: Crawled 1830 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:33:59 [scrapy.extensions.logstats] INFO: Crawled 1836 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:34:30 [scrapy.extensions.logstats] INFO: Crawled 1839 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:35:37 [scrapy.extensions.logstats] INFO: Crawled 1839 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:37:16 [scrapy.extensions.logstats] INFO: Crawled 1839 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:38:51 [scrapy.extensions.logstats] INFO: Crawled 1846 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:39:48 [scrapy.extensions.logstats] INFO: Crawled 1849 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:41:13 [scrapy.extensions.logstats] INFO: Crawled 1852 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:42:46 [scrapy.extensions.logstats] INFO: Crawled 1853 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:43:18 [scrapy.extensions.logstats] INFO: Crawled 1855 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:44:21 [scrapy.extensions.logstats] INFO: Crawled 1857 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:45:24 [scrapy.extensions.logstats] INFO: Crawled 1861 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:46:29 [scrapy.extensions.logstats] INFO: Crawled 1863 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:47:31 [scrapy.extensions.logstats] INFO: Crawled 1865 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:48:36 [scrapy.extensions.logstats] INFO: Crawled 1865 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:49:21 [scrapy.extensions.logstats] INFO: Crawled 1865 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:50:20 [scrapy.extensions.logstats] INFO: Crawled 1871 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:52:26 [scrapy.extensions.logstats] INFO: Crawled 1877 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:53:42 [scrapy.extensions.logstats] INFO: Crawled 1880 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:55:11 [scrapy.extensions.logstats] INFO: Crawled 1880 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:56:49 [scrapy.extensions.logstats] INFO: Crawled 1880 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:57:20 [scrapy.extensions.logstats] INFO: Crawled 1883 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:58:53 [scrapy.extensions.logstats] INFO: Crawled 1886 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 06:59:57 [scrapy.extensions.logstats] INFO: Crawled 1886 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:00:26 [scrapy.extensions.logstats] INFO: Crawled 1891 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:02:33 [scrapy.extensions.logstats] INFO: Crawled 1897 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:04:06 [scrapy.extensions.logstats] INFO: Crawled 1900 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:05:40 [scrapy.extensions.logstats] INFO: Crawled 1900 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:07:12 [scrapy.extensions.logstats] INFO: Crawled 1900 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:08:15 [scrapy.extensions.logstats] INFO: Crawled 1906 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:10:26 [scrapy.extensions.logstats] INFO: Crawled 1912 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:11:51 [scrapy.extensions.logstats] INFO: Crawled 1912 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:13:28 [scrapy.extensions.logstats] INFO: Crawled 1912 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:15:05 [scrapy.extensions.logstats] INFO: Crawled 1918 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:16:36 [scrapy.extensions.logstats] INFO: Crawled 1921 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:18:04 [scrapy.extensions.logstats] INFO: Crawled 1924 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:19:32 [scrapy.extensions.logstats] INFO: Crawled 1927 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:21:04 [scrapy.extensions.logstats] INFO: Crawled 1930 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:22:31 [scrapy.extensions.logstats] INFO: Crawled 1930 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:24:03 [scrapy.extensions.logstats] INFO: Crawled 1939 pages (at 9 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:25:35 [scrapy.extensions.logstats] INFO: Crawled 1939 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:27:14 [scrapy.extensions.logstats] INFO: Crawled 1939 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:28:21 [scrapy.extensions.logstats] INFO: Crawled 1944 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:29:57 [scrapy.extensions.logstats] INFO: Crawled 1947 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:31:35 [scrapy.extensions.logstats] INFO: Crawled 1947 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:32:09 [scrapy.extensions.logstats] INFO: Crawled 1951 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:33:42 [scrapy.extensions.logstats] INFO: Crawled 1955 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:35:48 [scrapy.extensions.logstats] INFO: Crawled 1955 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:36:23 [scrapy.extensions.logstats] INFO: Crawled 1960 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:38:01 [scrapy.extensions.logstats] INFO: Crawled 1964 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:38:36 [scrapy.extensions.logstats] INFO: Crawled 1964 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:40:44 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://demarini.com/robots.txt>: User timeout caused connection failure: Getting http://www.demarini.com/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.demarini.com/robots.txt took longer than 15.0 seconds..
2019-11-10 07:40:44 [scrapy.extensions.logstats] INFO: Crawled 1964 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:41:17 [scrapy.extensions.logstats] INFO: Crawled 1967 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:42:22 [scrapy.extensions.logstats] INFO: Crawled 1971 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:44:15 [scrapy.extensions.logstats] INFO: Crawled 1974 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:45:20 [scrapy.extensions.logstats] INFO: Crawled 1978 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:47:28 [scrapy.extensions.logstats] INFO: Crawled 1981 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:48:57 [scrapy.extensions.logstats] INFO: Crawled 1981 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:49:29 [scrapy.extensions.logstats] INFO: Crawled 1987 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:52:04 [scrapy.extensions.logstats] INFO: Crawled 1992 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:54:42 [scrapy.extensions.logstats] INFO: Crawled 1998 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:57:54 [scrapy.extensions.logstats] INFO: Crawled 1998 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:58:28 [scrapy.extensions.logstats] INFO: Crawled 2004 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 07:59:39 [scrapy.extensions.logstats] INFO: Crawled 2010 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:01:07 [scrapy.extensions.logstats] INFO: Crawled 2010 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:03:18 [scrapy.extensions.logstats] INFO: Crawled 2010 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:04:23 [scrapy.extensions.logstats] INFO: Crawled 2020 pages (at 10 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:05:29 [scrapy.extensions.logstats] INFO: Crawled 2020 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:07:02 [scrapy.extensions.logstats] INFO: Crawled 2020 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:07:24 [scrapy.extensions.logstats] INFO: Crawled 2025 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:09:41 [scrapy.extensions.logstats] INFO: Crawled 2030 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:12:24 [scrapy.extensions.logstats] INFO: Crawled 2034 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:14:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://investor.columbia.com/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://investor.columbia.com/ took longer than 15.0 seconds..
2019-11-10 08:14:10 [scrapy.extensions.logstats] INFO: Crawled 2039 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:16:52 [scrapy.extensions.logstats] INFO: Crawled 2041 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:17:54 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET https://eu.dvf.com/robots.txt>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 08:17:55 [scrapy.extensions.logstats] INFO: Crawled 2044 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:19:31 [scrapy.extensions.logstats] INFO: Crawled 2048 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:21:03 [scrapy.extensions.logstats] INFO: Crawled 2050 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:21:46 [scrapy.extensions.logstats] INFO: Crawled 2053 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:23:14 [scrapy.extensions.logstats] INFO: Crawled 2055 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:24:27 [scrapy.extensions.logstats] INFO: Crawled 2058 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:26:02 [scrapy.extensions.logstats] INFO: Crawled 2060 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:27:10 [scrapy.extensions.logstats] INFO: Crawled 2063 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:28:44 [scrapy.extensions.logstats] INFO: Crawled 2066 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:30:23 [scrapy.extensions.logstats] INFO: Crawled 2068 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:31:30 [scrapy.extensions.logstats] INFO: Crawled 2070 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:32:34 [scrapy.extensions.logstats] INFO: Crawled 2072 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:33:07 [scrapy.extensions.logstats] INFO: Crawled 2074 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:34:41 [scrapy.extensions.logstats] INFO: Crawled 2074 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:35:12 [scrapy.extensions.logstats] INFO: Crawled 2078 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:36:43 [scrapy.extensions.logstats] INFO: Crawled 2083 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:38:53 [scrapy.extensions.logstats] INFO: Crawled 2083 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:39:27 [scrapy.extensions.logstats] INFO: Crawled 2086 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:40:34 [scrapy.extensions.logstats] INFO: Crawled 2089 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:41:35 [scrapy.extensions.logstats] INFO: Crawled 2092 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:42:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://store.contour.com/collections/accessories>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 08:43:17 [scrapy.extensions.logstats] INFO: Crawled 2094 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:44:24 [scrapy.extensions.logstats] INFO: Crawled 2101 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:45:09 [scrapy.extensions.logstats] INFO: Crawled 2104 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:47:20 [scrapy.extensions.logstats] INFO: Crawled 2108 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:48:50 [scrapy.extensions.logstats] INFO: Crawled 2112 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:50:18 [scrapy.extensions.logstats] INFO: Crawled 2112 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:51:46 [scrapy.extensions.logstats] INFO: Crawled 2112 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:52:09 [scrapy.extensions.logstats] INFO: Crawled 2118 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:54:46 [scrapy.extensions.logstats] INFO: Crawled 2126 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:57:40 [scrapy.extensions.logstats] INFO: Crawled 2129 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 08:59:18 [scrapy.extensions.logstats] INFO: Crawled 2129 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:00:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://world.dvf.com>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://world.dvf.com took longer than 15.0 seconds..
2019-11-10 09:00:59 [scrapy.extensions.logstats] INFO: Crawled 2129 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:00:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://world.dvf.com>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://world.dvf.com took longer than 15.0 seconds..
2019-11-10 09:01:31 [scrapy.extensions.logstats] INFO: Crawled 2134 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:03:42 [scrapy.extensions.logstats] INFO: Crawled 2138 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:05:53 [scrapy.extensions.logstats] INFO: Crawled 2143 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:08:40 [scrapy.extensions.logstats] INFO: Crawled 2145 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:09:46 [scrapy.extensions.logstats] INFO: Crawled 2149 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:11:50 [scrapy.extensions.logstats] INFO: Crawled 2153 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:14:06 [scrapy.extensions.logstats] INFO: Crawled 2156 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:15:26 [scrapy.extensions.logstats] INFO: Crawled 2160 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:17:45 [scrapy.extensions.logstats] INFO: Crawled 2163 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:19:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.columbia.com>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.columbia.com took longer than 15.0 seconds..
2019-11-10 09:19:06 [scrapy.extensions.logstats] INFO: Crawled 2163 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:21:03 [scrapy.extensions.logstats] INFO: Crawled 2178 pages (at 15 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:23:31 [scrapy.extensions.logstats] INFO: Crawled 2181 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:26:12 [scrapy.extensions.logstats] INFO: Crawled 2181 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:27:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.columbia.com>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.columbia.com took longer than 15.0 seconds..
2019-11-10 09:27:47 [scrapy.extensions.logstats] INFO: Crawled 2181 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:27:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.columbia.com>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.columbia.com took longer than 15.0 seconds..
2019-11-10 09:27:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://eu.dvf.com/en/home/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://eu.dvf.com/en/home/ took longer than 15.0 seconds..
2019-11-10 09:28:21 [scrapy.extensions.logstats] INFO: Crawled 2185 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:30:29 [scrapy.extensions.logstats] INFO: Crawled 2192 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:31:36 [scrapy.extensions.logstats] INFO: Crawled 2195 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:32:44 [scrapy.extensions.logstats] INFO: Crawled 2198 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:34:14 [scrapy.extensions.logstats] INFO: Crawled 2201 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:35:50 [scrapy.extensions.logstats] INFO: Crawled 2204 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:37:32 [scrapy.extensions.logstats] INFO: Crawled 2207 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:39:01 [scrapy.extensions.logstats] INFO: Crawled 2207 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:40:08 [scrapy.extensions.logstats] INFO: Crawled 2207 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:41:40 [scrapy.extensions.logstats] INFO: Crawled 2212 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:43:08 [scrapy.extensions.logstats] INFO: Crawled 2216 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:43:54 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET https://nationaldesigncontest.dacor.com/robots.txt>: User timeout caused connection failure.
twisted.internet.error.TimeoutError: User timeout caused connection failure.
2019-11-10 09:44:39 [scrapy.extensions.logstats] INFO: Crawled 2219 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:45:25 [scrapy.extensions.logstats] INFO: Crawled 2222 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:46:10 [scrapy.extensions.logstats] INFO: Crawled 2224 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:47:16 [scrapy.extensions.logstats] INFO: Crawled 2224 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:49:26 [scrapy.extensions.logstats] INFO: Crawled 2232 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:50:30 [scrapy.extensions.logstats] INFO: Crawled 2234 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:52:02 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.demarini.com/en-us>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.demarini.com/en-us took longer than 15.0 seconds..
2019-11-10 09:52:02 [scrapy.extensions.logstats] INFO: Crawled 2237 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:53:44 [scrapy.extensions.logstats] INFO: Crawled 2238 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:54:16 [scrapy.extensions.logstats] INFO: Crawled 2239 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:55:24 [scrapy.extensions.logstats] INFO: Crawled 2243 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:56:58 [scrapy.extensions.logstats] INFO: Crawled 2247 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:57:51 [scrapy.extensions.logstats] INFO: Crawled 2249 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:58:35 [scrapy.extensions.logstats] INFO: Crawled 2251 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 09:59:20 [scrapy.extensions.logstats] INFO: Crawled 2252 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:00:04 [scrapy.extensions.logstats] INFO: Crawled 2254 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:01:46 [scrapy.extensions.logstats] INFO: Crawled 2258 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:02:43 [scrapy.extensions.logstats] INFO: Crawled 2259 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:03:15 [scrapy.extensions.logstats] INFO: Crawled 2260 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:04:21 [scrapy.extensions.logstats] INFO: Crawled 2260 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:05:24 [scrapy.extensions.logstats] INFO: Crawled 2262 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:06:31 [scrapy.extensions.logstats] INFO: Crawled 2268 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:08:45 [scrapy.extensions.logstats] INFO: Crawled 2268 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:09:20 [scrapy.extensions.logstats] INFO: Crawled 2272 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:11:03 [scrapy.extensions.logstats] INFO: Crawled 2278 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:12:37 [scrapy.extensions.logstats] INFO: Crawled 2280 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:14:12 [scrapy.extensions.logstats] INFO: Crawled 2282 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:15:16 [scrapy.extensions.logstats] INFO: Crawled 2284 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:16:21 [scrapy.extensions.logstats] INFO: Crawled 2284 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:17:08 [scrapy.extensions.logstats] INFO: Crawled 2284 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:18:06 [scrapy.extensions.logstats] INFO: Crawled 2289 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:19:34 [scrapy.extensions.logstats] INFO: Crawled 2292 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:21:05 [scrapy.extensions.logstats] INFO: Crawled 2298 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:22:42 [scrapy.extensions.logstats] INFO: Crawled 2298 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:24:18 [scrapy.extensions.logstats] INFO: Crawled 2298 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:25:24 [scrapy.extensions.logstats] INFO: Crawled 2302 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:26:29 [scrapy.extensions.logstats] INFO: Crawled 2304 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:27:34 [scrapy.extensions.logstats] INFO: Crawled 2306 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:28:39 [scrapy.extensions.logstats] INFO: Crawled 2308 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:29:47 [scrapy.extensions.logstats] INFO: Crawled 2310 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:30:22 [scrapy.extensions.logstats] INFO: Crawled 2312 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:32:03 [scrapy.extensions.logstats] INFO: Crawled 2316 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:32:48 [scrapy.extensions.logstats] INFO: Crawled 2316 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:33:50 [scrapy.extensions.logstats] INFO: Crawled 2316 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:34:22 [scrapy.extensions.logstats] INFO: Crawled 2318 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:35:32 [scrapy.extensions.logstats] INFO: Crawled 2322 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:36:05 [scrapy.extensions.logstats] INFO: Crawled 2324 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:37:12 [scrapy.extensions.logstats] INFO: Crawled 2326 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:38:16 [scrapy.extensions.logstats] INFO: Crawled 2328 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:39:47 [scrapy.extensions.logstats] INFO: Crawled 2332 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:40:33 [scrapy.extensions.logstats] INFO: Crawled 2334 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:41:23 [scrapy.extensions.logstats] INFO: Crawled 2336 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:42:33 [scrapy.extensions.logstats] INFO: Crawled 2338 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:43:41 [scrapy.extensions.logstats] INFO: Crawled 2340 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:44:47 [scrapy.extensions.logstats] INFO: Crawled 2342 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:45:51 [scrapy.extensions.logstats] INFO: Crawled 2344 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:46:58 [scrapy.extensions.logstats] INFO: Crawled 2346 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:47:57 [scrapy.extensions.logstats] INFO: Crawled 2348 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:49:04 [scrapy.extensions.logstats] INFO: Crawled 2350 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:50:09 [scrapy.extensions.logstats] INFO: Crawled 2352 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:51:21 [scrapy.extensions.logstats] INFO: Crawled 2354 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:52:17 [scrapy.extensions.logstats] INFO: Crawled 2354 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:53:17 [scrapy.extensions.logstats] INFO: Crawled 2354 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:54:31 [scrapy.extensions.logstats] INFO: Crawled 2358 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:55:05 [scrapy.extensions.logstats] INFO: Crawled 2360 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:56:40 [scrapy.extensions.logstats] INFO: Crawled 2364 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:57:45 [scrapy.extensions.logstats] INFO: Crawled 2366 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:58:51 [scrapy.extensions.logstats] INFO: Crawled 2366 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 10:59:56 [scrapy.extensions.logstats] INFO: Crawled 2366 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 11:00:29 [scrapy.extensions.logstats] INFO: Crawled 2369 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 11:01:38 [scrapy.extensions.logstats] INFO: Crawled 2371 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 11:02:44 [scrapy.extensions.logstats] INFO: Crawled 2374 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 11:04:21 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://curaegis.com/robots.txt>: User timeout caused connection failure: Getting http://curaegis.com/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://curaegis.com/robots.txt took longer than 15.0 seconds..
2019-11-10 11:04:21 [scrapy.extensions.logstats] INFO: Crawled 2376 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 11:05:27 [scrapy.extensions.logstats] INFO: Crawled 2378 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 11:06:33 [scrapy.extensions.logstats] INFO: Crawled 2380 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 11:07:45 [scrapy.extensions.logstats] INFO: Crawled 2383 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 11:08:17 [scrapy.extensions.logstats] INFO: Crawled 2386 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 11:09:21 [scrapy.extensions.logstats] INFO: Crawled 2389 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 11:11:01 [scrapy.extensions.logstats] INFO: Crawled 2389 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 11:12:21 [scrapy.extensions.logstats] INFO: Crawled 2389 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 11:13:07 [scrapy.extensions.logstats] INFO: Crawled 2397 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 11:16:16 [scrapy.extensions.logstats] INFO: Crawled 2402 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 11:18:08 [scrapy.extensions.logstats] INFO: Crawled 2403 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 11:19:29 [scrapy.extensions.logstats] INFO: Crawled 2406 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 11:20:34 [scrapy.extensions.logstats] INFO: Crawled 2409 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 11:22:09 [scrapy.extensions.logstats] INFO: Crawled 2409 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 11:22:10 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.danryanbuilders.com/homeowner-resources/customer-service/tel:8003349143>: HTTP status code is not handled or not allowed
2019-11-10 11:23:18 [scrapy.extensions.logstats] INFO: Crawled 2415 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 11:23:18 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.danryanbuilders.com/homeowner-resources/customer-service/tel:8662719897>: HTTP status code is not handled or not allowed
2019-11-10 11:24:23 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.danryanbuilders.com/homeowner-resources/customer-service/tel:8005147133>: HTTP status code is not handled or not allowed
2019-11-10 11:24:23 [scrapy.extensions.logstats] INFO: Crawled 2418 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 11:25:31 [scrapy.extensions.logstats] INFO: Crawled 2418 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 11:25:31 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.danryanbuilders.com/homeowner-resources/customer-service/tel:8667444034>: HTTP status code is not handled or not allowed
2019-11-10 11:26:04 [scrapy.extensions.logstats] INFO: Crawled 2421 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 11:26:40 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.danryanbuilders.com/homeowner-resources/customer-service/tel:8004432119>: HTTP status code is not handled or not allowed
2019-11-10 11:27:10 [scrapy.extensions.logstats] INFO: Crawled 2427 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 11:27:33 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.danryanbuilders.com/homeowner-resources/customer-service/tel:8438202506>: HTTP status code is not handled or not allowed
2019-11-10 11:29:39 [scrapy.extensions.logstats] INFO: Crawled 2433 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 11:31:14 [scrapy.extensions.logstats] INFO: Crawled 2433 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 11:32:00 [scrapy.core.downloader.handlers.http11] ERROR: Cancelling download of http://downloads.contour.com/storyteller/Contour-Storyteller-Installer.dmg: expected response size (23467841) larger than download max size (5242880).
2019-11-10 11:33:09 [scrapy.core.scraper] ERROR: Error downloading <GET http://downloads.contour.com/storyteller/Contour-Storyteller-Installer.dmg>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 343, in _cb_bodyready
    raise defer.CancelledError(error_msg % error_args)
twisted.internet.defer.CancelledError: Cancelling download of http://downloads.contour.com/storyteller/Contour-Storyteller-Installer.dmg: expected response size (23467841) larger than download max size (5242880).
2019-11-10 11:33:09 [scrapy.extensions.logstats] INFO: Crawled 2446 pages (at 13 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 11:35:19 [scrapy.extensions.logstats] INFO: Crawled 2449 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 11:37:01 [scrapy.extensions.logstats] INFO: Crawled 2452 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 11:38:50 [scrapy.extensions.logstats] INFO: Crawled 2452 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 11:40:14 [scrapy.extensions.logstats] INFO: Crawled 2452 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 11:41:09 [scrapy.extensions.logstats] INFO: Crawled 2459 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 11:43:03 [scrapy.extensions.logstats] INFO: Crawled 2459 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 11:43:27 [scrapy.extensions.logstats] INFO: Crawled 2463 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 11:44:38 [scrapy.extensions.logstats] INFO: Crawled 2471 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 11:46:13 [scrapy.extensions.logstats] INFO: Crawled 2475 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 11:47:49 [scrapy.extensions.logstats] INFO: Crawled 2479 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 11:49:39 [scrapy.extensions.logstats] INFO: Crawled 2479 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 11:51:57 [scrapy.extensions.logstats] INFO: Crawled 2479 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 11:52:29 [scrapy.extensions.logstats] INFO: Crawled 2484 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 11:54:42 [scrapy.extensions.logstats] INFO: Crawled 2494 pages (at 10 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 11:57:31 [scrapy.extensions.logstats] INFO: Crawled 2496 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 12:00:01 [scrapy.extensions.logstats] INFO: Crawled 2496 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 12:00:58 [scrapy.extensions.logstats] INFO: Crawled 2496 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 12:01:34 [scrapy.extensions.logstats] INFO: Crawled 2500 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 12:02:05 [scrapy.extensions.logstats] INFO: Crawled 2504 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 12:03:11 [scrapy.extensions.logstats] INFO: Crawled 2504 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 12:05:12 [scrapy.extensions.logstats] INFO: Crawled 2504 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 12:07:51 [scrapy.extensions.logstats] INFO: Crawled 2513 pages (at 9 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 12:09:13 [scrapy.extensions.logstats] INFO: Crawled 2516 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 12:10:58 [scrapy.extensions.logstats] INFO: Crawled 2519 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 12:12:30 [scrapy.extensions.logstats] INFO: Crawled 2522 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 12:14:11 [scrapy.extensions.logstats] INFO: Crawled 2525 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 12:15:29 [scrapy.extensions.logstats] INFO: Crawled 2527 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 12:16:16 [scrapy.extensions.logstats] INFO: Crawled 2528 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 12:18:52 [scrapy.extensions.logstats] INFO: Crawled 2541 pages (at 13 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 12:20:17 [scrapy.extensions.logstats] INFO: Crawled 2546 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 12:23:25 [scrapy.extensions.logstats] INFO: Crawled 2548 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 12:26:06 [scrapy.extensions.logstats] INFO: Crawled 2550 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 12:27:20 [scrapy.extensions.logstats] INFO: Crawled 2550 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 12:28:27 [scrapy.extensions.logstats] INFO: Crawled 2550 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 12:29:34 [scrapy.extensions.logstats] INFO: Crawled 2569 pages (at 19 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 12:33:32 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://dacor.com/robots.txt>: User timeout caused connection failure: Getting http://www.dacor.com/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.dacor.com/robots.txt took longer than 15.0 seconds..
2019-11-10 12:33:32 [scrapy.extensions.logstats] INFO: Crawled 2569 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 12:37:32 [scrapy.extensions.logstats] INFO: Crawled 2569 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 12:38:08 [scrapy.extensions.logstats] INFO: Crawled 2581 pages (at 12 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 12:39:51 [scrapy.extensions.logstats] INFO: Crawled 2590 pages (at 9 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 12:44:22 [scrapy.extensions.logstats] INFO: Crawled 2590 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 12:49:31 [scrapy.extensions.logstats] INFO: Crawled 2590 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 12:50:09 [scrapy.extensions.logstats] INFO: Crawled 2598 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 12:53:05 [scrapy.extensions.logstats] INFO: Crawled 2605 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 12:56:29 [scrapy.extensions.logstats] INFO: Crawled 2605 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 12:58:05 [scrapy.extensions.logstats] INFO: Crawled 2622 pages (at 17 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 13:02:44 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.d-box.com/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.d-box.com/ took longer than 15.0 seconds..
2019-11-10 13:02:44 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.dsc.com/>: User timeout caused connection failure.
2019-11-10 13:02:44 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.denovahomes.com/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.denovahomes.com/ took longer than 15.0 seconds..
2019-11-10 13:02:44 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.combe.com/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.combe.com/ took longer than 15.0 seconds..
2019-11-10 13:02:44 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET https://www.musclemilk.com/robots.txt>: User timeout caused connection failure.
twisted.internet.error.TimeoutError: User timeout caused connection failure.
2019-11-10 13:02:44 [scrapy.extensions.logstats] INFO: Crawled 2622 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 13:06:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cramco.net/ProductListing.aspx?CatId=692a72cb-7942-4c5a-98b4-872a6a67bfae>: User timeout caused connection failure.
2019-11-10 13:06:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.dana.com/sustainability>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.dana.com/sustainability took longer than 15.0 seconds..
2019-11-10 13:06:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.crbrandsinc.com/forms-documents>: User timeout caused connection failure.
2019-11-10 13:06:00 [scrapy.extensions.logstats] INFO: Crawled 2622 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 13:06:01 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.coscentrix.com/capability.html>: User timeout caused connection failure.
2019-11-10 13:06:01 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.cramco.net/dealerlocator.aspx>: User timeout caused connection failure.
2019-11-10 13:06:01 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.creagri.com/harvesting.html>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.creagri.com/harvesting.html took longer than 15.0 seconds..
2019-11-10 13:06:01 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.musclemilk.com/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.musclemilk.com/ took longer than 15.0 seconds..
2019-11-10 13:06:24 [scrapy.extensions.logstats] INFO: Crawled 2632 pages (at 10 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 13:06:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cramco.net/ProductListing.aspx?CatId=9785dc68-a4e9-4dda-a738-774fd29c37cb>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.cramco.net/ProductListing.aspx?CatId=9785dc68-a4e9-4dda-a738-774fd29c37cb took longer than 15.0 seconds..
2019-11-10 13:09:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cramco.net/ProductListing.aspx?CatId=ef144159-6954-4cfd-9772-f48bba113e02>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.cramco.net/ProductListing.aspx?CatId=ef144159-6954-4cfd-9772-f48bba113e02 took longer than 15.0 seconds..
2019-11-10 13:09:31 [scrapy.extensions.logstats] INFO: Crawled 2641 pages (at 9 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 13:11:53 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cramco.net/ProductListing.aspx?CatId=dd5d0cd2-30fb-4dd9-a915-f516617967f6>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.cramco.net/ProductListing.aspx?CatId=dd5d0cd2-30fb-4dd9-a915-f516617967f6 took longer than 15.0 seconds..
2019-11-10 13:11:54 [scrapy.extensions.logstats] INFO: Crawled 2641 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 13:13:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cramco.net/ProductListing.aspx?CatId=46c9e0b0-4f93-4b7c-a5c2-093cc16bf899>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.cramco.net/ProductListing.aspx?CatId=46c9e0b0-4f93-4b7c-a5c2-093cc16bf899 took longer than 15.0 seconds..
2019-11-10 13:13:02 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.crbrandsinc.com/business-inquiry>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.crbrandsinc.com/business-inquiry took longer than 15.0 seconds..
2019-11-10 13:13:02 [scrapy.extensions.logstats] INFO: Crawled 2641 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 13:13:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cramco.net/ProductListing.aspx?CatId=fbefd22f-e989-427c-8a96-d1601d678312>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.cramco.net/ProductListing.aspx?CatId=fbefd22f-e989-427c-8a96-d1601d678312 took longer than 15.0 seconds..
2019-11-10 13:13:25 [scrapy.extensions.logstats] INFO: Crawled 2647 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 13:15:23 [scrapy.extensions.logstats] INFO: Crawled 2658 pages (at 11 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 13:16:56 [scrapy.extensions.logstats] INFO: Crawled 2663 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 13:20:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.coscentrix.com/index.html>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.coscentrix.com/index.html took longer than 15.0 seconds..
2019-11-10 13:20:20 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.columbia.com/mens-jackets-coats/>: User timeout caused connection failure.
2019-11-10 13:20:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.deckers.com/privacy-policy>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.deckers.com/privacy-policy took longer than 15.0 seconds..
2019-11-10 13:20:20 [scrapy.extensions.logstats] INFO: Crawled 2663 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 13:23:10 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.dana.com/corporate-pages/privacy-policy>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.dana.com/corporate-pages/privacy-policy took longer than 15.0 seconds..
2019-11-10 13:23:10 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.crbrandsinc.com/contact-us>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.crbrandsinc.com/contact-us took longer than 15.0 seconds..
2019-11-10 13:23:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.crosman.com/general/find-a-service-center>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.crosman.com/general/find-a-service-center took longer than 15.0 seconds..
2019-11-10 13:23:10 [scrapy.extensions.logstats] INFO: Crawled 2663 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 13:23:11 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.dana.com/corporate-pages/standards-of-business-conduct>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.dana.com/corporate-pages/standards-of-business-conduct took longer than 15.0 seconds..
2019-11-10 13:30:09 [scrapy.extensions.logstats] INFO: Crawled 2680 pages (at 17 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 13:30:10 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.crbrandsinc.com/new-page>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2019-11-10 13:30:10 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.dana.com/corporate-pages/dcf>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.dana.com/corporate-pages/dcf took longer than 15.0 seconds..
2019-11-10 13:30:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cramco.net/ProductListing.aspx?CatId=d0111d2d-73c6-4427-911f-56af2b487b10>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.cramco.net/ProductListing.aspx?CatId=d0111d2d-73c6-4427-911f-56af2b487b10 took longer than 15.0 seconds..
2019-11-10 13:30:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curtmfg.com/knowledge-base>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curtmfg.com/knowledge-base took longer than 15.0 seconds..
2019-11-10 13:33:04 [scrapy.extensions.logstats] INFO: Crawled 2684 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 13:33:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cramco.net/ProductListing.aspx?CatId=5920f8e5-ed52-4388-8ca2-417e95cabb4f>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 13:33:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curtmfg.com/university/videos>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curtmfg.com/university/videos took longer than 15.0 seconds..
2019-11-10 13:35:17 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.curaegis.com/Contact>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.curaegis.com/Contact took longer than 15.0 seconds..
2019-11-10 13:35:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curtmfg.com/university/training-presentations>: User timeout caused connection failure.
2019-11-10 13:35:17 [scrapy.extensions.logstats] INFO: Crawled 2688 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 13:37:35 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.curaegis.com/Cura-Division/CURA%C2%AE-System>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.curaegis.com/Cura-Division/CURA%C2%AE-System took longer than 15.0 seconds..
2019-11-10 13:37:35 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.dacor.com/support/find-a-servicer>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.dacor.com/support/find-a-servicer took longer than 15.0 seconds..
2019-11-10 13:37:35 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET https://knowledgebase.dacor.com/robots.txt>: User timeout caused connection failure: Getting https://knowledgebase.dacor.com/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://knowledgebase.dacor.com/robots.txt took longer than 15.0 seconds..
2019-11-10 13:37:35 [scrapy.extensions.logstats] INFO: Crawled 2688 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 13:37:36 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cramco.net/ProductListing.aspx?CatId=3898f60e-bf0a-4d51-a755-8593d0e075fc>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 13:37:36 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.dacor.com/support/warranty-registration>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.dacor.com/support/warranty-registration took longer than 15.0 seconds..
2019-11-10 13:37:36 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.curaegis.com/Investors/Corporate-Governance>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.curaegis.com/Investors/Corporate-Governance took longer than 15.0 seconds..
2019-11-10 13:38:10 [scrapy.extensions.logstats] INFO: Crawled 2695 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 13:38:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://knowledgebase.dacor.com/main/topic/faq/list>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://knowledgebase.dacor.com/main/topic/faq/list took longer than 15.0 seconds..
2019-11-10 13:41:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://knowledgebase.dacor.com>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://knowledgebase.dacor.com took longer than 15.0 seconds..
2019-11-10 13:41:34 [scrapy.extensions.logstats] INFO: Crawled 2701 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 13:43:48 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.conferplastics.com/comments/feed/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.conferplastics.com/comments/feed/ took longer than 15.0 seconds..
2019-11-10 13:43:48 [scrapy.extensions.logstats] INFO: Crawled 2703 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 13:44:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cramco.net/ProductListing.aspx?CatId=a2765987-098b-4d7a-b63c-ab13f08c3f5c>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.cramco.net/ProductListing.aspx?CatId=a2765987-098b-4d7a-b63c-ab13f08c3f5c took longer than 15.0 seconds..
2019-11-10 13:44:59 [scrapy.extensions.logstats] INFO: Crawled 2703 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 13:46:04 [scrapy.extensions.logstats] INFO: Crawled 2703 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 13:46:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.dacor.com/support/contact-dacor>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 13:46:04 [scrapy.extensions.logstats] INFO: Crawled 2703 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 13:46:04 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.conferplastics.com/a-culture-of-innovation/>: User timeout caused connection failure.
2019-11-10 13:46:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.columbia.com/giftguide/>: User timeout caused connection failure.
2019-11-10 13:47:09 [scrapy.extensions.logstats] INFO: Crawled 2717 pages (at 14 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 13:50:28 [scrapy.extensions.logstats] INFO: Crawled 2717 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 13:53:53 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.dana.com/light-vehicles>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.dana.com/light-vehicles took longer than 15.0 seconds..
2019-11-10 13:53:53 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.curaegis.com/Cura-Division/Z-Coach>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.curaegis.com/Cura-Division/Z-Coach took longer than 15.0 seconds..
2019-11-10 13:53:53 [scrapy.extensions.logstats] INFO: Crawled 2717 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 13:54:24 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.danryanbuilders.com/the-dan-ryan-builders-difference/contact-us/tel:9197474970>: HTTP status code is not handled or not allowed
2019-11-10 13:54:24 [scrapy.extensions.logstats] INFO: Crawled 2724 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 13:55:50 [scrapy.extensions.logstats] INFO: Crawled 2730 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 13:56:13 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.danryanbuilders.com/the-dan-ryan-builders-difference/contact-us/tel:7042009730>: HTTP status code is not handled or not allowed
2019-11-10 13:56:42 [scrapy.extensions.logstats] INFO: Crawled 2730 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 13:59:42 [scrapy.extensions.logstats] INFO: Crawled 2730 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 14:00:16 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.danryanbuilders.com/the-dan-ryan-builders-difference/contact-us/tel:2404206046>: HTTP status code is not handled or not allowed
2019-11-10 14:00:16 [scrapy.extensions.logstats] INFO: Crawled 2736 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 14:02:03 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.danryanbuilders.com/the-dan-ryan-builders-difference/contact-us/tel:8438202505>: HTTP status code is not handled or not allowed
2019-11-10 14:02:03 [scrapy.extensions.logstats] INFO: Crawled 2742 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 14:04:27 [scrapy.extensions.logstats] INFO: Crawled 2742 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 14:05:33 [scrapy.extensions.logstats] INFO: Crawled 2754 pages (at 12 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 14:07:28 [scrapy.extensions.logstats] INFO: Crawled 2754 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 14:10:50 [scrapy.extensions.logstats] INFO: Crawled 2754 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 14:11:22 [scrapy.extensions.logstats] INFO: Crawled 2760 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 14:14:21 [scrapy.extensions.logstats] INFO: Crawled 2762 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 14:15:26 [scrapy.extensions.logstats] INFO: Crawled 2764 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 14:16:27 [scrapy.extensions.logstats] INFO: Crawled 2768 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 14:18:59 [scrapy.extensions.logstats] INFO: Crawled 2770 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 14:20:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.columbia.com/stores>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.columbia.com/stores took longer than 15.0 seconds..
2019-11-10 14:20:11 [scrapy.extensions.logstats] INFO: Crawled 2773 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 14:21:43 [scrapy.extensions.logstats] INFO: Crawled 2775 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 14:22:59 [scrapy.extensions.logstats] INFO: Crawled 2778 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 14:23:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.columbia.com/men-accessories-neckwear/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.columbia.com/men-accessories-neckwear/ took longer than 15.0 seconds..
2019-11-10 14:23:58 [scrapy.extensions.logstats] INFO: Crawled 2781 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 14:25:10 [scrapy.extensions.logstats] INFO: Crawled 2784 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 14:26:24 [scrapy.extensions.logstats] INFO: Crawled 2787 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 14:27:36 [scrapy.extensions.logstats] INFO: Crawled 2790 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 14:27:37 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.columbia.com/mens-accessories/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.columbia.com/mens-accessories/ took longer than 15.0 seconds..
2019-11-10 14:27:37 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demarini.com/en-us/california-transparency>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demarini.com/en-us/california-transparency took longer than 15.0 seconds..
2019-11-10 14:29:28 [scrapy.extensions.logstats] INFO: Crawled 2793 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 14:29:28 [scrapy.core.scraper] ERROR: Error downloading <GET http://contour.com/returns-policy>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2019-11-10 14:30:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.columbia.com/mens-big-tall-fishing/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.columbia.com/mens-big-tall-fishing/ took longer than 15.0 seconds..
2019-11-10 14:30:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cramco.net/ProductListing.aspx?CatId=8beee97c-86cc-44c4-95fe-723ecf9a55d1>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.cramco.net/ProductListing.aspx?CatId=8beee97c-86cc-44c4-95fe-723ecf9a55d1 took longer than 15.0 seconds..
2019-11-10 14:30:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demarini.com/en-us/terms-and-conditions>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demarini.com/en-us/terms-and-conditions took longer than 15.0 seconds..
2019-11-10 14:30:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.dvf.com/philanthropy/voices>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.dvf.com/philanthropy/voices took longer than 15.0 seconds..
2019-11-10 14:30:59 [scrapy.extensions.logstats] INFO: Crawled 2796 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 14:32:08 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demarini.com/en-us/legal>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demarini.com/en-us/legal took longer than 15.0 seconds..
2019-11-10 14:32:09 [scrapy.extensions.logstats] INFO: Crawled 2799 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 14:32:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demarini.com/en-us/2018-CF-Zen-Indemnity-Policy>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 14:33:20 [scrapy.extensions.logstats] INFO: Crawled 2801 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 14:33:43 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demarini.com/en-us/bats/slowpitch-bats/2020-demarini-ultimate-onslaught-30th-anniversary-slowpitch-bat>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demarini.com/en-us/bats/slowpitch-bats/2020-demarini-ultimate-onslaught-30th-anniversary-slowpitch-bat took longer than 15.0 seconds..
2019-11-10 14:34:08 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cramco.net/ProductListing.aspx?CatId=3419ac94-8365-4bab-ada6-a508a97151bb>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.cramco.net/ProductListing.aspx?CatId=3419ac94-8365-4bab-ada6-a508a97151bb took longer than 15.0 seconds..
2019-11-10 14:34:08 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demarini.com/en-us/bats/fastpitch-bats/2020-demarini-cf-ultimate-onslaught-10-fastpitch-bat>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demarini.com/en-us/bats/fastpitch-bats/2020-demarini-cf-ultimate-onslaught-10-fastpitch-bat took longer than 15.0 seconds..
2019-11-10 14:34:09 [scrapy.extensions.logstats] INFO: Crawled 2805 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 14:35:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cramco.net/ProductListing.aspx?CatId=6db27034-62d0-4a83-a10d-4b2273c3c01f>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.cramco.net/ProductListing.aspx?CatId=6db27034-62d0-4a83-a10d-4b2273c3c01f took longer than 15.0 seconds..
2019-11-10 14:35:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demarini.com/en-us/bats/baseball-bats/2020-cf-ultimate-onslaught-3-bbcor-bat>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demarini.com/en-us/bats/baseball-bats/2020-cf-ultimate-onslaught-3-bbcor-bat took longer than 15.0 seconds..
2019-11-10 14:35:23 [scrapy.extensions.logstats] INFO: Crawled 2805 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 14:36:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cramco.net/ProductListing.aspx?CatId=84d6fd65-43a9-4d80-b900-d5a6227aa308>: User timeout caused connection failure.
2019-11-10 14:36:32 [scrapy.extensions.logstats] INFO: Crawled 2805 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 14:36:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cramco.net/ProductListing.aspx?CatId=87c6c35e-43ba-4a78-9d94-e6c9005fd9d2>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.cramco.net/ProductListing.aspx?CatId=87c6c35e-43ba-4a78-9d94-e6c9005fd9d2 took longer than 15.0 seconds..
2019-11-10 14:36:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demarini.com/en-us/bats/slowpitch-bats>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demarini.com/en-us/bats/slowpitch-bats took longer than 15.0 seconds..
2019-11-10 14:36:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/communities/west-virginia/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/communities/west-virginia/ took longer than 15.0 seconds..
2019-11-10 14:37:04 [scrapy.extensions.logstats] INFO: Crawled 2810 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 14:39:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cramco.net/ProductListing.aspx?CatId=853ae32b-b96d-4679-ab29-f2e515e8ebc7>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.cramco.net/ProductListing.aspx?CatId=853ae32b-b96d-4679-ab29-f2e515e8ebc7 took longer than 15.0 seconds..
2019-11-10 14:39:22 [scrapy.extensions.logstats] INFO: Crawled 2814 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 14:41:44 [scrapy.extensions.logstats] INFO: Crawled 2817 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 14:43:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/communities/west-virginia/jefferson-county/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/communities/west-virginia/jefferson-county/ took longer than 15.0 seconds..
2019-11-10 14:43:25 [scrapy.extensions.logstats] INFO: Crawled 2820 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 14:43:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://curtisindustries.net/tel:5088532200>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 14:45:08 [scrapy.extensions.logstats] INFO: Crawled 2823 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 14:45:08 [scrapy.core.scraper] ERROR: Error downloading <GET https://curtisindustries.net/product/glide-n-ride-yamaha-drive-cab/>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 14:46:18 [scrapy.core.scraper] ERROR: Error downloading <GET http://store.contour.com/collections/mounts>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://store.contour.com/collections/mounts took longer than 15.0 seconds..
2019-11-10 14:46:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.columbia.com/mens-clothing-outerwear/?icpa=hp&icid=subhero&icsa=fal19&prid=visnav&crid=mens-image>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.columbia.com/mens-clothing-outerwear/?icpa=hp&icid=subhero&icsa=fal19&prid=visnav&crid=mens-image took longer than 15.0 seconds..
2019-11-10 14:46:18 [scrapy.core.scraper] ERROR: Error downloading <GET http://help.contour.com>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://help.contour.com took longer than 15.0 seconds..
2019-11-10 14:46:42 [scrapy.extensions.logstats] INFO: Crawled 2826 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 14:46:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/communities/west-virginia/berkeley-county/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/communities/west-virginia/berkeley-county/ took longer than 15.0 seconds..
2019-11-10 14:46:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.columbia.com/sale-discount-baby-clothing/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.columbia.com/sale-discount-baby-clothing/ took longer than 15.0 seconds..
2019-11-10 14:46:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curtmfg.com/customer-testimonials/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curtmfg.com/customer-testimonials/ took longer than 15.0 seconds..
2019-11-10 14:47:54 [scrapy.extensions.logstats] INFO: Crawled 2828 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 14:48:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://curtisindustries.net/product/kubota-bx80-standard-cab/>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 14:48:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.columbia.com/sale-discount-toddler-clothing/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.columbia.com/sale-discount-toddler-clothing/ took longer than 15.0 seconds..
2019-11-10 14:48:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.dermalogica.com/on/demandware.store/Sites-Dermalogica-Site/en_US/SiteRedirects-SetURL?c=US&l=en>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.dermalogica.com/on/demandware.store/Sites-Dermalogica-Site/en_US/SiteRedirects-SetURL?c=US&l=en took longer than 15.0 seconds..
2019-11-10 14:48:17 [scrapy.extensions.logstats] INFO: Crawled 2830 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 14:48:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.columbia.com/sale-discount-girls-clothing/>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 14:48:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://curtisindustries.net/product/john-deere-2032r-2038r-standard-cab/>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 14:49:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://curtisindustries.net/product/2019-massey-ferguson-gc1723-gc1725-premium-cab/>: User timeout caused connection failure.
2019-11-10 14:49:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.columbia.com/sale-discount-boys-clothing/>: User timeout caused connection failure.
2019-11-10 14:49:28 [scrapy.extensions.logstats] INFO: Crawled 2830 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 14:49:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.columbia.com/sale-discount-kids-clothing/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.columbia.com/sale-discount-kids-clothing/ took longer than 15.0 seconds..
2019-11-10 14:49:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://curtisindustries.net/mahindra-tractor-cabs/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://curtisindustries.net/mahindra-tractor-cabs/ took longer than 15.0 seconds..
2019-11-10 14:49:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/communities/west-virginia/morgantown/>: User timeout caused connection failure.
2019-11-10 14:50:15 [scrapy.extensions.logstats] INFO: Crawled 2844 pages (at 14 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 14:52:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/communities/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/communities/ took longer than 15.0 seconds..
2019-11-10 14:52:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.deltachildren.com/pages/returns-exchanges/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.deltachildren.com/pages/returns-exchanges/ took longer than 15.0 seconds..
2019-11-10 14:52:19 [scrapy.extensions.logstats] INFO: Crawled 2844 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 14:53:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://curtisindustries.net/wishlist/?pdf=502> (referer: https://curtisindustries.net/wishlist/)
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spiders\crawl.py", line 76, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\root\Desktop\GitHub\innovScraping\innovationScraping\innovScrapyTools\innovScrapyCode\spiders\customized_web_crawler.py", line 67, in parse_item
    insert_into_mongo(response.url, response.text, self.coll)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\http\response\__init__.py", line 93, in text
    raise AttributeError("Response content isn't text")
AttributeError: Response content isn't text
2019-11-10 14:55:41 [scrapy.extensions.logstats] INFO: Crawled 2846 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 14:55:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curtmfg.com/cargo-management/bike-racks/standard>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curtmfg.com/cargo-management/bike-racks/standard took longer than 15.0 seconds..
2019-11-10 14:55:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.deltachildren.com/pages/privacy-policy>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.deltachildren.com/pages/privacy-policy took longer than 15.0 seconds..
2019-11-10 14:55:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://blog.columbia.com>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://blog.columbia.com took longer than 15.0 seconds..
2019-11-10 14:55:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://world.dvf.com/new/occasion-dressing/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://world.dvf.com/new/occasion-dressing/ took longer than 15.0 seconds..
2019-11-10 14:56:52 [scrapy.extensions.logstats] INFO: Crawled 2848 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 14:56:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curtmfg.com/cargo-management/bike-racks/tray>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 14:56:52 [scrapy.core.scraper] ERROR: Error downloading <GET http://blog.columbia.com/>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2019-11-10 14:58:08 [scrapy.extensions.logstats] INFO: Crawled 2850 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 14:58:08 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curtmfg.com/trailer-parts/cargo-straps>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 14:58:08 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demarini.com/custom/>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 14:59:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cramco.net/ProductListing.aspx?CatId=7382b83c-73fa-481e-8666-73ef4b4d64bf>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.cramco.net/ProductListing.aspx?CatId=7382b83c-73fa-481e-8666-73ef4b4d64bf took longer than 15.0 seconds..
2019-11-10 14:59:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/the-dan-ryan-builders-difference/behind-the-walls/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/the-dan-ryan-builders-difference/behind-the-walls/ took longer than 15.0 seconds..
2019-11-10 14:59:17 [scrapy.extensions.logstats] INFO: Crawled 2852 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 14:59:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curtmfg.com/trailer-parts/safety-chains-hooks/hooks/quick>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 14:59:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://curtisindustries.net/literature/>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 14:59:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/the-dan-ryan-builders-difference/testimonials/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/the-dan-ryan-builders-difference/testimonials/ took longer than 15.0 seconds..
2019-11-10 14:59:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://shop.demarini.com/us/customer/account/login>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://shop.demarini.com/us/customer/account/login took longer than 15.0 seconds..
2019-11-10 15:00:21 [scrapy.extensions.logstats] INFO: Crawled 2854 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 15:00:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curtmfg.com/trailer-parts/jacks/a-frame>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 15:01:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curtmfg.com/weight-distribution/replacement-parts/hardware>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curtmfg.com/weight-distribution/replacement-parts/hardware took longer than 15.0 seconds..
2019-11-10 15:01:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.columbia.com/activity-outdoor-clothing/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.columbia.com/activity-outdoor-clothing/ took longer than 15.0 seconds..
2019-11-10 15:01:29 [scrapy.extensions.logstats] INFO: Crawled 2855 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 15:02:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.columbia.com/mens-winter-boots-shoes/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.columbia.com/mens-winter-boots-shoes/ took longer than 15.0 seconds..
2019-11-10 15:02:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curtmfg.com/towing-accessories/security/locks/coupler>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curtmfg.com/towing-accessories/security/locks/coupler took longer than 15.0 seconds..
2019-11-10 15:02:04 [scrapy.extensions.logstats] INFO: Crawled 2855 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 15:02:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curtmfg.com/towing-accessories/ball-mounts/2-inch/right-angle>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curtmfg.com/towing-accessories/ball-mounts/2-inch/right-angle took longer than 15.0 seconds..
2019-11-10 15:02:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://curtisindustries.net/product-pages/clearance/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://curtisindustries.net/product-pages/clearance/ took longer than 15.0 seconds..
2019-11-10 15:02:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.columbia.com/kids-accessories-waterbottles/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.columbia.com/kids-accessories-waterbottles/ took longer than 15.0 seconds..
2019-11-10 15:02:38 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.danryanbuilders.com/the-dan-ryan-builders-difference/contact-us/tel:8642147440>: HTTP status code is not handled or not allowed
2019-11-10 15:03:11 [scrapy.extensions.logstats] INFO: Crawled 2871 pages (at 16 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 15:06:00 [scrapy.extensions.logstats] INFO: Crawled 2871 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 15:10:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://curtisindustries.net/spreaders/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://curtisindustries.net/spreaders/ took longer than 15.0 seconds..
2019-11-10 15:10:13 [scrapy.extensions.logstats] INFO: Crawled 2872 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 15:10:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://curtisindustries.net/plows/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://curtisindustries.net/plows/ took longer than 15.0 seconds..
2019-11-10 15:10:37 [scrapy.core.scraper] ERROR: Error downloading <GET https://curtisindustries.net/front-end-loader-blades/>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 15:10:37 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.columbia.com/girls-outdoor-clothing/>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 15:11:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.crabtree-evelyn.com/pages/contact-us>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.crabtree-evelyn.com/pages/contact-us took longer than 15.0 seconds..
2019-11-10 15:11:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://curtisindustries.net/canopies-windshields/>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 15:11:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.columbia.com/kids-boys-equipment/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.columbia.com/kids-boys-equipment/ took longer than 15.0 seconds..
2019-11-10 15:11:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.crabtree-evelyn.com/pages/faqs>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.crabtree-evelyn.com/pages/faqs took longer than 15.0 seconds..
2019-11-10 15:11:24 [scrapy.extensions.logstats] INFO: Crawled 2875 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 15:11:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://curtisindustries.net/product-pages/curtis-attachments/>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 15:11:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demarini.com/en-us/international>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demarini.com/en-us/international took longer than 15.0 seconds..
2019-11-10 15:11:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.crabtree-evelyn.com/collections/mainline/products/8393>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 15:11:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://curtisindustries.net/product-pages/air-conditioning/>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 15:11:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.columbia.com/boys-accessories/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.columbia.com/boys-accessories/ took longer than 15.0 seconds..
2019-11-10 15:11:49 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.danryanbuilders.com/the-dan-ryan-builders-difference/contact-us/tel:2404206050>: HTTP status code is not handled or not allowed
2019-11-10 15:12:13 [scrapy.extensions.logstats] INFO: Crawled 2885 pages (at 10 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 15:16:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demers-ambulances.com/terms-of-use/>: User timeout caused connection failure.
2019-11-10 15:16:57 [scrapy.extensions.logstats] INFO: Crawled 2894 pages (at 9 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 15:21:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://curtisindustries.net/product-pages/compact-tractor-cabs/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://curtisindustries.net/product-pages/compact-tractor-cabs/ took longer than 15.0 seconds..
2019-11-10 15:21:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/the-dan-ryan-builders-difference/commitment-to-the-communities/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/the-dan-ryan-builders-difference/commitment-to-the-communities/ took longer than 15.0 seconds..
2019-11-10 15:21:32 [scrapy.extensions.logstats] INFO: Crawled 2895 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 15:21:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.beautycounter.com/product/transforming-duo-2019>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.beautycounter.com/product/transforming-duo-2019 took longer than 15.0 seconds..
2019-11-10 15:21:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://shop.demarini.com/en-us/checkout/cart>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://shop.demarini.com/en-us/checkout/cart took longer than 15.0 seconds..
2019-11-10 15:21:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demers-ambulances.com/deliveries/peterborough-fire-rescue-2017/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demers-ambulances.com/deliveries/peterborough-fire-rescue-2017/ took longer than 15.0 seconds..
2019-11-10 15:21:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://curtisindustries.net/about/news-and-media/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://curtisindustries.net/about/news-and-media/ took longer than 15.0 seconds..
2019-11-10 15:22:07 [scrapy.extensions.logstats] INFO: Crawled 2896 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 15:22:07 [scrapy.core.scraper] ERROR: Error downloading <GET https://curtisindustries.net/history/>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 15:22:07 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.beautycounter.com/product/better-balm-duo>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 15:22:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.beautycounter.com/product/eye-sparklers-palette>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 15:22:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://curtisindustries.net/about/>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 15:22:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://curtisindustries.net/#main-content-container>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 15:22:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.beautycounter.com/product/glow-and-go-mini-oils>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 15:23:20 [scrapy.extensions.logstats] INFO: Crawled 2899 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 15:23:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.beautycounter.com/revolution>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.beautycounter.com/revolution took longer than 15.0 seconds..
2019-11-10 15:23:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.beautycounter.com/our-mission>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 15:24:30 [scrapy.extensions.logstats] INFO: Crawled 2901 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 15:24:30 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.beautycounter.com/products/counterman>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 15:25:06 [scrapy.extensions.logstats] INFO: Crawled 2902 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 15:25:43 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.beautycounter.com/products/bath-body>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.beautycounter.com/products/bath-body took longer than 15.0 seconds..
2019-11-10 15:25:43 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.columbia.com/women-plussizes-pfg/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.columbia.com/women-plussizes-pfg/ took longer than 15.0 seconds..
2019-11-10 15:25:43 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demers-ambulances.com/deliveries/nebraska-city-fire-rescue/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demers-ambulances.com/deliveries/nebraska-city-fire-rescue/ took longer than 15.0 seconds..
2019-11-10 15:25:43 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.beautycounter.com/products/makeup>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 15:26:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.columbia.com/womens-plus-size-jackets-vests/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.columbia.com/womens-plus-size-jackets-vests/ took longer than 15.0 seconds..
2019-11-10 15:26:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demers-ambulances.com/deliveries/los-pinos-fire-district/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demers-ambulances.com/deliveries/los-pinos-fire-district/ took longer than 15.0 seconds..
2019-11-10 15:26:18 [scrapy.extensions.logstats] INFO: Crawled 2904 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 15:26:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.crabtree-evelyn.com/products/8487>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 15:26:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.columbia.com/womens-plus-size-clothing/>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 15:26:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demers-ambulances.com/delivery/showcase/wheaton-fire-department/>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 15:26:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.beautycounter.com/products/skin-care>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 15:26:51 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.dacor.com/products/collections/product-comparison>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 15:26:51 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.columbia.com/womens-water-shoe/>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 15:26:51 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.beautycounter.com/products/gifts>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 15:27:14 [scrapy.extensions.logstats] INFO: Crawled 2906 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 15:27:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.beautycounter.com/help/shipping>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 15:27:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.columbia.com/womens-boots/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.columbia.com/womens-boots/ took longer than 15.0 seconds..
2019-11-10 15:27:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demers-ambulances.com/model-comparison-chart/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demers-ambulances.com/model-comparison-chart/ took longer than 15.0 seconds..
2019-11-10 15:28:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.crabtree-evelyn.com/products/9213>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.crabtree-evelyn.com/products/9213 took longer than 15.0 seconds..
2019-11-10 15:28:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.coty.com/terms-use>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.coty.com/terms-use took longer than 15.0 seconds..
2019-11-10 15:28:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.columbia.com/womens-shoes/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.columbia.com/womens-shoes/ took longer than 15.0 seconds..
2019-11-10 15:28:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demers-ambulances.com/ambulances/type-iii/fire>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demers-ambulances.com/ambulances/type-iii/fire took longer than 15.0 seconds..
2019-11-10 15:28:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.beautycounter.com/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.beautycounter.com/ took longer than 15.0 seconds..
2019-11-10 15:28:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/email-alerts>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/email-alerts took longer than 15.0 seconds..
2019-11-10 15:28:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://world.dvf.com/on/demandware.store/Sites-DvF_World-Site/default/Flow-ChangeLocale?country=TGO&language=ee>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://world.dvf.com/on/demandware.store/Sites-DvF_World-Site/default/Flow-ChangeLocale?country=TGO&language=ee took longer than 15.0 seconds..
2019-11-10 15:28:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.coty.com/faq>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.coty.com/faq took longer than 15.0 seconds..
2019-11-10 15:28:22 [scrapy.extensions.logstats] INFO: Crawled 2908 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 15:28:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://world.dvf.com/on/demandware.store/Sites-DvF_World-Site/default/Flow-ChangeLocale?country=THA&language=th>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://world.dvf.com/on/demandware.store/Sites-DvF_World-Site/default/Flow-ChangeLocale?country=THA&language=th took longer than 15.0 seconds..
2019-11-10 15:29:09 [scrapy.extensions.logstats] INFO: Crawled 2923 pages (at 15 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 15:31:24 [scrapy.extensions.logstats] INFO: Crawled 2923 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 15:34:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://world.dvf.com/on/demandware.store/Sites-DvF_World-Site/default/Flow-ChangeLocale?country=ISR&language=ar>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://world.dvf.com/on/demandware.store/Sites-DvF_World-Site/default/Flow-ChangeLocale?country=ISR&language=ar took longer than 15.0 seconds..
2019-11-10 15:34:11 [scrapy.extensions.logstats] INFO: Crawled 2924 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 15:34:11 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/warranty>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/warranty took longer than 15.0 seconds..
2019-11-10 15:34:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demers-ambulances.com/contact/international/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demers-ambulances.com/contact/international/ took longer than 15.0 seconds..
2019-11-10 15:34:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.columbia.com/womens-skirts-skorts/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.columbia.com/womens-skirts-skorts/ took longer than 15.0 seconds..
2019-11-10 15:34:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://world.dvf.com/on/demandware.store/Sites-DvF_World-Site/default/Flow-ChangeLocale?country=IDN&language=id>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://world.dvf.com/on/demandware.store/Sites-DvF_World-Site/default/Flow-ChangeLocale?country=IDN&language=id took longer than 15.0 seconds..
2019-11-10 15:34:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.dacor.com/products/collections/heritage>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 15:34:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://world.dvf.com/on/demandware.store/Sites-DvF_World-Site/default/Flow-ChangeLocale?country=ARM&language=hy>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 15:34:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.columbia.com/womens-pants-hiking-trail/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.columbia.com/womens-pants-hiking-trail/ took longer than 15.0 seconds..
2019-11-10 15:34:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demers-ambulances.com/contact/canada/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demers-ambulances.com/contact/canada/ took longer than 15.0 seconds..
2019-11-10 15:34:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://world.dvf.com/on/demandware.store/Sites-DvF_World-Site/default/Flow-ChangeLocale?country=ARG&language=es>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 15:34:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.dacor.com/home>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 15:34:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demarini.com/en-us/how-to-choose-a-bat>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demarini.com/en-us/how-to-choose-a-bat took longer than 15.0 seconds..
2019-11-10 15:35:19 [scrapy.extensions.logstats] INFO: Crawled 2934 pages (at 10 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 15:38:20 [scrapy.downloadermiddlewares.robotstxt] ERROR: Error downloading <GET http://www.DVF.com/robots.txt>: User timeout caused connection failure: Getting https://www.dvf.com/robots.txt took longer than 15.0 seconds..
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.dvf.com/robots.txt took longer than 15.0 seconds..
2019-11-10 15:38:20 [scrapy.extensions.logstats] INFO: Crawled 2940 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 15:40:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demarini.com/en-us/fastpitch>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demarini.com/en-us/fastpitch took longer than 15.0 seconds..
2019-11-10 15:40:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://world.dvf.com/shoes/sandals-flats/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://world.dvf.com/shoes/sandals-flats/ took longer than 15.0 seconds..
2019-11-10 15:40:55 [scrapy.extensions.logstats] INFO: Crawled 2941 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 15:40:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.columbia.com/women-bottoms-pants/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.columbia.com/women-bottoms-pants/ took longer than 15.0 seconds..
2019-11-10 15:40:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demarini.com/en-us/bats/fastpitch-bats/prism>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demarini.com/en-us/bats/fastpitch-bats/prism took longer than 15.0 seconds..
2019-11-10 15:40:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demers-ambulances.com/contact/request-demo/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demers-ambulances.com/contact/request-demo/ took longer than 15.0 seconds..
2019-11-10 15:40:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.deltaapparelinc.com/privacy-policy>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.deltaapparelinc.com/privacy-policy took longer than 15.0 seconds..
2019-11-10 15:40:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://world.dvf.com/clothing/dresses/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://world.dvf.com/clothing/dresses/ took longer than 15.0 seconds..
2019-11-10 15:41:19 [scrapy.extensions.logstats] INFO: Crawled 2943 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 15:42:01 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demarini.com/en-us/explore/demarini-nation>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demarini.com/en-us/explore/demarini-nation took longer than 15.0 seconds..
2019-11-10 15:42:01 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.deltaapparelinc.com/california-transparency-act>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.deltaapparelinc.com/california-transparency-act took longer than 15.0 seconds..
2019-11-10 15:42:01 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.columbia.com/pants-women/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.columbia.com/pants-women/ took longer than 15.0 seconds..
2019-11-10 15:42:01 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demers-ambulances.com/parts-accessories-services/medical-equipment/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demers-ambulances.com/parts-accessories-services/medical-equipment/ took longer than 15.0 seconds..
2019-11-10 15:42:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demarini.com/en-us/explore/history>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demarini.com/en-us/explore/history took longer than 15.0 seconds..
2019-11-10 15:42:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.columbia.com/women-baselayer-thermals-tops/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.columbia.com/women-baselayer-thermals-tops/ took longer than 15.0 seconds..
2019-11-10 15:42:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demers-ambulances.com/parts-accessories-services/warranty/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demers-ambulances.com/parts-accessories-services/warranty/ took longer than 15.0 seconds..
2019-11-10 15:42:45 [scrapy.extensions.logstats] INFO: Crawled 2944 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 15:42:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demarini.com/en-us/baseball>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 15:42:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://world.dvf.com>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 15:43:20 [scrapy.extensions.logstats] INFO: Crawled 2953 pages (at 9 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 15:45:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curls.biz/It-s-A-Curl-For-Babies/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curls.biz/It-s-A-Curl-For-Babies/ took longer than 15.0 seconds..
2019-11-10 15:45:12 [scrapy.extensions.logstats] INFO: Crawled 2959 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 15:48:12 [scrapy.extensions.logstats] INFO: Crawled 2959 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 15:50:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curls.biz/curly-q-hair-products-for-kids/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curls.biz/curly-q-hair-products-for-kids/ took longer than 15.0 seconds..
2019-11-10 15:50:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://world.dvf.com/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://world.dvf.com/ took longer than 15.0 seconds..
2019-11-10 15:50:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demarini.com/en-us/batting-helmets>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demarini.com/en-us/batting-helmets took longer than 15.0 seconds..
2019-11-10 15:50:10 [scrapy.extensions.logstats] INFO: Crawled 2960 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 15:50:33 [scrapy.core.scraper] ERROR: Error downloading <GET https://world.dvf.com>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://world.dvf.com took longer than 15.0 seconds..
2019-11-10 15:50:33 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demarini.com/en-us/bags/backpacks>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demarini.com/en-us/bags/backpacks took longer than 15.0 seconds..
2019-11-10 15:50:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demarini.com/en-us/bats/baseball-bats/usa-baseball-bats>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demarini.com/en-us/bats/baseball-bats/usa-baseball-bats took longer than 15.0 seconds..
2019-11-10 15:51:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/press-releases/detail/290/delta-apparel-reports-fiscal-2019-second-quarter-and>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/press-releases/detail/290/delta-apparel-reports-fiscal-2019-second-quarter-and took longer than 15.0 seconds..
2019-11-10 15:51:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://world.dvf.com/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://world.dvf.com/ took longer than 15.0 seconds..
2019-11-10 15:51:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demarini.com/en-us/bats/baseball-bats/senior-league-baseball-bats>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demarini.com/en-us/bats/baseball-bats/senior-league-baseball-bats took longer than 15.0 seconds..
2019-11-10 15:51:21 [scrapy.extensions.logstats] INFO: Crawled 2962 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 15:51:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/faq>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/faq took longer than 15.0 seconds..
2019-11-10 15:52:57 [scrapy.extensions.logstats] INFO: Crawled 2972 pages (at 10 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 15:52:57 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=426>: HTTP status code is not handled or not allowed
2019-11-10 15:54:49 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.crabtree-evelyn.com/apps/%redirect_store_url%>: HTTP status code is not handled or not allowed
2019-11-10 15:54:49 [scrapy.extensions.logstats] INFO: Crawled 2975 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 15:54:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://curtisindustries.net/product-pages/golf-car-ptv/%7B%7B%20x.link>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://curtisindustries.net/product-pages/golf-car-ptv/%7B%7B%20x.link took longer than 15.0 seconds..
2019-11-10 15:55:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/stock-data>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/stock-data took longer than 15.0 seconds..
2019-11-10 15:55:58 [scrapy.extensions.logstats] INFO: Crawled 2977 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 15:55:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.crabtree-evelyn.com/#MainContent>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 15:56:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/quote>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/quote took longer than 15.0 seconds..
2019-11-10 15:56:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.crosman.com/general/terms-of-use>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.crosman.com/general/terms-of-use took longer than 15.0 seconds..
2019-11-10 15:56:57 [scrapy.extensions.logstats] INFO: Crawled 2979 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 15:57:21 [scrapy.extensions.logstats] INFO: Crawled 2981 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 15:57:44 [scrapy.core.scraper] ERROR: Error downloading <GET https://curtisindustries.net/kubota-utv-cabs/%7B%7B%20x.link>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 15:58:32 [scrapy.extensions.logstats] INFO: Crawled 2983 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 15:59:37 [scrapy.extensions.logstats] INFO: Crawled 2983 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 15:59:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curls.biz/baby-hair-cream.html>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curls.biz/baby-hair-cream.html took longer than 15.0 seconds..
2019-11-10 15:59:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curtmfg.com/gooseneck/adapters/x5>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curtmfg.com/gooseneck/adapters/x5 took longer than 15.0 seconds..
2019-11-10 15:59:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.crosman.com/catalog-2019-pdf>: User timeout caused connection failure.
2019-11-10 15:59:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demers-ambulances.com/parts-accessories-services/parts-catalog/categories/>: User timeout caused connection failure.
2019-11-10 16:00:05 [scrapy.extensions.logstats] INFO: Crawled 2992 pages (at 9 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 16:04:29 [scrapy.extensions.logstats] INFO: Crawled 2998 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 16:04:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://support.crosman.com/hc/en-us/categories/200223634-Owner-s-Manuals-and-Parts-Diagrams>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://support.crosman.com/hc/en-us/categories/200223634-Owner-s-Manuals-and-Parts-Diagrams took longer than 15.0 seconds..
2019-11-10 16:04:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.dermaflash.com/on/demandware.store/Sites-trydermaflash-Site/default/Page-Include?cid=privacy-policy>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.dermaflash.com/on/demandware.store/Sites-trydermaflash-Site/default/Page-Include?cid=privacy-policy took longer than 15.0 seconds..
2019-11-10 16:06:51 [scrapy.extensions.logstats] INFO: Crawled 3004 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 16:06:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demers-ambulances.com/ambulances/remount-retrofit/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demers-ambulances.com/ambulances/remount-retrofit/ took longer than 15.0 seconds..
2019-11-10 16:06:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curtmfg.com/gooseneck/installation-brackets/under-bed>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curtmfg.com/gooseneck/installation-brackets/under-bed took longer than 15.0 seconds..
2019-11-10 16:06:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.dermaflash.com/on/demandware.store/Sites-trydermaflash-Site/default/Page-Include?cid=terms-and-conditions>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.dermaflash.com/on/demandware.store/Sites-trydermaflash-Site/default/Page-Include?cid=terms-and-conditions took longer than 15.0 seconds..
2019-11-10 16:09:46 [scrapy.extensions.logstats] INFO: Crawled 3010 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 16:10:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curtmfg.com/gooseneck/installation-brackets>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 16:10:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demers-ambulances.com/ambulances/in-stock/preowned/>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 16:10:58 [scrapy.extensions.logstats] INFO: Crawled 3014 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 16:12:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demers-ambulances.com/ambulances/demers-difference/engineering/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demers-ambulances.com/ambulances/demers-difference/engineering/ took longer than 15.0 seconds..
2019-11-10 16:12:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curtmfg.com/gooseneck/hitches/oem-style>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curtmfg.com/gooseneck/hitches/oem-style took longer than 15.0 seconds..
2019-11-10 16:12:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.diamondwipes.com/blogs/news/diamond-wipes-international-usa-table-tennis-announce-partnership>: User timeout caused connection failure.
2019-11-10 16:12:54 [scrapy.extensions.logstats] INFO: Crawled 3014 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 16:15:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.deltaapparelinc.com/investors/stock-data>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.deltaapparelinc.com/investors/stock-data took longer than 15.0 seconds..
2019-11-10 16:15:25 [scrapy.extensions.logstats] INFO: Crawled 3015 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 16:16:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.deltaapparelinc.com/investors/financial-information>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.deltaapparelinc.com/investors/financial-information took longer than 15.0 seconds..
2019-11-10 16:16:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.coty.com/sustainability/workplace>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.coty.com/sustainability/workplace took longer than 15.0 seconds..
2019-11-10 16:16:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.deltaapparelinc.com/investors/news-events>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.deltaapparelinc.com/investors/news-events took longer than 15.0 seconds..
2019-11-10 16:16:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curtmfg.com/gooseneck/oem-puck-system-kits>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curtmfg.com/gooseneck/oem-puck-system-kits took longer than 15.0 seconds..
2019-11-10 16:16:27 [scrapy.extensions.logstats] INFO: Crawled 3016 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 16:16:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.dermaflash.com/faqs.html>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 16:16:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/press-releases/detail/284/delta-apparel-reports-first-quarter-fiscal-2019-results>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/press-releases/detail/284/delta-apparel-reports-first-quarter-fiscal-2019-results took longer than 15.0 seconds..
2019-11-10 16:16:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.deltaapparelinc.com/investors/_>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.deltaapparelinc.com/investors/_ took longer than 15.0 seconds..
2019-11-10 16:16:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demers-ambulances.com/ambulances/type-iii/ems/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demers-ambulances.com/ambulances/type-iii/ems/ took longer than 15.0 seconds..
2019-11-10 16:17:15 [scrapy.extensions.logstats] INFO: Crawled 3028 pages (at 12 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 16:19:14 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=16145>: HTTP status code is not handled or not allowed
2019-11-10 16:19:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/sec-filings>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/sec-filings took longer than 15.0 seconds..
2019-11-10 16:19:15 [scrapy.extensions.logstats] INFO: Crawled 3031 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 16:21:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.deltaapparelinc.com/our-brands/coast>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.deltaapparelinc.com/our-brands/coast took longer than 15.0 seconds..
2019-11-10 16:21:21 [scrapy.extensions.logstats] INFO: Crawled 3031 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 16:23:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.coty.com/sustainability/inclusive-beauty>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.coty.com/sustainability/inclusive-beauty took longer than 15.0 seconds..
2019-11-10 16:23:10 [scrapy.extensions.logstats] INFO: Crawled 3031 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 16:23:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.deltachildren.com/collections/full-size-bed-rails>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.deltachildren.com/collections/full-size-bed-rails took longer than 15.0 seconds..
2019-11-10 16:24:19 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=17795>: HTTP status code is not handled or not allowed
2019-11-10 16:24:19 [scrapy.extensions.logstats] INFO: Crawled 3040 pages (at 9 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 16:24:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curtmfg.com/5th-wheel/extension-harnesses>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curtmfg.com/5th-wheel/extension-harnesses took longer than 15.0 seconds..
2019-11-10 16:27:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.coty.com/brands/consumer-beauty>: User timeout caused connection failure.
2019-11-10 16:27:42 [scrapy.extensions.logstats] INFO: Crawled 3045 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 16:30:44 [scrapy.core.scraper] ERROR: Error downloading <GET http://investors.coopertire.com>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://investors.coopertire.com took longer than 15.0 seconds..
2019-11-10 16:30:44 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.columbia.com/sale-discount-mens-big-tall/>: User timeout caused connection failure.
2019-11-10 16:30:44 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curtmfg.com/5th-wheel/gooseneck-adapters/rail-hitches>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curtmfg.com/5th-wheel/gooseneck-adapters/rail-hitches took longer than 15.0 seconds..
2019-11-10 16:30:44 [scrapy.core.scraper] ERROR: Error downloading <GET http://ca.coopertire.com/safety/tips/rotation>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://ca.coopertire.com/safety/tips/rotation took longer than 15.0 seconds..
2019-11-10 16:30:44 [scrapy.extensions.logstats] INFO: Crawled 3045 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 16:30:44 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.deltaapparelinc.com/about/careers>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.deltaapparelinc.com/about/careers took longer than 15.0 seconds..
2019-11-10 16:31:20 [scrapy.extensions.logstats] INFO: Crawled 3059 pages (at 14 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 16:32:32 [scrapy.extensions.logstats] INFO: Crawled 3068 pages (at 9 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 16:38:46 [scrapy.extensions.logstats] INFO: Crawled 3068 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 16:43:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.deltachildren.com/collections/cribs/products/princess-magical-dreams-4-in-1-crib>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.deltachildren.com/collections/cribs/products/princess-magical-dreams-4-in-1-crib took longer than 15.0 seconds..
2019-11-10 16:43:11 [scrapy.extensions.logstats] INFO: Crawled 3069 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 16:43:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.dermaflash.com>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.dermaflash.com took longer than 15.0 seconds..
2019-11-10 16:43:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.columbia.com/toolsandhome/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.columbia.com/toolsandhome/ took longer than 15.0 seconds..
2019-11-10 16:43:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curtmfg.com/5th-wheel/hitches/25k>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curtmfg.com/5th-wheel/hitches/25k took longer than 15.0 seconds..
2019-11-10 16:43:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.deltachildren.com/products/northbrook-4-in-1-crib?variant=15944402819>: User timeout caused connection failure.
2019-11-10 16:44:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.deltaapparelinc.com/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.deltaapparelinc.com/ took longer than 15.0 seconds..
2019-11-10 16:44:12 [scrapy.core.scraper] ERROR: Error downloading <GET http://ca.coopertire.com/about-us/sponsorships>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://ca.coopertire.com/about-us/sponsorships took longer than 15.0 seconds..
2019-11-10 16:44:12 [scrapy.extensions.logstats] INFO: Crawled 3071 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 16:44:12 [scrapy.core.scraper] ERROR: Error downloading <GET http://ca.coopertire.com/about-us/why-cooper>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://ca.coopertire.com/about-us/why-cooper took longer than 15.0 seconds..
2019-11-10 16:44:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curtmfg.com/5th-wheel/hitches/24k>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curtmfg.com/5th-wheel/hitches/24k took longer than 15.0 seconds..
2019-11-10 16:44:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.columbia.com/men-equipment-duffels/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.columbia.com/men-equipment-duffels/ took longer than 15.0 seconds..
2019-11-10 16:45:15 [scrapy.core.scraper] ERROR: Error downloading <GET http://frca.coopertire.com/tires/view-tires>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://frca.coopertire.com/tires/view-tires took longer than 15.0 seconds..
2019-11-10 16:45:15 [scrapy.core.scraper] ERROR: Error downloading <GET http://ca.coopertire.com/safety/replacement-guide/speed-rating>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://ca.coopertire.com/safety/replacement-guide/speed-rating took longer than 15.0 seconds..
2019-11-10 16:45:15 [scrapy.extensions.logstats] INFO: Crawled 3073 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 16:45:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curls.biz/add_review.php?productid=16175>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curls.biz/add_review.php?productid=16175 took longer than 15.0 seconds..
2019-11-10 16:45:48 [scrapy.core.scraper] ERROR: Error downloading <GET http://ca.coopertire.com/safety/replacement-guide/load-capacity>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://ca.coopertire.com/safety/replacement-guide/load-capacity took longer than 15.0 seconds..
2019-11-10 16:45:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.columbia.com/men-equipment/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.columbia.com/men-equipment/ took longer than 15.0 seconds..
2019-11-10 16:45:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curtmfg.com/5th-wheel/hitches>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curtmfg.com/5th-wheel/hitches took longer than 15.0 seconds..
2019-11-10 16:46:20 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curls.biz/add_review.php?productid=16174>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curls.biz/add_review.php?productid=16174 took longer than 15.0 seconds..
2019-11-10 16:46:20 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.columbia.com/mens-watches/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.columbia.com/mens-watches/ took longer than 15.0 seconds..
2019-11-10 16:46:20 [scrapy.extensions.logstats] INFO: Crawled 3075 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 16:46:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=16174>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=16174 took longer than 15.0 seconds..
2019-11-10 16:46:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curtmfg.com/5th-wheel>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curtmfg.com/5th-wheel took longer than 15.0 seconds..
2019-11-10 16:46:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demers-ambulances.com/about/history/>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 16:47:32 [scrapy.extensions.logstats] INFO: Crawled 3077 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 16:48:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=16187>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=16187 took longer than 15.0 seconds..
2019-11-10 16:48:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.conversionlabs.com/historical-data>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.conversionlabs.com/historical-data took longer than 15.0 seconds..
2019-11-10 16:48:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demers-ambulances.com/about/videos/category/merger/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demers-ambulances.com/about/videos/category/merger/ took longer than 15.0 seconds..
2019-11-10 16:48:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://support.crosman.com/hc>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://support.crosman.com/hc took longer than 15.0 seconds..
2019-11-10 16:48:40 [scrapy.extensions.logstats] INFO: Crawled 3078 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 16:48:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curls.biz/curly-q-gel-les-c-for-all-hair-types.html>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curls.biz/curly-q-gel-les-c-for-all-hair-types.html took longer than 15.0 seconds..
2019-11-10 16:48:40 [scrapy.core.scraper] ERROR: Error downloading <GET http://ca.coopertire.com/safety/replacement-guide>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://ca.coopertire.com/safety/replacement-guide took longer than 15.0 seconds..
2019-11-10 16:48:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curtmfg.com/trailer-hitches/weld-on>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curtmfg.com/trailer-hitches/weld-on took longer than 15.0 seconds..
2019-11-10 16:48:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.columbia.com/mens-shorts/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.columbia.com/mens-shorts/ took longer than 15.0 seconds..
2019-11-10 16:49:14 [scrapy.extensions.logstats] INFO: Crawled 3089 pages (at 11 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 16:51:27 [scrapy.extensions.logstats] INFO: Crawled 3095 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 16:53:27 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=405>: HTTP status code is not handled or not allowed
2019-11-10 16:53:28 [scrapy.core.scraper] ERROR: Error downloading <GET http://ca.coopertire.com/tires/view-tires/trucks-pickups>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://ca.coopertire.com/tires/view-tires/trucks-pickups took longer than 15.0 seconds..
2019-11-10 16:53:28 [scrapy.extensions.logstats] INFO: Crawled 3095 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 16:56:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/communities/north-carolina/raleigh/>: User timeout caused connection failure.
2019-11-10 16:56:40 [scrapy.extensions.logstats] INFO: Crawled 3095 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 16:56:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/communities/north-carolina/charlotte-metro/>: User timeout caused connection failure.
2019-11-10 16:57:14 [scrapy.extensions.logstats] INFO: Crawled 3106 pages (at 11 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 16:59:00 [scrapy.extensions.logstats] INFO: Crawled 3115 pages (at 9 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 17:02:56 [scrapy.extensions.logstats] INFO: Crawled 3115 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 17:08:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/communities/maryland/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/communities/maryland/ took longer than 15.0 seconds..
2019-11-10 17:08:10 [scrapy.extensions.logstats] INFO: Crawled 3115 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 17:08:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curls.biz/best-curl-defining-cream-products.html>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curls.biz/best-curl-defining-cream-products.html took longer than 15.0 seconds..
2019-11-10 17:10:19 [scrapy.extensions.logstats] INFO: Crawled 3130 pages (at 15 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 17:11:46 [scrapy.core.scraper] ERROR: Error downloading <GET http://ca.coopertire.com/for-owners/voluntary-recall-information>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://ca.coopertire.com/for-owners/voluntary-recall-information took longer than 15.0 seconds..
2019-11-10 17:11:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.columbia.com/men-shirts-polos/>: User timeout caused connection failure.
2019-11-10 17:11:46 [scrapy.extensions.logstats] INFO: Crawled 3130 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 17:14:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curls.biz/help.php>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curls.biz/help.php took longer than 15.0 seconds..
2019-11-10 17:14:42 [scrapy.extensions.logstats] INFO: Crawled 3130 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 17:14:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curtmfg.com/trailer-hitches>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curtmfg.com/trailer-hitches took longer than 15.0 seconds..
2019-11-10 17:14:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.conversionlabs.com/join/%20target=>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.conversionlabs.com/join/%20target= took longer than 15.0 seconds..
2019-11-10 17:14:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curls.biz/best-shampoo-for-curly-hair/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curls.biz/best-shampoo-for-curly-hair/ took longer than 15.0 seconds..
2019-11-10 17:15:06 [scrapy.extensions.logstats] INFO: Crawled 3140 pages (at 10 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 17:18:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cyanotech.com/cdn-cgi/l/email-protection#d0b9beb6bf90b3a9b1bebfa4b5b3b8feb3bfbd>: User timeout caused connection failure.
2019-11-10 17:18:40 [scrapy.extensions.logstats] INFO: Crawled 3147 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 17:21:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://d1io3yog0oux5.cloudfront.net/_85dd8d46f96813e295ff66f66ed12eac/conversionlabs/db/235/819/pdf/CVLB+Corporate+Presentation+Q3+2019.pdf>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://d1io3yog0oux5.cloudfront.net/_85dd8d46f96813e295ff66f66ed12eac/conversionlabs/db/235/819/pdf/CVLB+Corporate+Presentation+Q3+2019.pdf took longer than 15.0 seconds..
2019-11-10 17:21:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curls.biz/Blueberry-Bliss-Reparative-Hair-Mask.html>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curls.biz/Blueberry-Bliss-Reparative-Hair-Mask.html took longer than 15.0 seconds..
2019-11-10 17:21:55 [scrapy.extensions.logstats] INFO: Crawled 3147 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 17:21:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curls.biz/Blueberry-Collection/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curls.biz/Blueberry-Collection/ took longer than 15.0 seconds..
2019-11-10 17:22:32 [scrapy.extensions.logstats] INFO: Crawled 3151 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 17:23:32 [scrapy.extensions.logstats] INFO: Crawled 3155 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 17:24:03 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=17717>: HTTP status code is not handled or not allowed
2019-11-10 17:25:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curls.biz/curls-retail-products/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curls.biz/curls-retail-products/ took longer than 15.0 seconds..
2019-11-10 17:25:51 [scrapy.extensions.logstats] INFO: Crawled 3155 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 17:25:51 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curls.biz/Blueberry-Bliss-Reparative-Hair-Wash.html>: User timeout caused connection failure.
2019-11-10 17:26:25 [scrapy.extensions.logstats] INFO: Crawled 3161 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 17:28:20 [scrapy.extensions.logstats] INFO: Crawled 3165 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 17:29:50 [scrapy.extensions.logstats] INFO: Crawled 3167 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 17:30:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curls.biz/add_review.php?productid=17723>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curls.biz/add_review.php?productid=17723 took longer than 15.0 seconds..
2019-11-10 17:30:19 [scrapy.extensions.logstats] INFO: Crawled 3169 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 17:31:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curls.biz/curly-blog/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curls.biz/curly-blog/ took longer than 15.0 seconds..
2019-11-10 17:31:34 [scrapy.extensions.logstats] INFO: Crawled 3171 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 17:32:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curls.biz/curly-blog/category/news>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curls.biz/curly-blog/category/news took longer than 15.0 seconds..
2019-11-10 17:32:46 [scrapy.extensions.logstats] INFO: Crawled 3172 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 17:33:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curls.biz/curly-blog/category/celebrities>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curls.biz/curly-blog/category/celebrities took longer than 15.0 seconds..
2019-11-10 17:33:25 [scrapy.extensions.logstats] INFO: Crawled 3174 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 17:34:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curls.biz/curly-blog/curls-2018-scholarship-opportunity-105781>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curls.biz/curly-blog/curls-2018-scholarship-opportunity-105781 took longer than 15.0 seconds..
2019-11-10 17:34:31 [scrapy.extensions.logstats] INFO: Crawled 3176 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 17:35:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curls.biz/redirect.php?bannerid=15&imageid=125>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curls.biz/redirect.php?bannerid=15&imageid=125 took longer than 15.0 seconds..
2019-11-10 17:35:41 [scrapy.extensions.logstats] INFO: Crawled 3178 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 17:36:51 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curls.biz/redirect.php?bannerid=15&imageid=65>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curls.biz/redirect.php?bannerid=15&imageid=65 took longer than 15.0 seconds..
2019-11-10 17:36:52 [scrapy.extensions.logstats] INFO: Crawled 3179 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 17:37:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curls.biz/lose-curls-waves-products-by-type/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curls.biz/lose-curls-waves-products-by-type/ took longer than 15.0 seconds..
2019-11-10 17:37:25 [scrapy.extensions.logstats] INFO: Crawled 3180 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 17:38:01 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curls.biz/curly-hair-products-by-type/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curls.biz/curly-hair-products-by-type/ took longer than 15.0 seconds..
2019-11-10 17:38:37 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=17723>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=17723 took longer than 15.0 seconds..
2019-11-10 17:38:37 [scrapy.extensions.logstats] INFO: Crawled 3182 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 17:39:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curls.biz/very-curly-hair-products-by-type/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curls.biz/very-curly-hair-products-by-type/ took longer than 15.0 seconds..
2019-11-10 17:39:13 [scrapy.extensions.logstats] INFO: Crawled 3183 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 17:39:50 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.curls.biz/curly-blog/about-curls>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.curls.biz/curly-blog/about-curls took longer than 15.0 seconds..
2019-11-10 17:39:50 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.curls.biz/curly-blog/curls-video-product-demos>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.curls.biz/curly-blog/curls-video-product-demos took longer than 15.0 seconds..
2019-11-10 17:40:19 [scrapy.extensions.logstats] INFO: Crawled 3185 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 17:40:53 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.curls.biz/curly-blog/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.curls.biz/curly-blog/ took longer than 15.0 seconds..
2019-11-10 17:41:31 [scrapy.extensions.logstats] INFO: Crawled 3187 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 17:42:41 [scrapy.extensions.logstats] INFO: Crawled 3189 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 17:43:08 [scrapy.extensions.logstats] INFO: Crawled 3190 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 17:44:37 [scrapy.extensions.logstats] INFO: Crawled 3193 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 17:45:30 [scrapy.extensions.logstats] INFO: Crawled 3195 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 17:46:08 [scrapy.extensions.logstats] INFO: Crawled 3196 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 17:47:44 [scrapy.extensions.logstats] INFO: Crawled 3202 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 17:48:07 [scrapy.extensions.logstats] INFO: Crawled 3203 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 17:49:19 [scrapy.extensions.logstats] INFO: Crawled 3206 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 17:50:07 [scrapy.extensions.logstats] INFO: Crawled 3207 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 17:51:19 [scrapy.extensions.logstats] INFO: Crawled 3210 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 17:51:43 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.conferplastics.com/information/confer-and-the-community/>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2019-11-10 17:52:07 [scrapy.extensions.logstats] INFO: Crawled 3212 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 17:52:32 [scrapy.core.scraper] ERROR: Error downloading <GET http://ca.coopertire.com/promotions>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://ca.coopertire.com/promotions took longer than 15.0 seconds..
2019-11-10 17:53:15 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.conferplastics.com/pools-and-spa/pool-ladders-a-frame/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.conferplastics.com/pools-and-spa/pool-ladders-a-frame/ took longer than 15.0 seconds..
2019-11-10 17:53:15 [scrapy.core.scraper] ERROR: Error downloading <GET http://ca.coopertire.com/where-to-start>: User timeout caused connection failure.
2019-11-10 17:53:15 [scrapy.extensions.logstats] INFO: Crawled 3214 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 17:53:15 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.conferplastics.com/pools-and-spa/pool-deck-ladders/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.conferplastics.com/pools-and-spa/pool-deck-ladders/ took longer than 15.0 seconds..
2019-11-10 17:53:15 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.deckers.com/brands>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.deckers.com/brands took longer than 15.0 seconds..
2019-11-10 17:54:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cramco.net/ProductListing.aspx?CatId=14ea4a2b-3cb9-475e-92a3-7a89da43fe93>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.cramco.net/ProductListing.aspx?CatId=14ea4a2b-3cb9-475e-92a3-7a89da43fe93 took longer than 15.0 seconds..
2019-11-10 17:54:29 [scrapy.extensions.logstats] INFO: Crawled 3216 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 17:55:07 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cramco.net/ProductListing.aspx?CatId=4334ea5b-08a9-4c0c-aacc-f8f6abd768df>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.cramco.net/ProductListing.aspx?CatId=4334ea5b-08a9-4c0c-aacc-f8f6abd768df took longer than 15.0 seconds..
2019-11-10 17:55:07 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.conferplastics.com/category/tips/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.conferplastics.com/category/tips/ took longer than 15.0 seconds..
2019-11-10 17:55:07 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.deckers.com/culture/community-involvement>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.deckers.com/culture/community-involvement took longer than 15.0 seconds..
2019-11-10 17:55:07 [scrapy.core.scraper] ERROR: Error downloading <GET http://ca.coopertire.com/safety/tips/proper-tire-repair>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://ca.coopertire.com/safety/tips/proper-tire-repair took longer than 15.0 seconds..
2019-11-10 17:55:07 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cyanotech.com/our-purpose/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.cyanotech.com/our-purpose/ took longer than 15.0 seconds..
2019-11-10 17:55:07 [scrapy.extensions.logstats] INFO: Crawled 3217 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 17:55:44 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/press-releases/detail/153/delta-apparel-reports-fiscal-2017-first-quarter-results>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/press-releases/detail/153/delta-apparel-reports-fiscal-2017-first-quarter-results took longer than 15.0 seconds..
2019-11-10 17:55:44 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.conferplastics.com/shop/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.conferplastics.com/shop/ took longer than 15.0 seconds..
2019-11-10 17:55:44 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cyanotech.com/our-history/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.cyanotech.com/our-history/ took longer than 15.0 seconds..
2019-11-10 17:55:44 [scrapy.core.scraper] ERROR: Error downloading <GET http://ca.coopertire.com/safety/tips/storing-tires>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://ca.coopertire.com/safety/tips/storing-tires took longer than 15.0 seconds..
2019-11-10 17:55:44 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.deckers.com/careers>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.deckers.com/careers took longer than 15.0 seconds..
2019-11-10 17:56:07 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.conferplastics.com/category/news/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.conferplastics.com/category/news/ took longer than 15.0 seconds..
2019-11-10 17:56:07 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/press-releases/detail/151/delta-apparel-reports-fiscal-2016-fourth-quarter-and>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/press-releases/detail/151/delta-apparel-reports-fiscal-2016-fourth-quarter-and took longer than 15.0 seconds..
2019-11-10 17:56:07 [scrapy.core.scraper] ERROR: Error downloading <GET http://ca.coopertire.com/safety/replacement-guide/tire-mixing>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://ca.coopertire.com/safety/replacement-guide/tire-mixing took longer than 15.0 seconds..
2019-11-10 17:56:07 [scrapy.extensions.logstats] INFO: Crawled 3222 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 17:58:16 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.conferplastics.com/information/missing-or-replacement/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.conferplastics.com/information/missing-or-replacement/ took longer than 15.0 seconds..
2019-11-10 17:58:16 [scrapy.extensions.logstats] INFO: Crawled 3227 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 17:59:51 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.conferplastics.com/distributor-locator-where-to-buy/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.conferplastics.com/distributor-locator-where-to-buy/ took longer than 15.0 seconds..
2019-11-10 17:59:51 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cramco.net/ProductListing.aspx?CatId=5581bec1-96be-493d-b923-897f6d107421>: User timeout caused connection failure.
2019-11-10 17:59:51 [scrapy.extensions.logstats] INFO: Crawled 3227 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 18:01:04 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.conferplastics.com/information/manuals/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.conferplastics.com/information/manuals/ took longer than 15.0 seconds..
2019-11-10 18:01:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cramco.net/ContactUs.aspx?pageId=5>: User timeout caused connection failure.
2019-11-10 18:01:04 [scrapy.extensions.logstats] INFO: Crawled 3227 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 18:01:04 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.conferplastics.com/category/custom/>: User timeout caused connection failure.
2019-11-10 18:01:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.crosman.com/archery/centerpoint-crossbows>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.crosman.com/archery/centerpoint-crossbows took longer than 15.0 seconds..
2019-11-10 18:02:16 [scrapy.extensions.logstats] INFO: Crawled 3232 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 18:02:16 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.conferplastics.com/recall/>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2019-11-10 18:03:04 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.conferplastics.com/terms-and-conditions-for-proprietary/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.conferplastics.com/terms-and-conditions-for-proprietary/ took longer than 15.0 seconds..
2019-11-10 18:03:04 [scrapy.extensions.logstats] INFO: Crawled 3236 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 18:03:52 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.conferplastics.com/custom-blow-molding/samples-gallery/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.conferplastics.com/custom-blow-molding/samples-gallery/ took longer than 15.0 seconds..
2019-11-10 18:04:57 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.conferplastics.com/custom-blow-molding/capabilities-and-facilities/>: User timeout caused connection failure.
2019-11-10 18:04:57 [scrapy.extensions.logstats] INFO: Crawled 3240 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 18:05:46 [scrapy.extensions.logstats] INFO: Crawled 3242 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 18:06:59 [scrapy.extensions.logstats] INFO: Crawled 3244 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 18:08:09 [scrapy.extensions.logstats] INFO: Crawled 3246 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 18:09:24 [scrapy.extensions.logstats] INFO: Crawled 3248 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 18:10:39 [scrapy.extensions.logstats] INFO: Crawled 3250 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 18:11:56 [scrapy.extensions.logstats] INFO: Crawled 3252 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 18:13:08 [scrapy.extensions.logstats] INFO: Crawled 3254 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 18:14:22 [scrapy.extensions.logstats] INFO: Crawled 3256 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 18:15:24 [scrapy.extensions.logstats] INFO: Crawled 3258 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 18:16:37 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cramco.net/aboutus.aspx>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.cramco.net/aboutus.aspx took longer than 15.0 seconds..
2019-11-10 18:16:37 [scrapy.extensions.logstats] INFO: Crawled 3260 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 18:17:49 [scrapy.extensions.logstats] INFO: Crawled 3260 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 18:18:59 [scrapy.extensions.logstats] INFO: Crawled 3260 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 18:19:34 [scrapy.extensions.logstats] INFO: Crawled 3263 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 18:20:46 [scrapy.extensions.logstats] INFO: Crawled 3266 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 18:21:19 [scrapy.extensions.logstats] INFO: Crawled 3269 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 18:22:30 [scrapy.extensions.logstats] INFO: Crawled 3272 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 18:24:12 [scrapy.extensions.logstats] INFO: Crawled 3275 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 18:25:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cramco.net/ProductListing.aspx?CatId=f7fadd94-4064-4aff-8a4e-33ad9767f772>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.cramco.net/ProductListing.aspx?CatId=f7fadd94-4064-4aff-8a4e-33ad9767f772 took longer than 15.0 seconds..
2019-11-10 18:25:59 [scrapy.extensions.logstats] INFO: Crawled 3275 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 18:27:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cramco.net/dealerlocator.aspx>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.cramco.net/dealerlocator.aspx took longer than 15.0 seconds..
2019-11-10 18:27:39 [scrapy.extensions.logstats] INFO: Crawled 3275 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 18:27:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cramco.net/contactus.aspx>: User timeout caused connection failure.
2019-11-10 18:28:16 [scrapy.extensions.logstats] INFO: Crawled 3278 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 18:28:51 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cramco.net/ProductListing.aspx?CatId=9f7dc94c-9e1b-48d9-a13a-a743df6dd5a3>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.cramco.net/ProductListing.aspx?CatId=9f7dc94c-9e1b-48d9-a13a-a743df6dd5a3 took longer than 15.0 seconds..
2019-11-10 18:29:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cramco.net/ProductListing.aspx?CatId=ec4a43a7-eafb-40cc-87a2-84e30db368eb>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.cramco.net/ProductListing.aspx?CatId=ec4a43a7-eafb-40cc-87a2-84e30db368eb took longer than 15.0 seconds..
2019-11-10 18:29:27 [scrapy.extensions.logstats] INFO: Crawled 3281 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 18:31:01 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cramco.net/ProductListing.aspx?CatId=fcb2d82a-e2e0-4b65-acad-c85e45455e6c>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.cramco.net/ProductListing.aspx?CatId=fcb2d82a-e2e0-4b65-acad-c85e45455e6c took longer than 15.0 seconds..
2019-11-10 18:31:01 [scrapy.extensions.logstats] INFO: Crawled 3281 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 18:31:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cramco.net/ProductListing.aspx?CatId=f5ccb6ae-fde4-4479-acef-a761ccffec4c>: User timeout caused connection failure.
2019-11-10 18:31:26 [scrapy.extensions.logstats] INFO: Crawled 3284 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 18:32:16 [scrapy.extensions.logstats] INFO: Crawled 3290 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 18:34:09 [scrapy.extensions.logstats] INFO: Crawled 3293 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 18:36:03 [scrapy.extensions.logstats] INFO: Crawled 3296 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 18:37:26 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.cramco.net/salesteam.aspx>: User timeout caused connection failure.
2019-11-10 18:37:26 [scrapy.core.scraper] ERROR: Error downloading <GET http://cyanotech.com/meet>: User timeout caused connection failure.
2019-11-10 18:37:26 [scrapy.extensions.logstats] INFO: Crawled 3296 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 18:38:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.crosman.com/catalog/product_compare/add/product/8157/uenc/aHR0cHM6Ly93d3cuY3Jvc21hbi5jb20vYXJjaGVyeS9jZW50ZXJwb2ludC1jcm9zc2Jvd3M,/form_key/DDkKaMWP2DBmn2HL/>: User timeout caused connection failure.
2019-11-10 18:38:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/all-sec-filings/content/0001101396-12-000015/dla-03312012x10q.htm>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/all-sec-filings/content/0001101396-12-000015/dla-03312012x10q.htm took longer than 15.0 seconds..
2019-11-10 18:38:39 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.conferplastics.com/product/restor-a-spa-kit/>: User timeout caused connection failure.
2019-11-10 18:38:40 [scrapy.extensions.logstats] INFO: Crawled 3296 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 18:38:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.crosman.com/archery/centerpoint-crossbows/mercenary-370>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.crosman.com/archery/centerpoint-crossbows/mercenary-370 took longer than 15.0 seconds..
2019-11-10 18:38:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/press-releases/detail/74/>: User timeout caused connection failure.
2019-11-10 18:39:28 [scrapy.extensions.logstats] INFO: Crawled 3304 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 18:40:16 [scrapy.core.scraper] ERROR: Error downloading <GET http://ir.deckers.com/News>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://ir.deckers.com/News took longer than 15.0 seconds..
2019-11-10 18:40:16 [scrapy.extensions.logstats] INFO: Crawled 3304 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 18:41:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.crosman.com/archery/centerpoint-crossbows>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.crosman.com/archery/centerpoint-crossbows took longer than 15.0 seconds..
2019-11-10 18:41:52 [scrapy.extensions.logstats] INFO: Crawled 3304 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 18:42:17 [scrapy.extensions.logstats] INFO: Crawled 3309 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 18:43:54 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.conferplastics.com/patio-and-spa-essentials/spa-essentials/lass36-g-b/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.conferplastics.com/patio-and-spa-essentials/spa-essentials/lass36-g-b/ took longer than 15.0 seconds..
2019-11-10 18:43:54 [scrapy.extensions.logstats] INFO: Crawled 3314 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 18:46:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.crosman.com/archery/centerpoint-crossbows>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.crosman.com/archery/centerpoint-crossbows took longer than 15.0 seconds..
2019-11-10 18:46:22 [scrapy.extensions.logstats] INFO: Crawled 3314 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 18:47:29 [scrapy.extensions.logstats] INFO: Crawled 3320 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 18:48:42 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.conferplastics.com/patio-and-spa-essentials/spa-essentials/lass36-sc-r-b/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.conferplastics.com/patio-and-spa-essentials/spa-essentials/lass36-sc-r-b/ took longer than 15.0 seconds..
2019-11-10 18:48:42 [scrapy.extensions.logstats] INFO: Crawled 3326 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 18:50:09 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/warranty/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/warranty/ took longer than 15.0 seconds..
2019-11-10 18:50:09 [scrapy.extensions.logstats] INFO: Crawled 3328 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 18:51:54 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/tag/women-start-ups/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/tag/women-start-ups/ took longer than 15.0 seconds..
2019-11-10 18:51:54 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.conferplastics.com/patio-and-spa-essentials/spa-essentials/hs2-dg/>: User timeout caused connection failure.
2019-11-10 18:51:54 [scrapy.extensions.logstats] INFO: Crawled 3328 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 18:53:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/tag/winter/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/tag/winter/ took longer than 15.0 seconds..
2019-11-10 18:53:03 [scrapy.extensions.logstats] INFO: Crawled 3328 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 18:53:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.conferplastics.com/patio-and-spa-essentials/spa-essentials/espresso-handistep/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.conferplastics.com/patio-and-spa-essentials/spa-essentials/espresso-handistep/ took longer than 15.0 seconds..
2019-11-10 18:53:36 [scrapy.extensions.logstats] INFO: Crawled 3334 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 18:55:39 [scrapy.extensions.logstats] INFO: Crawled 3335 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 18:56:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cyanotech.com/2019/01/09/cyanotech-names-brian-orlopp-as-vp-finance-chief-financial-officer/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.cyanotech.com/2019/01/09/cyanotech-names-brian-orlopp-as-vp-finance-chief-financial-officer/ took longer than 15.0 seconds..
2019-11-10 18:56:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cyanotech.com/2019/01/09/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.cyanotech.com/2019/01/09/ took longer than 15.0 seconds..
2019-11-10 18:56:27 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/tag/wedding/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/tag/wedding/ took longer than 15.0 seconds..
2019-11-10 18:56:27 [scrapy.extensions.logstats] INFO: Crawled 3337 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 18:56:51 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.deckers.com/index.php/culture/values>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.deckers.com/index.php/culture/values took longer than 15.0 seconds..
2019-11-10 18:56:51 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/tag/tips-and-tricks/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/tag/tips-and-tricks/ took longer than 15.0 seconds..
2019-11-10 18:56:51 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.conferplastics.com/patio-and-spa-essentials/spa-essentials/edge-step-website-2/>: User timeout caused connection failure.
2019-11-10 18:56:51 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cyanotech.com/2019/04/03/>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 18:56:51 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/all-sec-filings/xbrl_doc_only/64>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/all-sec-filings/xbrl_doc_only/64 took longer than 15.0 seconds..
2019-11-10 18:56:51 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.deckers.com/index.php/brands>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.deckers.com/index.php/brands took longer than 15.0 seconds..
2019-11-10 18:56:51 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/communities/maryland/frederick/parkside-at-walkersville/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/communities/maryland/frederick/parkside-at-walkersville/ took longer than 15.0 seconds..
2019-11-10 18:57:15 [scrapy.extensions.logstats] INFO: Crawled 3343 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 18:57:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curtissmotorcycles.com/zeus-technical>: User timeout caused connection failure.
2019-11-10 18:58:52 [scrapy.core.scraper] ERROR: Error downloading <GET http://investors.coopertire.com/file/Index?KeyFile=400671216>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://investors.coopertire.com/file/Index?KeyFile=400671216 took longer than 15.0 seconds..
2019-11-10 18:58:52 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.danryanbuilders.com/find-your-home/frederick-md-quick-move-in-homes/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.danryanbuilders.com/find-your-home/frederick-md-quick-move-in-homes/ took longer than 15.0 seconds..
2019-11-10 18:58:52 [scrapy.core.scraper] ERROR: Error downloading <GET http://us.coopertire.com/Tires/Winter.aspx>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://us.coopertire.com/Tires/Winter.aspx took longer than 15.0 seconds..
2019-11-10 18:58:52 [scrapy.extensions.logstats] INFO: Crawled 3345 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 18:59:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/all-sec-filings/xbrl_doc_only/173>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/all-sec-filings/xbrl_doc_only/173 took longer than 15.0 seconds..
2019-11-10 18:59:41 [scrapy.core.scraper] ERROR: Error downloading <GET http://investors.coopertire.com/CorporateProfile/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://investors.coopertire.com/CorporateProfile/ took longer than 15.0 seconds..
2019-11-10 18:59:41 [scrapy.core.scraper] ERROR: Error downloading <GET http://frca.coopertire.com/legal/terms-of-service>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://frca.coopertire.com/legal/terms-of-service took longer than 15.0 seconds..
2019-11-10 18:59:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demers-ambulances.com/contact/find-a-dealer/usa/ncemergencyvehicles.com>: User timeout caused connection failure.
2019-11-10 18:59:41 [scrapy.core.scraper] ERROR: Error downloading <GET http://us.coopertire.com/Tires/Sport-Utility.aspx>: User timeout caused connection failure.
2019-11-10 18:59:41 [scrapy.extensions.logstats] INFO: Crawled 3346 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 19:00:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/all-sec-filings/content/0001101396-13-000018/dla_20130330-10q.htm>: User timeout caused connection failure.
2019-11-10 19:00:05 [scrapy.extensions.logstats] INFO: Crawled 3347 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 19:00:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curls.biz/review/17754/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curls.biz/review/17754/ took longer than 15.0 seconds..
2019-11-10 19:00:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curtissmotorcycles.com/hades-technical>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curtissmotorcycles.com/hades-technical took longer than 15.0 seconds..
2019-11-10 19:00:49 [scrapy.core.scraper] ERROR: Error downloading <GET http://us.coopertire.com/Tires/Light-Truck.aspx>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://us.coopertire.com/Tires/Light-Truck.aspx took longer than 15.0 seconds..
2019-11-10 19:00:49 [scrapy.core.scraper] ERROR: Error downloading <GET http://investors.coopertire.com/Contact/Index?KeyGenPage=305221>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://investors.coopertire.com/Contact/Index?KeyGenPage=305221 took longer than 15.0 seconds..
2019-11-10 19:00:49 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/tag/sun-tan/>: User timeout caused connection failure.
2019-11-10 19:00:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/press-releases/detail/43/>: User timeout caused connection failure.
2019-11-10 19:00:49 [scrapy.core.scraper] ERROR: Error downloading <GET http://investors.coopertire.com/Board-of-Directors>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://investors.coopertire.com/Board-of-Directors took longer than 15.0 seconds..
2019-11-10 19:00:49 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.curls.biz/store/curlie-cutie-cleansing-Cream/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.curls.biz/store/curlie-cutie-cleansing-Cream/ took longer than 15.0 seconds..
2019-11-10 19:00:49 [scrapy.core.scraper] ERROR: Error downloading <GET http://us.coopertire.com/Tires/Passenger.aspx>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://us.coopertire.com/Tires/Passenger.aspx took longer than 15.0 seconds..
2019-11-10 19:00:49 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/tag/summerskin/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/tag/summerskin/ took longer than 15.0 seconds..
2019-11-10 19:00:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cyanotech.com/public-filings/investor-news/page/2/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.cyanotech.com/public-filings/investor-news/page/2/ took longer than 15.0 seconds..
2019-11-10 19:00:49 [scrapy.core.scraper] ERROR: Error downloading <GET http://frca.coopertire.com/tires/view-tires/suvs-cuvs>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://frca.coopertire.com/tires/view-tires/suvs-cuvs took longer than 15.0 seconds..
2019-11-10 19:00:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demers-ambulances.com/contact/find-a-dealer/international/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demers-ambulances.com/contact/find-a-dealer/international/ took longer than 15.0 seconds..
2019-11-10 19:00:49 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.crosman.com/airguns/air-rifles?powerplant=21>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.crosman.com/airguns/air-rifles?powerplant=21 took longer than 15.0 seconds..
2019-11-10 19:00:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://support.crosman.com/hc/en-us/articles/203904450-What-s-the-deal-with-your-shipping-policy->
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://support.crosman.com/hc/en-us/articles/203904450-What-s-the-deal-with-your-shipping-policy- took longer than 15.0 seconds..
2019-11-10 19:01:17 [scrapy.extensions.logstats] INFO: Crawled 3355 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 19:02:36 [scrapy.core.scraper] ERROR: Error downloading <GET http://us.coopertire.com/Tires/Performance.aspx>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://us.coopertire.com/Tires/Performance.aspx took longer than 15.0 seconds..
2019-11-10 19:02:36 [scrapy.extensions.logstats] INFO: Crawled 3360 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 19:04:12 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/tag/smooth-skin/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/tag/smooth-skin/ took longer than 15.0 seconds..
2019-11-10 19:04:12 [scrapy.core.scraper] ERROR: Error downloading <GET http://us.coopertire.com/legal/terms-of-service>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://us.coopertire.com/legal/terms-of-service took longer than 15.0 seconds..
2019-11-10 19:04:12 [scrapy.core.scraper] ERROR: Error downloading <GET http://coopertire.com/Utility/Supplier-Network.aspx>: User timeout caused connection failure.
2019-11-10 19:04:12 [scrapy.extensions.logstats] INFO: Crawled 3360 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 19:06:13 [scrapy.core.scraper] ERROR: Error downloading <GET http://investors.coopertire.com/Insider-Filings>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://investors.coopertire.com/Insider-Filings took longer than 15.0 seconds..
2019-11-10 19:06:13 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/tag/skincare/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/tag/skincare/ took longer than 15.0 seconds..
2019-11-10 19:06:13 [scrapy.extensions.logstats] INFO: Crawled 3362 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 19:06:39 [scrapy.core.scraper] ERROR: Error downloading <GET http://frca.coopertire.com/tires/view-tires?vehicleType=car>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://frca.coopertire.com/tires/view-tires?vehicleType=car took longer than 15.0 seconds..
2019-11-10 19:07:23 [scrapy.core.scraper] ERROR: Error downloading <GET http://mx.coopertire.com/Tires/Sport-Utility.aspx>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://mx.coopertire.com/Tires/Sport-Utility.aspx took longer than 15.0 seconds..
2019-11-10 19:07:23 [scrapy.core.scraper] ERROR: Error downloading <GET http://us.coopertire.com/where-to-start/buying-new-tires.aspx>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://us.coopertire.com/where-to-start/buying-new-tires.aspx took longer than 15.0 seconds..
2019-11-10 19:07:23 [scrapy.core.scraper] ERROR: Error downloading <GET http://coopertire.com/Careers/Total-Rewards.aspx>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://coopertire.com/Careers/Total-Rewards.aspx took longer than 15.0 seconds..
2019-11-10 19:07:23 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/tag/skin/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/tag/skin/ took longer than 15.0 seconds..
2019-11-10 19:07:23 [scrapy.core.scraper] ERROR: Error downloading <GET http://investors.coopertire.com/Annual-Reports/Index?KeyGenPage=304771>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://investors.coopertire.com/Annual-Reports/Index?KeyGenPage=304771 took longer than 15.0 seconds..
2019-11-10 19:07:23 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curls.biz/review/16174/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curls.biz/review/16174/ took longer than 15.0 seconds..
2019-11-10 19:07:23 [scrapy.extensions.logstats] INFO: Crawled 3364 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 19:07:23 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/tag/sheet-mask/>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2019-11-10 19:08:24 [scrapy.core.scraper] ERROR: Error downloading <GET http://frca.coopertire.com/safety/replacement-guide/load-capacity>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://frca.coopertire.com/safety/replacement-guide/load-capacity took longer than 15.0 seconds..
2019-11-10 19:08:24 [scrapy.core.scraper] ERROR: Error downloading <GET http://us.coopertire.com/where-to-start/help-me-choose.aspx>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://us.coopertire.com/where-to-start/help-me-choose.aspx took longer than 15.0 seconds..
2019-11-10 19:08:24 [scrapy.core.scraper] ERROR: Error downloading <GET http://mx.coopertire.com/Tires/Light-Truck.aspx>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://mx.coopertire.com/Tires/Light-Truck.aspx took longer than 15.0 seconds..
2019-11-10 19:08:24 [scrapy.core.scraper] ERROR: Error downloading <GET http://ca.coopertire.com/Tires/Winter.aspx>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://ca.coopertire.com/Tires/Winter.aspx took longer than 15.0 seconds..
2019-11-10 19:08:24 [scrapy.core.scraper] ERROR: Error downloading <GET http://coopertire.com/Careers/Career-Opportunities.aspx>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://coopertire.com/Careers/Career-Opportunities.aspx took longer than 15.0 seconds..
2019-11-10 19:08:24 [scrapy.extensions.logstats] INFO: Crawled 3365 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 19:08:48 [scrapy.core.scraper] ERROR: Error downloading <GET http://frca.coopertire.com/safety/replacement-guide>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://frca.coopertire.com/safety/replacement-guide took longer than 15.0 seconds..
2019-11-10 19:08:48 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/how-to-get-skincare-to-do-its-job-in-the-colder-months/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/how-to-get-skincare-to-do-its-job-in-the-colder-months/ took longer than 15.0 seconds..
2019-11-10 19:08:48 [scrapy.core.scraper] ERROR: Error downloading <GET http://investors.coopertire.com/SEC-Filings>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://investors.coopertire.com/SEC-Filings took longer than 15.0 seconds..
2019-11-10 19:08:48 [scrapy.core.scraper] ERROR: Error downloading <GET http://mx.coopertire.com/Tires/Passenger.aspx>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://mx.coopertire.com/Tires/Passenger.aspx took longer than 15.0 seconds..
2019-11-10 19:08:48 [scrapy.core.scraper] ERROR: Error downloading <GET http://ca.coopertire.com/Tires/Sport-Utility.aspx>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://ca.coopertire.com/Tires/Sport-Utility.aspx took longer than 15.0 seconds..
2019-11-10 19:08:48 [scrapy.core.scraper] ERROR: Error downloading <GET http://us.coopertire.com/html-sitemap>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://us.coopertire.com/html-sitemap took longer than 15.0 seconds..
2019-11-10 19:09:12 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/tag/resetskinforsummer/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/tag/resetskinforsummer/ took longer than 15.0 seconds..
2019-11-10 19:09:12 [scrapy.core.scraper] ERROR: Error downloading <GET http://investors.coopertire.com/Financials>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://investors.coopertire.com/Financials took longer than 15.0 seconds..
2019-11-10 19:09:12 [scrapy.core.scraper] ERROR: Error downloading <GET http://mx.coopertire.com/Tires/Performance.aspx>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://mx.coopertire.com/Tires/Performance.aspx took longer than 15.0 seconds..
2019-11-10 19:09:12 [scrapy.core.scraper] ERROR: Error downloading <GET http://frca.coopertire.com/safety/tips/tire-service-bulletins>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://frca.coopertire.com/safety/tips/tire-service-bulletins took longer than 15.0 seconds..
2019-11-10 19:09:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curls.biz/review/16175/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curls.biz/review/16175/ took longer than 15.0 seconds..
2019-11-10 19:09:12 [scrapy.core.scraper] ERROR: Error downloading <GET http://us.coopertire.com/robots>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://us.coopertire.com/robots took longer than 15.0 seconds..
2019-11-10 19:09:12 [scrapy.core.scraper] ERROR: Error downloading <GET http://ca.coopertire.com/Tires/Light-Truck.aspx>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://ca.coopertire.com/Tires/Light-Truck.aspx took longer than 15.0 seconds..
2019-11-10 19:09:12 [scrapy.extensions.logstats] INFO: Crawled 3368 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 19:10:14 [scrapy.core.scraper] ERROR: Error downloading <GET http://frca.coopertire.com/safety/tips/winter-driving>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://frca.coopertire.com/safety/tips/winter-driving took longer than 15.0 seconds..
2019-11-10 19:10:14 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/tag/press/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/tag/press/ took longer than 15.0 seconds..
2019-11-10 19:10:14 [scrapy.core.scraper] ERROR: Error downloading <GET http://investors.coopertire.com/Events-and-Presentations>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://investors.coopertire.com/Events-and-Presentations took longer than 15.0 seconds..
2019-11-10 19:10:14 [scrapy.core.scraper] ERROR: Error downloading <GET http://ca.coopertire.com/Tires/Passenger.aspx>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://ca.coopertire.com/Tires/Passenger.aspx took longer than 15.0 seconds..
2019-11-10 19:10:14 [scrapy.core.scraper] ERROR: Error downloading <GET http://us.coopertire.com/for-owners/tire-warranty>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://us.coopertire.com/for-owners/tire-warranty took longer than 15.0 seconds..
2019-11-10 19:10:14 [scrapy.core.scraper] ERROR: Error downloading <GET http://es.coopertire.com/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://es.coopertire.com/ took longer than 15.0 seconds..
2019-11-10 19:10:15 [scrapy.extensions.logstats] INFO: Crawled 3370 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 19:11:28 [scrapy.core.scraper] ERROR: Error downloading <GET http://investors.coopertire.com/Investor-Highlights/Index?KeyGenPage=305233>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://investors.coopertire.com/Investor-Highlights/Index?KeyGenPage=305233 took longer than 15.0 seconds..
2019-11-10 19:11:28 [scrapy.core.scraper] ERROR: Error downloading <GET http://ca.coopertire.com/Tires/Performance.aspx>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://ca.coopertire.com/Tires/Performance.aspx took longer than 15.0 seconds..
2019-11-10 19:11:28 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/tag/prep/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/tag/prep/ took longer than 15.0 seconds..
2019-11-10 19:11:28 [scrapy.core.scraper] ERROR: Error downloading <GET http://us.coopertire.com/for-owners/tire-registration>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://us.coopertire.com/for-owners/tire-registration took longer than 15.0 seconds..
2019-11-10 19:11:28 [scrapy.core.scraper] ERROR: Error downloading <GET http://frca.coopertire.com/safety/tips/used-tires>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://frca.coopertire.com/safety/tips/used-tires took longer than 15.0 seconds..
2019-11-10 19:11:28 [scrapy.extensions.logstats] INFO: Crawled 3372 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 19:11:28 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/tag/peach-fuzz/>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2019-11-10 19:12:04 [scrapy.core.scraper] ERROR: Error downloading <GET http://us.coopertire.com/safety/good-driving-habits>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://us.coopertire.com/safety/good-driving-habits took longer than 15.0 seconds..
2019-11-10 19:12:28 [scrapy.core.scraper] ERROR: Error downloading <GET http://investors.coopertire.com/Overview>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://investors.coopertire.com/Overview took longer than 15.0 seconds..
2019-11-10 19:12:28 [scrapy.core.scraper] ERROR: Error downloading <GET http://frca.coopertire.com/safety/tips/tire-alterations>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://frca.coopertire.com/safety/tips/tire-alterations took longer than 15.0 seconds..
2019-11-10 19:12:28 [scrapy.core.scraper] ERROR: Error downloading <GET http://coopertire.com/News.aspx>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://coopertire.com/News.aspx took longer than 15.0 seconds..
2019-11-10 19:12:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curls.biz/curly-hair-type-guide.html>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curls.biz/curly-hair-type-guide.html took longer than 15.0 seconds..
2019-11-10 19:12:28 [scrapy.extensions.logstats] INFO: Crawled 3374 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 19:12:29 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/tag/moisturize/>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2019-11-10 19:13:17 [scrapy.core.scraper] ERROR: Error downloading <GET http://us.coopertire.com/safety/sidewalls/tire-sidewall-information>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://us.coopertire.com/safety/sidewalls/tire-sidewall-information took longer than 15.0 seconds..
2019-11-10 19:13:17 [scrapy.core.scraper] ERROR: Error downloading <GET http://frca.coopertire.com/safety/tips/proper-loading>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://frca.coopertire.com/safety/tips/proper-loading took longer than 15.0 seconds..
2019-11-10 19:13:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curls.biz/curl-enhancing-hair-products-for-women/?rf_selection=>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curls.biz/curl-enhancing-hair-products-for-women/?rf_selection= took longer than 15.0 seconds..
2019-11-10 19:13:17 [scrapy.core.scraper] ERROR: Error downloading <GET http://mx.coopertire.com/Terms-of-Service.aspx>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://mx.coopertire.com/Terms-of-Service.aspx took longer than 15.0 seconds..
2019-11-10 19:13:17 [scrapy.extensions.logstats] INFO: Crawled 3375 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 19:13:17 [scrapy.core.scraper] ERROR: Error downloading <GET http://us.coopertire.com/safety/replacement-guide/vehicle-modification>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://us.coopertire.com/safety/replacement-guide/vehicle-modification took longer than 15.0 seconds..
2019-11-10 19:13:17 [scrapy.core.scraper] ERROR: Error downloading <GET http://frca.coopertire.com/about-us/sponsorships>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://frca.coopertire.com/about-us/sponsorships took longer than 15.0 seconds..
2019-11-10 19:13:17 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/tag/moisture/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/tag/moisture/ took longer than 15.0 seconds..
2019-11-10 19:13:17 [scrapy.core.scraper] ERROR: Error downloading <GET http://mx.coopertire.com/Tires/Light-Truck/Disco-STT-Pro.aspx>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://mx.coopertire.com/Tires/Light-Truck/Disco-STT-Pro.aspx took longer than 15.0 seconds..
2019-11-10 19:13:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curls.biz/add_review.php?productid=16148&cat=118>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curls.biz/add_review.php?productid=16148&cat=118 took longer than 15.0 seconds..
2019-11-10 19:15:01 [scrapy.core.scraper] ERROR: Error downloading <GET http://us.coopertire.com/safety/replacement-guide/approved-rims>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://us.coopertire.com/safety/replacement-guide/approved-rims took longer than 15.0 seconds..
2019-11-10 19:15:01 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/tag/makeup/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/tag/makeup/ took longer than 15.0 seconds..
2019-11-10 19:15:01 [scrapy.core.scraper] ERROR: Error downloading <GET http://frca.coopertire.com/about-us/why-cooper>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://frca.coopertire.com/about-us/why-cooper took longer than 15.0 seconds..
2019-11-10 19:15:01 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=16148>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=16148 took longer than 15.0 seconds..
2019-11-10 19:15:01 [scrapy.core.scraper] ERROR: Error downloading <GET http://mx.coopertire.com/Tires/Performance/Cooper-Zeon-RS3-G1.aspx>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://mx.coopertire.com/Tires/Performance/Cooper-Zeon-RS3-G1.aspx took longer than 15.0 seconds..
2019-11-10 19:15:01 [scrapy.extensions.logstats] INFO: Crawled 3378 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 19:15:37 [scrapy.core.scraper] ERROR: Error downloading <GET http://us.coopertire.com/safety/replacement-guide/load-capacity>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://us.coopertire.com/safety/replacement-guide/load-capacity took longer than 15.0 seconds..
2019-11-10 19:15:37 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/tag/lotion/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/tag/lotion/ took longer than 15.0 seconds..
2019-11-10 19:15:37 [scrapy.core.scraper] ERROR: Error downloading <GET http://frca.coopertire.com/where-to-start/buying-new-tires>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://frca.coopertire.com/where-to-start/buying-new-tires took longer than 15.0 seconds..
2019-11-10 19:15:37 [scrapy.core.scraper] ERROR: Error downloading <GET http://mx.coopertire.com/Sponsorships>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://mx.coopertire.com/Sponsorships took longer than 15.0 seconds..
2019-11-10 19:15:37 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curls.biz/best-curl-cream.html>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curls.biz/best-curl-cream.html took longer than 15.0 seconds..
2019-11-10 19:15:37 [scrapy.core.scraper] ERROR: Error downloading <GET http://ch.coopertire.com>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: ch.coopertire.com.
2019-11-10 19:15:37 [scrapy.extensions.logstats] INFO: Crawled 3380 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 19:16:46 [scrapy.core.scraper] ERROR: Error downloading <GET http://us.coopertire.com/safety/replacement-guide/tire-service-life>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://us.coopertire.com/safety/replacement-guide/tire-service-life took longer than 15.0 seconds..
2019-11-10 19:16:46 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/tag/living/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/tag/living/ took longer than 15.0 seconds..
2019-11-10 19:16:46 [scrapy.core.scraper] ERROR: Error downloading <GET http://mx.coopertire.com/Customer-Care/Warranty-Information>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://mx.coopertire.com/Customer-Care/Warranty-Information took longer than 15.0 seconds..
2019-11-10 19:16:46 [scrapy.core.scraper] ERROR: Error downloading <GET http://frca.coopertire.com/tires/view-tires.aspx?vehicleType=truck>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://frca.coopertire.com/tires/view-tires.aspx?vehicleType=truck took longer than 15.0 seconds..
2019-11-10 19:16:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curls.biz/add_review.php?productid=16191&cat=118>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curls.biz/add_review.php?productid=16191&cat=118 took longer than 15.0 seconds..
2019-11-10 19:16:46 [scrapy.extensions.logstats] INFO: Crawled 3382 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 19:16:46 [scrapy.core.scraper] ERROR: Error downloading <GET http://us.coopertire.com/safety/tips/winter-driving>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://us.coopertire.com/safety/tips/winter-driving took longer than 15.0 seconds..
2019-11-10 19:16:46 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/tag/infuse/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/tag/infuse/ took longer than 15.0 seconds..
2019-11-10 19:16:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.diamondwipes.com/blogs/news?page=2>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.diamondwipes.com/blogs/news?page=2 took longer than 15.0 seconds..
2019-11-10 19:16:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curls.biz/add_review.php?productid=16190&cat=118>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curls.biz/add_review.php?productid=16190&cat=118 took longer than 15.0 seconds..
2019-11-10 19:16:46 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.dermaflash.com/user-manual.html>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.dermaflash.com/user-manual.html took longer than 15.0 seconds..
2019-11-10 19:17:50 [scrapy.extensions.logstats] INFO: Crawled 3384 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 19:17:50 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/tag/icy-green/>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2019-11-10 19:19:01 [scrapy.core.scraper] ERROR: Error downloading <GET http://us.coopertire.com/safety/tips/proper-tire-repair>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://us.coopertire.com/safety/tips/proper-tire-repair took longer than 15.0 seconds..
2019-11-10 19:19:01 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.diamondwipes.com/blogs/news/diamond-wipes-is-returning-to-natural-products-expo-west-in-march>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.diamondwipes.com/blogs/news/diamond-wipes-is-returning-to-natural-products-expo-west-in-march took longer than 15.0 seconds..
2019-11-10 19:19:01 [scrapy.core.scraper] ERROR: Error downloading <GET http://mx.coopertire.com/Customer-Care/Dealer-Locator>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://mx.coopertire.com/Customer-Care/Dealer-Locator took longer than 15.0 seconds..
2019-11-10 19:19:01 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.deltaapparelinc.com/news-media/events/detail/2549/b-riley-fbr-annual-investor-conference>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.deltaapparelinc.com/news-media/events/detail/2549/b-riley-fbr-annual-investor-conference took longer than 15.0 seconds..
2019-11-10 19:19:01 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=16190>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=16190 took longer than 15.0 seconds..
2019-11-10 19:19:01 [scrapy.core.scraper] ERROR: Error downloading <GET http://wwww.dermaflash.com/privacy-policy.html>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\endpoints.py", line 954, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: wwww.dermaflash.com.
2019-11-10 19:19:01 [scrapy.extensions.logstats] INFO: Crawled 3385 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 19:19:01 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/tag/ice-queen/>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2019-11-10 19:19:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.deltaapparelinc.com/news-media/events/detail/2551/fy19-q3-earnings-call>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.deltaapparelinc.com/news-media/events/detail/2551/fy19-q3-earnings-call took longer than 15.0 seconds..
2019-11-10 19:19:25 [scrapy.core.scraper] ERROR: Error downloading <GET http://us.coopertire.com/safety/tips/wheel-alignment>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://us.coopertire.com/safety/tips/wheel-alignment took longer than 15.0 seconds..
2019-11-10 19:19:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curls.biz/Sea-Kelp-Curl-Cleanser.html>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curls.biz/Sea-Kelp-Curl-Cleanser.html took longer than 15.0 seconds..
2019-11-10 19:19:25 [scrapy.extensions.logstats] INFO: Crawled 3386 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 19:19:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.diamondwipes.com/blogs/news/hero-wipes-fire-wins-2018-world-of-wipes-innovation-award>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 19:19:25 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/tag/healthy/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/tag/healthy/ took longer than 15.0 seconds..
2019-11-10 19:19:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.deltaapparelinc.com/news-media/events/detail/2554/fy19-q4-and-year-end-earnings-call>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.deltaapparelinc.com/news-media/events/detail/2554/fy19-q4-and-year-end-earnings-call took longer than 15.0 seconds..
2019-11-10 19:19:25 [scrapy.core.scraper] ERROR: Error downloading <GET http://mx.coopertire.com/Tires/Performance>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://mx.coopertire.com/Tires/Performance took longer than 15.0 seconds..
2019-11-10 19:19:25 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.dermaflash.com/order>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.dermaflash.com/order took longer than 15.0 seconds..
2019-11-10 19:19:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.deltachildren.com/pages/product-label-information>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.deltachildren.com/pages/product-label-information took longer than 15.0 seconds..
2019-11-10 19:19:25 [scrapy.core.scraper] ERROR: Error downloading <GET http://us.coopertire.com/safety/tips/proper-tire-inflation>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://us.coopertire.com/safety/tips/proper-tire-inflation took longer than 15.0 seconds..
2019-11-10 19:19:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curls.biz/best-clarifying-shampoo.html>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curls.biz/best-clarifying-shampoo.html took longer than 15.0 seconds..
2019-11-10 19:22:34 [scrapy.extensions.logstats] INFO: Crawled 3401 pages (at 15 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 19:25:01 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.deltachildren.com/products/disney-princess-carriage-toddler-to-twin-bed>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.deltachildren.com/products/disney-princess-carriage-toddler-to-twin-bed took longer than 15.0 seconds..
2019-11-10 19:25:01 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.dermaflash.com/faqs.html>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.dermaflash.com/faqs.html took longer than 15.0 seconds..
2019-11-10 19:25:01 [scrapy.core.scraper] ERROR: Error downloading <GET http://us.coopertire.com/where-to-start/tires-matter>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://us.coopertire.com/where-to-start/tires-matter took longer than 15.0 seconds..
2019-11-10 19:25:01 [scrapy.extensions.logstats] INFO: Crawled 3401 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 19:26:37 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/tag/halloween-ispo/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/tag/halloween-ispo/ took longer than 15.0 seconds..
2019-11-10 19:26:37 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.deltachildren.com/collections/bassinets/products/smooth-glide-bassinet>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.deltachildren.com/collections/bassinets/products/smooth-glide-bassinet took longer than 15.0 seconds..
2019-11-10 19:26:37 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.crosman.com/airguns>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.crosman.com/airguns took longer than 15.0 seconds..
2019-11-10 19:26:37 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=17755>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=17755 took longer than 15.0 seconds..
2019-11-10 19:26:37 [scrapy.extensions.logstats] INFO: Crawled 3401 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 19:26:37 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/tag/facial/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/tag/facial/ took longer than 15.0 seconds..
2019-11-10 19:27:24 [scrapy.extensions.logstats] INFO: Crawled 3408 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 19:27:49 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/tag/face-mask/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/tag/face-mask/ took longer than 15.0 seconds..
2019-11-10 19:29:22 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/tag/extract/>: User timeout caused connection failure.
2019-11-10 19:29:22 [scrapy.extensions.logstats] INFO: Crawled 3413 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 19:31:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/all-sec-filings/content/0001101396-13-000025/dla_20130629-10k.htm>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/all-sec-filings/content/0001101396-13-000025/dla_20130629-10k.htm took longer than 15.0 seconds..
2019-11-10 19:31:06 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/tag/exfoliation/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/tag/exfoliation/ took longer than 15.0 seconds..
2019-11-10 19:31:06 [scrapy.core.scraper] ERROR: Error downloading <GET http://us.coopertire.com/where-to-start/tire-maintenance>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://us.coopertire.com/where-to-start/tire-maintenance took longer than 15.0 seconds..
2019-11-10 19:31:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.crosman.com/contact>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.crosman.com/contact took longer than 15.0 seconds..
2019-11-10 19:31:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curls.biz/add_review.php?productid=17753&cat=118>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curls.biz/add_review.php?productid=17753&cat=118 took longer than 15.0 seconds..
2019-11-10 19:31:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.deltachildren.com/collections/avengers>: User timeout caused connection failure.
2019-11-10 19:31:06 [scrapy.extensions.logstats] INFO: Crawled 3413 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 19:31:55 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/tag/exfoliate/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/tag/exfoliate/ took longer than 15.0 seconds..
2019-11-10 19:31:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/press-releases/detail/105/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/press-releases/detail/105/ took longer than 15.0 seconds..
2019-11-10 19:31:55 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.dermaflash.com/how-to-use.html>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.dermaflash.com/how-to-use.html took longer than 15.0 seconds..
2019-11-10 19:31:55 [scrapy.core.scraper] ERROR: Error downloading <GET http://us.coopertire.com/tires/promotions>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://us.coopertire.com/tires/promotions took longer than 15.0 seconds..
2019-11-10 19:31:55 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.crosman.com/connect>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.crosman.com/connect took longer than 15.0 seconds..
2019-11-10 19:31:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.deltachildren.com/collections/teenage-mutant-ninja-turtles>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.deltachildren.com/collections/teenage-mutant-ninja-turtles took longer than 15.0 seconds..
2019-11-10 19:31:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.coty.com/join-us/how-we-work/sophie-jouanneau>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.coty.com/join-us/how-we-work/sophie-jouanneau took longer than 15.0 seconds..
2019-11-10 19:31:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=17753>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curls.biz/get_block.php?block=acr_get_product_ratings&productid=17753 took longer than 15.0 seconds..
2019-11-10 19:31:55 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/tag/dry-skin/>: User timeout caused connection failure.
2019-11-10 19:31:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/press-releases/detail/105>: User timeout caused connection failure.
2019-11-10 19:32:19 [scrapy.extensions.logstats] INFO: Crawled 3418 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 19:32:43 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/tag/dermapore/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/tag/dermapore/ took longer than 15.0 seconds..
2019-11-10 19:34:36 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/tag/dermaplaning/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/tag/dermaplaning/ took longer than 15.0 seconds..
2019-11-10 19:34:36 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.dermaflash.com/order/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.dermaflash.com/order/ took longer than 15.0 seconds..
2019-11-10 19:34:36 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/all-sec-filings/content/0001101396-13-000032/dla_20130928-10q.htm>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/all-sec-filings/content/0001101396-13-000032/dla_20130928-10q.htm took longer than 15.0 seconds..
2019-11-10 19:34:36 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.deltaapparelinc.com/news-media/events/detail/2193/24th-annual-roth-conference>: User timeout caused connection failure.
2019-11-10 19:34:36 [scrapy.extensions.logstats] INFO: Crawled 3421 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 19:36:38 [scrapy.core.scraper] ERROR: Error downloading <GET http://us.coopertire.com/tires/view-tires.aspx?vehicleType=car>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://us.coopertire.com/tires/view-tires.aspx?vehicleType=car took longer than 15.0 seconds..
2019-11-10 19:36:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curls.biz/add_review.php?productid=17799&cat=118>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curls.biz/add_review.php?productid=17799&cat=118 took longer than 15.0 seconds..
2019-11-10 19:36:38 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/tag/dermaplane/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/tag/dermaplane/ took longer than 15.0 seconds..
2019-11-10 19:36:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.crosman.com/discover/airguns>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.crosman.com/discover/airguns took longer than 15.0 seconds..
2019-11-10 19:36:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/press-releases/detail/107/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/press-releases/detail/107/ took longer than 15.0 seconds..
2019-11-10 19:36:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.dermaflash.com/shopallproducts/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.dermaflash.com/shopallproducts/ took longer than 15.0 seconds..
2019-11-10 19:36:38 [scrapy.extensions.logstats] INFO: Crawled 3421 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 19:36:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.deltachildren.com/collections/twin-beds/products/princess-madeline-twin-bed>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.deltachildren.com/collections/twin-beds/products/princess-madeline-twin-bed took longer than 15.0 seconds..
2019-11-10 19:36:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.coty.com/in-the-news/press-release/marv-and-coty-inc-announce-new-fragrance-agreement>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.coty.com/in-the-news/press-release/marv-and-coty-inc-announce-new-fragrance-agreement took longer than 15.0 seconds..
2019-11-10 19:36:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.deltaapparelinc.com/news-media/events/detail/2194/fy12-q3-earnings-call>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.deltaapparelinc.com/news-media/events/detail/2194/fy12-q3-earnings-call took longer than 15.0 seconds..
2019-11-10 19:36:38 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/tag/dermaflash/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/tag/dermaflash/ took longer than 15.0 seconds..
2019-11-10 19:36:38 [scrapy.core.scraper] ERROR: Error downloading <GET http://us.coopertire.com/tires/view-tires?viewalltire=all>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://us.coopertire.com/tires/view-tires?viewalltire=all took longer than 15.0 seconds..
2019-11-10 19:36:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/board-of-directors>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/board-of-directors took longer than 15.0 seconds..
2019-11-10 19:37:17 [scrapy.extensions.logstats] INFO: Crawled 3429 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 19:39:05 [scrapy.extensions.logstats] INFO: Crawled 3433 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 19:41:28 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/tag/cold-weather/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/tag/cold-weather/ took longer than 15.0 seconds..
2019-11-10 19:41:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/ir-calendar>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/ir-calendar took longer than 15.0 seconds..
2019-11-10 19:41:28 [scrapy.extensions.logstats] INFO: Crawled 3433 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 19:43:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/press-releases>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/press-releases took longer than 15.0 seconds..
2019-11-10 19:43:47 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/tag/cold/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/tag/cold/ took longer than 15.0 seconds..
2019-11-10 19:43:47 [scrapy.extensions.logstats] INFO: Crawled 3434 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 19:44:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/washington-west-division-drb-group/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/washington-west-division-drb-group/ took longer than 15.0 seconds..
2019-11-10 19:44:25 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/tag/clown/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/tag/clown/ took longer than 15.0 seconds..
2019-11-10 19:44:25 [scrapy.core.scraper] ERROR: Error downloading <GET http://ir.deltaapparelinc.com/news/detail/300/delta-apparel-updates-preliminary-fourth-quarter-and-full-year-results>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://ir.deltaapparelinc.com/news/detail/300/delta-apparel-updates-preliminary-fourth-quarter-and-full-year-results took longer than 15.0 seconds..
2019-11-10 19:44:25 [scrapy.extensions.logstats] INFO: Crawled 3435 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 19:44:56 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/tag/beauty-staples/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/tag/beauty-staples/ took longer than 15.0 seconds..
2019-11-10 19:44:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/disclaimers/rale-pipersgrove/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/disclaimers/rale-pipersgrove/ took longer than 15.0 seconds..
2019-11-10 19:44:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/rss>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/rss took longer than 15.0 seconds..
2019-11-10 19:44:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curls.biz/Denman-Classic-Brush-p-428.html>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curls.biz/Denman-Classic-Brush-p-428.html took longer than 15.0 seconds..
2019-11-10 19:45:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/tag/beauty/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/tag/beauty/ took longer than 15.0 seconds..
2019-11-10 19:45:20 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/disclaimers/pitt-maplegrove/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/disclaimers/pitt-maplegrove/ took longer than 15.0 seconds..
2019-11-10 19:45:20 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/press-releases/detail/107>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/press-releases/detail/107 took longer than 15.0 seconds..
2019-11-10 19:45:20 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curls.biz/redirect.php?bannerid=11&imageid=60>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curls.biz/redirect.php?bannerid=11&imageid=60 took longer than 15.0 seconds..
2019-11-10 19:45:21 [scrapy.extensions.logstats] INFO: Crawled 3437 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 19:45:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://curtisindustries.net/club-car-utv-cabs/>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 19:45:44 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/category/skincare/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/category/skincare/ took longer than 15.0 seconds..
2019-11-10 19:45:44 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/disclaimers/char-grabngo/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/disclaimers/char-grabngo/ took longer than 15.0 seconds..
2019-11-10 19:45:44 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/all-sec-filings/xbrl_doc_only/374>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/all-sec-filings/xbrl_doc_only/374 took longer than 15.0 seconds..
2019-11-10 19:46:09 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/category/press-releases/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/category/press-releases/ took longer than 15.0 seconds..
2019-11-10 19:46:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/all-sec-filings/content/0001101396-14-000014/dla_20140329-10q.htm>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/all-sec-filings/content/0001101396-14-000014/dla_20140329-10q.htm took longer than 15.0 seconds..
2019-11-10 19:46:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/wv-panhandle/stonebrook-village/york-ii-garage/1666277/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/wv-panhandle/stonebrook-village/york-ii-garage/1666277/ took longer than 15.0 seconds..
2019-11-10 19:46:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.curls.biz/home.php>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.curls.biz/home.php took longer than 15.0 seconds..
2019-11-10 19:46:09 [scrapy.extensions.logstats] INFO: Crawled 3439 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 19:46:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/press-releases/detail/113>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/press-releases/detail/113 took longer than 15.0 seconds..
2019-11-10 19:46:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/wv-panhandle/overlook-at-riverside-townhomes/litchfield-ii/1667087/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/wv-panhandle/overlook-at-riverside-townhomes/litchfield-ii/1667087/ took longer than 15.0 seconds..
2019-11-10 19:46:39 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/category/media-placements/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/category/media-placements/ took longer than 15.0 seconds..
2019-11-10 19:46:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://curtisindustries.net/polaris-utv-cabs/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://curtisindustries.net/polaris-utv-cabs/ took longer than 15.0 seconds..
2019-11-10 19:46:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://curtisindustries.net/yamaha-utv-cabs/>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 19:46:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/all-sec-filings/content/0001101396-14-000032/dla_20140927-10k.htm>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/all-sec-filings/content/0001101396-14-000032/dla_20140927-10k.htm took longer than 15.0 seconds..
2019-11-10 19:46:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/wv-panhandle/overlook-at-riverside-townhomes/litchfield-ii/1667082/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/wv-panhandle/overlook-at-riverside-townhomes/litchfield-ii/1667082/ took longer than 15.0 seconds..
2019-11-10 19:46:39 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/blog/page/15/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/blog/page/15/ took longer than 15.0 seconds..
2019-11-10 19:46:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://investors.coty.com>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://investors.coty.com took longer than 15.0 seconds..
2019-11-10 19:47:13 [scrapy.extensions.logstats] INFO: Crawled 3441 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 19:47:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://curtisindustries.net/yanmar-utv-cabs/>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 19:47:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/wv-panhandle/overlook-at-riverside-townhomes/bedford-ii/1667079/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/wv-panhandle/overlook-at-riverside-townhomes/bedford-ii/1667079/ took longer than 15.0 seconds..
2019-11-10 19:47:52 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/blog/page/4/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/blog/page/4/ took longer than 15.0 seconds..
2019-11-10 19:47:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/press-releases/detail/121/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/press-releases/detail/121/ took longer than 15.0 seconds..
2019-11-10 19:47:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://curtisindustries.net/product-pages/utility-vehicle-cabs/%7B%7B%20x.link%20%7D%7D>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 19:48:16 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/blog/page/3/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/blog/page/3/ took longer than 15.0 seconds..
2019-11-10 19:48:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/press-releases/detail/121>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/press-releases/detail/121 took longer than 15.0 seconds..
2019-11-10 19:48:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/wv-panhandle/overlook-at-riverside-townhomes/deep-creek-ii/1667074/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/wv-panhandle/overlook-at-riverside-townhomes/deep-creek-ii/1667074/ took longer than 15.0 seconds..
2019-11-10 19:48:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://investors.coty.com/investor-resources/rss-feeds/default.aspx>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://investors.coty.com/investor-resources/rss-feeds/default.aspx took longer than 15.0 seconds..
2019-11-10 19:48:16 [scrapy.extensions.logstats] INFO: Crawled 3443 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 19:48:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://curtisindustries.net/product-pages/utility-vehicle-cabs/tel:5088532200>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 19:48:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/wv-panhandle/overlook-at-riverside-single-family-homes/whitehall/1666449/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/wv-panhandle/overlook-at-riverside-single-family-homes/whitehall/1666449/ took longer than 15.0 seconds..
2019-11-10 19:48:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/press-releases/detail/142/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/press-releases/detail/142/ took longer than 15.0 seconds..
2019-11-10 19:48:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://investors.coty.com/investor-resources/emails-alerts/default.aspx>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://investors.coty.com/investor-resources/emails-alerts/default.aspx took longer than 15.0 seconds..
2019-11-10 19:48:17 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/craft-the-perfect-spa-day-at-home-with-dermaflash/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/craft-the-perfect-spa-day-at-home-with-dermaflash/ took longer than 15.0 seconds..
2019-11-10 19:48:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.deltaapparelinc.com/investors/corporate-governance/board-committees>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.deltaapparelinc.com/investors/corporate-governance/board-committees took longer than 15.0 seconds..
2019-11-10 19:48:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.coty.com/our-story/coty-leader>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.coty.com/our-story/coty-leader took longer than 15.0 seconds..
2019-11-10 19:48:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://investors.coty.com/investor-resources/registered-shareholder-information/default.aspx>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://investors.coty.com/investor-resources/registered-shareholder-information/default.aspx took longer than 15.0 seconds..
2019-11-10 19:48:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/press-releases/detail/142>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/press-releases/detail/142 took longer than 15.0 seconds..
2019-11-10 19:48:41 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/female-start-ups-we-admire/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/female-start-ups-we-admire/ took longer than 15.0 seconds..
2019-11-10 19:48:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/wv-panhandle/mccauley-crossing-towns/litchfield-ii/1712087/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/wv-panhandle/mccauley-crossing-towns/litchfield-ii/1712087/ took longer than 15.0 seconds..
2019-11-10 19:48:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.deltaapparelinc.com/investors/financial-information/financial-results>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.deltaapparelinc.com/investors/financial-information/financial-results took longer than 15.0 seconds..
2019-11-10 19:48:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://curtisindustries.net/product-pages/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://curtisindustries.net/product-pages/ took longer than 15.0 seconds..
2019-11-10 19:48:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.coty.com/privacy-policy>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.coty.com/privacy-policy took longer than 15.0 seconds..
2019-11-10 19:49:05 [scrapy.extensions.logstats] INFO: Crawled 3445 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 19:49:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/all-sec-filings/xbrl_doc_only/917>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/all-sec-filings/xbrl_doc_only/917 took longer than 15.0 seconds..
2019-11-10 19:49:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://investors.coty.com/investor-resources/investor-contacts/default.aspx>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://investors.coty.com/investor-resources/investor-contacts/default.aspx took longer than 15.0 seconds..
2019-11-10 19:49:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.deltaapparelinc.com/investors/financial-information/cash-flow>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.deltaapparelinc.com/investors/financial-information/cash-flow took longer than 15.0 seconds..
2019-11-10 19:49:05 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/wp-admin/admin-ajax.php?action=process_simple_like&post_id=23288&nonce=df3eef113a&is_comment=0&disabled=true>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/wp-admin/admin-ajax.php?action=process_simple_like&post_id=23288&nonce=df3eef113a&is_comment=0&disabled=true took longer than 15.0 seconds..
2019-11-10 19:49:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demarini.com/en-us/bats/baseball-bats?bat_model_year=6589>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demarini.com/en-us/bats/baseball-bats?bat_model_year=6589 took longer than 15.0 seconds..
2019-11-10 19:49:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/frederick-hagerstown/rosewood-village/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/frederick-hagerstown/rosewood-village/ took longer than 15.0 seconds..
2019-11-10 19:49:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://curtisindustries.net/product-pages/accessories/%7B%7B%20x.link%20%7D%7D>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://curtisindustries.net/product-pages/accessories/%7B%7B%20x.link%20%7D%7D took longer than 15.0 seconds..
2019-11-10 19:49:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.coty.com/faqs>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.coty.com/faqs took longer than 15.0 seconds..
2019-11-10 19:49:43 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/all-sec-filings/content/0001101396-16-000090/dla_20160702-10q.htm>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/all-sec-filings/content/0001101396-16-000090/dla_20160702-10q.htm took longer than 15.0 seconds..
2019-11-10 19:49:43 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/why-dermaflash-is-the-holy-grail-product-you-cant-live-without/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/why-dermaflash-is-the-holy-grail-product-you-cant-live-without/ took longer than 15.0 seconds..
2019-11-10 19:49:43 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.deltaapparelinc.com/investors/financial-information/income-statement>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.deltaapparelinc.com/investors/financial-information/income-statement took longer than 15.0 seconds..
2019-11-10 19:49:43 [scrapy.core.scraper] ERROR: Error downloading <GET https://investors.coty.com/news-events-and-presentations/events-and-presentations/default.aspx>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://investors.coty.com/news-events-and-presentations/events-and-presentations/default.aspx took longer than 15.0 seconds..
2019-11-10 19:49:43 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/frederick-hagerstown/parkside-at-walkersville/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/frederick-hagerstown/parkside-at-walkersville/ took longer than 15.0 seconds..
2019-11-10 19:49:43 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demarini.com/en-us/bats/baseball-bats?bat_model_year=2893>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demarini.com/en-us/bats/baseball-bats?bat_model_year=2893 took longer than 15.0 seconds..
2019-11-10 19:49:43 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.dacor.com/products/collections/heritage/ranges/heritage-36-induction-pro-range>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.dacor.com/products/collections/heritage/ranges/heritage-36-induction-pro-range took longer than 15.0 seconds..
2019-11-10 19:49:43 [scrapy.core.scraper] ERROR: Error downloading <GET https://curtisindustries.net/product-pages/accessories/tel:5088532200>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://curtisindustries.net/product-pages/accessories/tel:5088532200 took longer than 15.0 seconds..
2019-11-10 19:50:19 [scrapy.extensions.logstats] INFO: Crawled 3447 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 19:50:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.dacor.com/products/collections/heritage/ranges/heritage-30-induction-pro-range>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 19:50:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.crabtree-evelyn.com/collections/crabtree/products/8237>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 19:50:19 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/the-importance-of-sticking-to-a-pre-and-post-flash-routine/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/the-importance-of-sticking-to-a-pre-and-post-flash-routine/ took longer than 15.0 seconds..
2019-11-10 19:50:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/disclaimers/char-getmoving/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/disclaimers/char-getmoving/ took longer than 15.0 seconds..
2019-11-10 19:50:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/press-releases/detail/145/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/press-releases/detail/145/ took longer than 15.0 seconds..
2019-11-10 19:50:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://investors.coty.com/news-events-and-presentations/news/default.aspx>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://investors.coty.com/news-events-and-presentations/news/default.aspx took longer than 15.0 seconds..
2019-11-10 19:50:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.coty.com/cookie-policy>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.coty.com/cookie-policy took longer than 15.0 seconds..
2019-11-10 19:50:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.deltaapparelinc.com/investors/financial-information/balance-sheet>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.deltaapparelinc.com/investors/financial-information/balance-sheet took longer than 15.0 seconds..
2019-11-10 19:50:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demarini.com/en-us/bats/baseball-bats?bat_model_year=5415>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demarini.com/en-us/bats/baseball-bats?bat_model_year=5415 took longer than 15.0 seconds..
2019-11-10 19:50:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.crabtree-evelyn.com/collections/crabtree/products/8298>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 19:50:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.coty.com/contact-information>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.coty.com/contact-information took longer than 15.0 seconds..
2019-11-10 19:50:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/press-releases/detail/145>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/press-releases/detail/145 took longer than 15.0 seconds..
2019-11-10 19:50:46 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/wp-admin/admin-ajax.php?action=process_simple_like&post_id=23362&nonce=df3eef113a&is_comment=0&disabled=true>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/wp-admin/admin-ajax.php?action=process_simple_like&post_id=23362&nonce=df3eef113a&is_comment=0&disabled=true took longer than 15.0 seconds..
2019-11-10 19:50:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.deltaapparelinc.com/investors/financial-information/financial-information>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.deltaapparelinc.com/investors/financial-information/financial-information took longer than 15.0 seconds..
2019-11-10 19:50:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demarini.com/en-us/bats/baseball-bats?baseball_bat_barrel_material=4556>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demarini.com/en-us/bats/baseball-bats?baseball_bat_barrel_material=4556 took longer than 15.0 seconds..
2019-11-10 19:50:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://investors.coty.com/stock-information/dividend-history/default.aspx>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://investors.coty.com/stock-information/dividend-history/default.aspx took longer than 15.0 seconds..
2019-11-10 19:50:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/our-home-plans/wv-panhandle-homes/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/our-home-plans/wv-panhandle-homes/ took longer than 15.0 seconds..
2019-11-10 19:50:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://supplier.coty.com/supplier-program>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://supplier.coty.com/supplier-program took longer than 15.0 seconds..
2019-11-10 19:50:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.dacor.com/products/collections/heritage/ranges/heritage-48-dual-fuel-epicure-range>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.dacor.com/products/collections/heritage/ranges/heritage-48-dual-fuel-epicure-range took longer than 15.0 seconds..
2019-11-10 19:51:10 [scrapy.extensions.logstats] INFO: Crawled 3449 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 19:51:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.crabtree-evelyn.com/collections/crabtree/products/8437>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 19:51:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.coty.com/about>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.coty.com/about took longer than 15.0 seconds..
2019-11-10 19:51:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/all-sec-filings/xbrl_doc_only/968>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/all-sec-filings/xbrl_doc_only/968 took longer than 15.0 seconds..
2019-11-10 19:51:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://supplier.coty.com/Communications>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://supplier.coty.com/Communications took longer than 15.0 seconds..
2019-11-10 19:51:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.deltaapparelinc.com/investors/company-information/contacts>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.deltaapparelinc.com/investors/company-information/contacts took longer than 15.0 seconds..
2019-11-10 19:51:10 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/how-to-prep-your-skin-for-the-fall/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/how-to-prep-your-skin-for-the-fall/ took longer than 15.0 seconds..
2019-11-10 19:51:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://investors.coty.com/stock-information/investment-calculator/default.aspx>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://investors.coty.com/stock-information/investment-calculator/default.aspx took longer than 15.0 seconds..
2019-11-10 19:51:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.dacor.com/products/collections/heritage/ranges/heritage-30-dual-fuel-pro-range>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.dacor.com/products/collections/heritage/ranges/heritage-30-dual-fuel-pro-range took longer than 15.0 seconds..
2019-11-10 19:51:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demarini.com/en-us/bats/baseball-bats?baseball_bat_barrel_material=912>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demarini.com/en-us/bats/baseball-bats?baseball_bat_barrel_material=912 took longer than 15.0 seconds..
2019-11-10 19:51:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/our-home-plans/martinsburg-homes/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/our-home-plans/martinsburg-homes/ took longer than 15.0 seconds..
2019-11-10 19:51:34 [scrapy.core.scraper] ERROR: Error downloading <GET http://shop.deltachildren.com>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://shop.deltachildren.com took longer than 15.0 seconds..
2019-11-10 19:51:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://world.dvf.com/new/all-new-arrivals/sweater/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://world.dvf.com/new/all-new-arrivals/sweater/ took longer than 15.0 seconds..
2019-11-10 19:51:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.crabtree-evelyn.com/collections/crabtree/products/8398>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 19:51:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.dacor.com/products/collections/modernist/ranges/modernist-48-pro-dual-fuel-steam-range>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 19:51:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.deltaapparelinc.com/investors/company-information/management-team>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.deltaapparelinc.com/investors/company-information/management-team took longer than 15.0 seconds..
2019-11-10 19:51:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/all-sec-filings/content/0001101396-16-000097/dla_20161001-10k.htm>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/all-sec-filings/content/0001101396-16-000097/dla_20161001-10k.htm took longer than 15.0 seconds..
2019-11-10 19:51:58 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/fall-beauty-staples-were-obsessed-with/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/fall-beauty-staples-were-obsessed-with/ took longer than 15.0 seconds..
2019-11-10 19:51:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demarini.com/en-us/bats/baseball-bats?baseball_bat_barrel_material=913>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demarini.com/en-us/bats/baseball-bats?baseball_bat_barrel_material=913 took longer than 15.0 seconds..
2019-11-10 19:51:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://world.dvf.com/new/all-new-arrivals/skirt/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://world.dvf.com/new/all-new-arrivals/skirt/ took longer than 15.0 seconds..
2019-11-10 19:51:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/our-home-plans/morgantown-homes/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/our-home-plans/morgantown-homes/ took longer than 15.0 seconds..
2019-11-10 19:51:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.dacor.com/products/collections/modernist/ranges/modernist-36-pro-gas-range>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 19:52:22 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/wp-admin/admin-ajax.php?action=process_simple_like&post_id=23366&nonce=df3eef113a&is_comment=0&disabled=true>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/wp-admin/admin-ajax.php?action=process_simple_like&post_id=23366&nonce=df3eef113a&is_comment=0&disabled=true took longer than 15.0 seconds..
2019-11-10 19:52:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/our-home-plans/hagerstown-homes/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/our-home-plans/hagerstown-homes/ took longer than 15.0 seconds..
2019-11-10 19:52:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.deltaapparelinc.com/investors/company-information/profile>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.deltaapparelinc.com/investors/company-information/profile took longer than 15.0 seconds..
2019-11-10 19:52:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demarini.com/en-us/bats/baseball-bats?baseball_bat_barrel_diameter=5742>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demarini.com/en-us/bats/baseball-bats?baseball_bat_barrel_diameter=5742 took longer than 15.0 seconds..
2019-11-10 19:52:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/press-releases/detail/151>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/press-releases/detail/151 took longer than 15.0 seconds..
2019-11-10 19:52:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://world.dvf.com/new/all-new-arrivals/dress/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://world.dvf.com/new/all-new-arrivals/dress/ took longer than 15.0 seconds..
2019-11-10 19:52:23 [scrapy.extensions.logstats] INFO: Crawled 3452 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 19:52:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.deltaapparelinc.com/investors/company-information/company-information>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.deltaapparelinc.com/investors/company-information/company-information took longer than 15.0 seconds..
2019-11-10 19:52:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/all-sec-filings/xbrl_doc_only/679>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/all-sec-filings/xbrl_doc_only/679 took longer than 15.0 seconds..
2019-11-10 19:52:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/wv-panhandle/briar-run/york-ii-garage/1664364/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/wv-panhandle/briar-run/york-ii-garage/1664364/ took longer than 15.0 seconds..
2019-11-10 19:52:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://world.dvf.com/new/all-new-arrivals/boots/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://world.dvf.com/new/all-new-arrivals/boots/ took longer than 15.0 seconds..
2019-11-10 19:52:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demarini.com/en-us/bats/baseball-bats?baseball_bat_barrel_diameter=908>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demarini.com/en-us/bats/baseball-bats?baseball_bat_barrel_diameter=908 took longer than 15.0 seconds..
2019-11-10 19:52:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.dacor.com/products/collections/heritage/wall-ovens/heritage-27-epicure-double-wall-ovens>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.dacor.com/products/collections/heritage/wall-ovens/heritage-27-epicure-double-wall-ovens took longer than 15.0 seconds..
2019-11-10 19:52:46 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/10-makeup-ideas-for-halloween-made-better-when-you-flash/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/10-makeup-ideas-for-halloween-made-better-when-you-flash/ took longer than 15.0 seconds..
2019-11-10 19:52:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://world.dvf.com/new/tvf-for-dvf/12/>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 19:52:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.dacor.com/products/collections/heritage/>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 19:53:10 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/wp-admin/admin-ajax.php?action=process_simple_like&post_id=23421&nonce=df3eef113a&is_comment=0&disabled=true>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/wp-admin/admin-ajax.php?action=process_simple_like&post_id=23421&nonce=df3eef113a&is_comment=0&disabled=true took longer than 15.0 seconds..
2019-11-10 19:53:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/all-sec-filings/content/0001101396-17-000005/dla_20161231-10q.htm>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/all-sec-filings/content/0001101396-17-000005/dla_20161231-10q.htm took longer than 15.0 seconds..
2019-11-10 19:53:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.deltaapparelinc.com/investors/news-events/email-alerts>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.deltaapparelinc.com/investors/news-events/email-alerts took longer than 15.0 seconds..
2019-11-10 19:53:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.crabtree-evelyn.com/collections/crabtree/products/8439>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.crabtree-evelyn.com/collections/crabtree/products/8439 took longer than 15.0 seconds..
2019-11-10 19:53:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/wv-panhandle/briar-run/york-ii-garage/1664363/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/wv-panhandle/briar-run/york-ii-garage/1664363/ took longer than 15.0 seconds..
2019-11-10 19:53:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demarini.com/en-us/bats/baseball-bats?baseball_bat_weight_drop=1021>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demarini.com/en-us/bats/baseball-bats?baseball_bat_weight_drop=1021 took longer than 15.0 seconds..
2019-11-10 19:53:10 [scrapy.extensions.logstats] INFO: Crawled 3454 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 19:53:34 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/how-to-get-camera-ready-skin-for-your-fall-wedding/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/how-to-get-camera-ready-skin-for-your-fall-wedding/ took longer than 15.0 seconds..
2019-11-10 19:53:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://world.dvf.com/new/tvf-for-dvf/10/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://world.dvf.com/new/tvf-for-dvf/10/ took longer than 15.0 seconds..
2019-11-10 19:53:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.deltaapparelinc.com/investors/news-events/ir-calendar>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.deltaapparelinc.com/investors/news-events/ir-calendar took longer than 15.0 seconds..
2019-11-10 19:53:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demarini.com/en-us/bats/baseball-bats?baseball_bat_weight_drop=1023>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demarini.com/en-us/bats/baseball-bats?baseball_bat_weight_drop=1023 took longer than 15.0 seconds..
2019-11-10 19:53:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/press-releases/detail/153/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/press-releases/detail/153/ took longer than 15.0 seconds..
2019-11-10 19:53:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.dacor.com/products/collections/modernist/cooktops/modernist-30-induction-cooktop>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.dacor.com/products/collections/modernist/cooktops/modernist-30-induction-cooktop took longer than 15.0 seconds..
2019-11-10 19:53:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/wv-panhandle/archers-rock/tulane-ii/1724264/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/wv-panhandle/archers-rock/tulane-ii/1724264/ took longer than 15.0 seconds..
2019-11-10 19:53:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.dacor.com/products/collections/modernist/cooktops/modernist-36-gas-cooktop>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 19:53:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/wv-panhandle/stonebrook-village/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/wv-panhandle/stonebrook-village/ took longer than 15.0 seconds..
2019-11-10 19:53:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/all-sec-filings/content/0001101396-17-000035/dla_20170701-10q.htm>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/all-sec-filings/content/0001101396-17-000035/dla_20170701-10q.htm took longer than 15.0 seconds..
2019-11-10 19:53:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://world.dvf.com/new/tvf-for-dvf/black/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://world.dvf.com/new/tvf-for-dvf/black/ took longer than 15.0 seconds..
2019-11-10 19:53:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demarini.com/en-us/bats/baseball-bats?baseball_bat_series=3500>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demarini.com/en-us/bats/baseball-bats?baseball_bat_series=3500 took longer than 15.0 seconds..
2019-11-10 19:53:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.deltaapparelinc.com/investors/news-events/press-releases>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.deltaapparelinc.com/investors/news-events/press-releases took longer than 15.0 seconds..
2019-11-10 19:53:58 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/wp-admin/admin-ajax.php?action=process_simple_like&post_id=23449&nonce=df3eef113a&is_comment=0&disabled=true>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/wp-admin/admin-ajax.php?action=process_simple_like&post_id=23449&nonce=df3eef113a&is_comment=0&disabled=true took longer than 15.0 seconds..
2019-11-10 19:54:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://world.dvf.com/new/tvf-for-dvf/top-blouse-shirt/>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 19:54:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.dacor.com/products/collections/modernist/column/modernist-36-column-freezer-panel-ready>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 19:54:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demarini.com/en-us/bats/baseball-bats?baseball_bat_series=3501>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demarini.com/en-us/bats/baseball-bats?baseball_bat_series=3501 took longer than 15.0 seconds..
2019-11-10 19:54:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/our-home-plans/baltimore-homes/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/our-home-plans/baltimore-homes/ took longer than 15.0 seconds..
2019-11-10 19:54:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/all-sec-filings/content/0001101396-17-000045/dla_20170930-10k.htm>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/all-sec-filings/content/0001101396-17-000045/dla_20170930-10k.htm took longer than 15.0 seconds..
2019-11-10 19:54:42 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/category/dermaflash/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/category/dermaflash/ took longer than 15.0 seconds..
2019-11-10 19:54:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.deltaapparelinc.com/investors/news-events/news-events>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.deltaapparelinc.com/investors/news-events/news-events took longer than 15.0 seconds..
2019-11-10 19:54:42 [scrapy.extensions.logstats] INFO: Crawled 3457 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 19:55:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/press-releases/detail/262/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/press-releases/detail/262/ took longer than 15.0 seconds..
2019-11-10 19:55:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://world.dvf.com/new/the-cashmere-shop/top-blouse-shirt/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://world.dvf.com/new/the-cashmere-shop/top-blouse-shirt/ took longer than 15.0 seconds..
2019-11-10 19:55:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.deltaapparelinc.com/our-brands/overview>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.deltaapparelinc.com/our-brands/overview took longer than 15.0 seconds..
2019-11-10 19:55:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.dacor.com/products/collections/modernist/column/modernist-30-column-freezer-panel-ready>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.dacor.com/products/collections/modernist/column/modernist-30-column-freezer-panel-ready took longer than 15.0 seconds..
2019-11-10 19:55:14 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/how-to-get-skincare-to-do-its-job-in-the-colder-months/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/how-to-get-skincare-to-do-its-job-in-the-colder-months/ took longer than 15.0 seconds..
2019-11-10 19:55:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/our-home-plans/charleston-homes-1/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/our-home-plans/charleston-homes-1/ took longer than 15.0 seconds..
2019-11-10 19:55:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demarini.com/en-us/bats/baseball-bats?baseball_bat_certification=4551>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demarini.com/en-us/bats/baseball-bats?baseball_bat_certification=4551 took longer than 15.0 seconds..
2019-11-10 19:55:14 [scrapy.extensions.logstats] INFO: Crawled 3458 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 19:55:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://world.dvf.com/new/tvf-for-dvf/?srule=newness&sz=24&start=0>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 19:55:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.dacor.com/products/collections/heritage/wall-ovens/heritage-27-flush-single-wall-oven>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 19:55:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/all-sec-filings/xbrl_doc_only/1202>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/all-sec-filings/xbrl_doc_only/1202 took longer than 15.0 seconds..
2019-11-10 19:55:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demarini.com/en-us/bats/baseball-bats?baseball_bat_certification=3800>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demarini.com/en-us/bats/baseball-bats?baseball_bat_certification=3800 took longer than 15.0 seconds..
2019-11-10 19:55:50 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com took longer than 15.0 seconds..
2019-11-10 19:55:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/find-your-home/morgantown-wv-quick-move-in-homes/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/find-your-home/morgantown-wv-quick-move-in-homes/ took longer than 15.0 seconds..
2019-11-10 19:55:50 [scrapy.core.scraper] ERROR: Error downloading <GET http://contour.com/video_listing/contour2-phantom-2>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://contour.com/video_listing/contour2-phantom-2 took longer than 15.0 seconds..
2019-11-10 19:55:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://world.dvf.com/new/the-cashmere-shop/black/>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 19:55:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.dacor.com/products/collections/heritage/wall-ovens/heritage-30-epicure-single-wall-oven>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 19:56:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demarini.com/en-us/bags/special-ops-wheeled-bag>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demarini.com/en-us/bags/special-ops-wheeled-bag took longer than 15.0 seconds..
2019-11-10 19:56:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/press-releases/detail/274/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/press-releases/detail/274/ took longer than 15.0 seconds..
2019-11-10 19:56:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/find-your-home/jefferson-county-wv-quick-move-in-home/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/find-your-home/jefferson-county-wv-quick-move-in-home/ took longer than 15.0 seconds..
2019-11-10 19:56:26 [scrapy.core.scraper] ERROR: Error downloading <GET http://contour.com/video_listing/new-jammer-line-little-swizterland-bike-park>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://contour.com/video_listing/new-jammer-line-little-swizterland-bike-park took longer than 15.0 seconds..
2019-11-10 19:56:26 [scrapy.extensions.logstats] INFO: Crawled 3460 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 19:56:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.dacor.com/products/collections/heritage/wall-ovens/heritage-27-pro-single-wall-oven>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 19:57:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demarini.com/en-us/bags/voodoo-rebirth-backpack>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demarini.com/en-us/bags/voodoo-rebirth-backpack took longer than 15.0 seconds..
2019-11-10 19:57:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/our-home-plans-2018/greenville-homes/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/our-home-plans-2018/greenville-homes/ took longer than 15.0 seconds..
2019-11-10 19:57:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/press-releases/detail/274>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/press-releases/detail/274 took longer than 15.0 seconds..
2019-11-10 19:57:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://world.dvf.com/new/pre-order/16/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://world.dvf.com/new/pre-order/16/ took longer than 15.0 seconds..
2019-11-10 19:57:04 [scrapy.core.scraper] ERROR: Error downloading <GET http://contour.com/video_cat/bike>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://contour.com/video_cat/bike took longer than 15.0 seconds..
2019-11-10 19:57:04 [scrapy.extensions.logstats] INFO: Crawled 3461 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 19:57:04 [scrapy.core.scraper] ERROR: Error downloading <GET http://contour.com/wp-login.php?redirect_to=http%3A%2F%2Fcontour.com%2Fvideos>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2019-11-10 19:57:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/our-home-plans-2018/charleston-homes/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/our-home-plans-2018/charleston-homes/ took longer than 15.0 seconds..
2019-11-10 19:57:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demarini.com/en-us/bags/special-ops-spectre-wheeled-bag>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demarini.com/en-us/bags/special-ops-spectre-wheeled-bag took longer than 15.0 seconds..
2019-11-10 19:57:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/press-releases/detail/284/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/press-releases/detail/284/ took longer than 15.0 seconds..
2019-11-10 19:57:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.dacor.com/products/collections/modernist/wall-ovens/modernist-30-combination-wall-oven>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.dacor.com/products/collections/modernist/wall-ovens/modernist-30-combination-wall-oven took longer than 15.0 seconds..
2019-11-10 19:57:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://world.dvf.com/new/pre-order/l/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://world.dvf.com/new/pre-order/l/ took longer than 15.0 seconds..
2019-11-10 19:57:38 [scrapy.core.scraper] ERROR: Error downloading <GET http://contour.com/wp-login.php?redirect_to=http%3A%2F%2Fcontour.com%2Fphotos>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2019-11-10 19:57:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://world.dvf.com/new/the-cashmere-shop/nude%2Fbrown/>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 19:58:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/home-buyer-resources/charleston-online-new-home-specialist/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/home-buyer-resources/charleston-online-new-home-specialist/ took longer than 15.0 seconds..
2019-11-10 19:58:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demarini.com/en-us/bags/voodoo-rebirth-backpack-navy-scarlet-white>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demarini.com/en-us/bags/voodoo-rebirth-backpack-navy-scarlet-white took longer than 15.0 seconds..
2019-11-10 19:58:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.dacor.com/products/collections/heritage/ventilation/heritage-46-downdraft>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.dacor.com/products/collections/heritage/ventilation/heritage-46-downdraft took longer than 15.0 seconds..
2019-11-10 19:58:14 [scrapy.extensions.logstats] INFO: Crawled 3463 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 19:58:14 [scrapy.core.scraper] ERROR: Error downloading <GET http://contour.com/author/contourvideo>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2019-11-10 19:58:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.crabtree-evelyn.com/products/%redirect_store_url%>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 19:58:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.dacor.com/products/collections/heritage/ventilation/heritage-36-chimney-hood>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 19:58:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/home-buyer-resources/buying-tips/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/home-buyer-resources/buying-tips/ took longer than 15.0 seconds..
2019-11-10 19:58:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demarini.com/en-us/bags/voodoo-junior-backpack>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demarini.com/en-us/bags/voodoo-junior-backpack took longer than 15.0 seconds..
2019-11-10 19:58:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://world.dvf.com/new/pre-order/colorblock/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://world.dvf.com/new/pre-order/colorblock/ took longer than 15.0 seconds..
2019-11-10 19:58:46 [scrapy.core.scraper] ERROR: Error downloading <GET http://contour.com/new-video-community>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2019-11-10 19:58:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.dacor.com/products/collections/modernist/ventilation/modernist-36-island-hood>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 19:58:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.crabtree-evelyn.com/pages/crabtree-collection>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 19:58:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://world.dvf.com/new/pre-order/animal/>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 19:58:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/the-dan-ryan-builders-difference/career-opportunities/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/the-dan-ryan-builders-difference/career-opportunities/ took longer than 15.0 seconds..
2019-11-10 19:59:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demarini.com/en-us/bags?baseball_bag_type=2320>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demarini.com/en-us/bags?baseball_bag_type=2320 took longer than 15.0 seconds..
2019-11-10 19:59:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://curtisindustries.net/become-a-curtis-dealer/tel:5088532200>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://curtisindustries.net/become-a-curtis-dealer/tel:5088532200 took longer than 15.0 seconds..
2019-11-10 19:59:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://shop.demarini.com/en-us/customer/account/login/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://shop.demarini.com/en-us/customer/account/login/ took longer than 15.0 seconds..
2019-11-10 19:59:19 [scrapy.extensions.logstats] INFO: Crawled 3465 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 19:59:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.dacor.com/products/collections/modernist/ventilation/modernist-48-downdraft>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 19:59:19 [scrapy.core.scraper] ERROR: Error downloading <GET http://contour.com/contour-becomes-exclusive-pov-camera-wakeboardings-elite-series>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2019-11-10 19:59:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.crabtree-evelyn.com/collections/mainline/products/8493>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 19:59:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demarini.com/en-us/apparel/caps/gold-d-flexfit-hat>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demarini.com/en-us/apparel/caps/gold-d-flexfit-hat took longer than 15.0 seconds..
2019-11-10 19:59:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://world.dvf.com/new/pre-order/white/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://world.dvf.com/new/pre-order/white/ took longer than 15.0 seconds..
2019-11-10 19:59:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/the-dan-ryan-builders-difference/commitment-to-the-communities/mission-10-miler/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/the-dan-ryan-builders-difference/commitment-to-the-communities/mission-10-miler/ took longer than 15.0 seconds..
2019-11-10 19:59:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://curtisindustries.net/become-a-curtis-dealer/tel:5088543377>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://curtisindustries.net/become-a-curtis-dealer/tel:5088543377 took longer than 15.0 seconds..
2019-11-10 19:59:58 [scrapy.core.scraper] ERROR: Error downloading <GET http://contour.com/cam-zink-locks-partnership-contour>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2019-11-10 19:59:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.crabtree-evelyn.com/collections/mainline/products/8392>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 19:59:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://world.dvf.com/new/pre-order/red/>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 20:00:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/the-dan-ryan-builders-difference/commitment-to-the-communities/make-a-wish/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/the-dan-ryan-builders-difference/commitment-to-the-communities/make-a-wish/ took longer than 15.0 seconds..
2019-11-10 20:00:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.dacor.com/products/collections/modernist/ventilation/modernist-36-wall-hood>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.dacor.com/products/collections/modernist/ventilation/modernist-36-wall-hood took longer than 15.0 seconds..
2019-11-10 20:00:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demarini.com/en-us/apparel/caps/2020-usa-printed-snapback>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demarini.com/en-us/apparel/caps/2020-usa-printed-snapback took longer than 15.0 seconds..
2019-11-10 20:00:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://shop.demarini.com/us/customer/account/forgotpassword/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://shop.demarini.com/us/customer/account/forgotpassword/ took longer than 15.0 seconds..
2019-11-10 20:00:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://curtisindustries.net/product-registration/tel:5088532200>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://curtisindustries.net/product-registration/tel:5088532200 took longer than 15.0 seconds..
2019-11-10 20:00:38 [scrapy.extensions.logstats] INFO: Crawled 3467 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 20:00:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.dacor.com/products/collections/modernist/ventilation/modernist-30-wall-hood>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 20:00:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://world.dvf.com/new/the-cashmere-shop/yellow/>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 20:00:38 [scrapy.core.scraper] ERROR: Error downloading <GET http://contour.com/author/cameron-kirby>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2019-11-10 20:01:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/the-dan-ryan-builders-difference/commitment-to-the-communities/a-legacy-of-giving/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/the-dan-ryan-builders-difference/commitment-to-the-communities/a-legacy-of-giving/ took longer than 15.0 seconds..
2019-11-10 20:01:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demarini.com/en-us/apparel/caps/b-i-g-snapback>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demarini.com/en-us/apparel/caps/b-i-g-snapback took longer than 15.0 seconds..
2019-11-10 20:01:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cramco.net/ProductDetails.aspx?item_no=92780-539&CatId=ff02b02b-a317-4305-a1c9-e1ece177eaa6>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.cramco.net/ProductDetails.aspx?item_no=92780-539&CatId=ff02b02b-a317-4305-a1c9-e1ece177eaa6 took longer than 15.0 seconds..
2019-11-10 20:01:12 [scrapy.extensions.logstats] INFO: Crawled 3468 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 20:01:12 [scrapy.core.scraper] ERROR: Error downloading <GET http://contour.com/flying-icon-climber-steph-davis-joins-team-contour>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2019-11-10 20:01:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://world.dvf.com/new/the-cashmere-shop/colorblock/>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 20:01:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.dacor.com/products/collections/heritage/microwaves/heritage-24-microwave-in-a-drawer>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 20:01:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/the-dan-ryan-builders-difference/contact-us/tel:7249391015>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/the-dan-ryan-builders-difference/contact-us/tel:7249391015 took longer than 15.0 seconds..
2019-11-10 20:01:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demarini.com/en-us/apparel/caps/radiation-d-flexfit-hat>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demarini.com/en-us/apparel/caps/radiation-d-flexfit-hat took longer than 15.0 seconds..
2019-11-10 20:01:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.crabtree-evelyn.com/collections/mainline/products/8437>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.crabtree-evelyn.com/collections/mainline/products/8437 took longer than 15.0 seconds..
2019-11-10 20:01:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://curtisindustries.net/contact-us/tel:5088532200>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://curtisindustries.net/contact-us/tel:5088532200 took longer than 15.0 seconds..
2019-11-10 20:01:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cramco.net/ProductDetails.aspx?item_no=G5735-549&CatId=ff02b02b-a317-4305-a1c9-e1ece177eaa6>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.cramco.net/ProductDetails.aspx?item_no=G5735-549&CatId=ff02b02b-a317-4305-a1c9-e1ece177eaa6 took longer than 15.0 seconds..
2019-11-10 20:01:48 [scrapy.core.scraper] ERROR: Error downloading <GET http://contour.com/contour-action-cameras-now-accepts-bitcoin>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2019-11-10 20:01:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.crabtree-evelyn.com/collections/mainline/products/8398>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 20:01:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.dacor.com/products/collections/heritage/warming-drawers/heritage-30-flush-warming-drawer>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 20:01:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demarini.com/en-us/apparel/pants/girls-sleek-pant>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 20:02:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/homeowner-resources/customer-service/tel:4122756617>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/homeowner-resources/customer-service/tel:4122756617 took longer than 15.0 seconds..
2019-11-10 20:02:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://world.dvf.com/new/pre-order/dress/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://world.dvf.com/new/pre-order/dress/ took longer than 15.0 seconds..
2019-11-10 20:02:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cramco.net/ProductDetails.aspx?item_no=72688-539&CatId=ff02b02b-a317-4305-a1c9-e1ece177eaa6>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.cramco.net/ProductDetails.aspx?item_no=72688-539&CatId=ff02b02b-a317-4305-a1c9-e1ece177eaa6 took longer than 15.0 seconds..
2019-11-10 20:02:28 [scrapy.extensions.logstats] INFO: Crawled 3470 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 20:02:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.dacor.com/products/collections/heritage/warming-drawers/heritage-24-pro-warming-drawers>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 20:02:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://curtisindustries.net/shop/>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 20:02:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/homeowner-resources/customer-service/tel:8664235676>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/homeowner-resources/customer-service/tel:8664235676 took longer than 15.0 seconds..
2019-11-10 20:02:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://world.dvf.com/new/the-cashmere-shop/s/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://world.dvf.com/new/the-cashmere-shop/s/ took longer than 15.0 seconds..
2019-11-10 20:02:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.crabtree-evelyn.com/collections/mainline/products/8387>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.crabtree-evelyn.com/collections/mainline/products/8387 took longer than 15.0 seconds..
2019-11-10 20:02:52 [scrapy.core.scraper] ERROR: Error downloading <GET http://contour.com/contour-granted-meaningful-new-patents-covering-wireless-connectivity>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://contour.com/contour-granted-meaningful-new-patents-covering-wireless-connectivity took longer than 15.0 seconds..
2019-11-10 20:02:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demarini.com/en-us/apparel/pants/women-s-fierce-pant>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demarini.com/en-us/apparel/pants/women-s-fierce-pant took longer than 15.0 seconds..
2019-11-10 20:02:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cramco.net/ProductDetails.aspx?item_no=W2550-539&CatId=ff02b02b-a317-4305-a1c9-e1ece177eaa6>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.cramco.net/ProductDetails.aspx?item_no=W2550-539&CatId=ff02b02b-a317-4305-a1c9-e1ece177eaa6 took longer than 15.0 seconds..
2019-11-10 20:02:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://world.dvf.com/new/pre-order/accessories/>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 20:03:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demarini.com/en-us/apparel/pants/women-s-sleek-pant>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demarini.com/en-us/apparel/pants/women-s-sleek-pant took longer than 15.0 seconds..
2019-11-10 20:03:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/communities/pennsylvania/south-central-pa/saddle-ridge-estates/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/communities/pennsylvania/south-central-pa/saddle-ridge-estates/ took longer than 15.0 seconds..
2019-11-10 20:03:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cramco.net/ProductDetails.aspx?item_no=45537-539&CatId=ff02b02b-a317-4305-a1c9-e1ece177eaa6>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.cramco.net/ProductDetails.aspx?item_no=45537-539&CatId=ff02b02b-a317-4305-a1c9-e1ece177eaa6 took longer than 15.0 seconds..
2019-11-10 20:03:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.crabtree-evelyn.com/collections/mainline/products/9255>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.crabtree-evelyn.com/collections/mainline/products/9255 took longer than 15.0 seconds..
2019-11-10 20:03:16 [scrapy.core.scraper] ERROR: Error downloading <GET http://contour.com/wp-login.php?redirect_to=http%3A%2F%2Fcontour.com%2Fcameras%2Fcontour-4k>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://contour.com/wp-login.php?redirect_to=http%3A%2F%2Fcontour.com%2Fcameras%2Fcontour-4k took longer than 15.0 seconds..
2019-11-10 20:03:16 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.contour.com>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.contour.com took longer than 15.0 seconds..
2019-11-10 20:03:16 [scrapy.extensions.logstats] INFO: Crawled 3472 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 20:03:16 [scrapy.core.scraper] ERROR: Error downloading <GET http://contour.com/video_listing/fail-track-day-180-degree-spin>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2019-11-10 20:03:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://world.dvf.com/remy-mesh-mockneck/13377DVF.html?dwvar_13377DVF_size=XS&dwvar_13377DVF_color=PDFBL&bcid=new-arrivals-woman-in-charge>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 20:03:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/communities/pennsylvania/south-central-pa/mountain-shadows/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/communities/pennsylvania/south-central-pa/mountain-shadows/ took longer than 15.0 seconds..
2019-11-10 20:03:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demarini.com/en-us/apparel/pants/men-s-uprising-pant>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demarini.com/en-us/apparel/pants/men-s-uprising-pant took longer than 15.0 seconds..
2019-11-10 20:03:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.crabtree-evelyn.com/collections/mainline/products/9213>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.crabtree-evelyn.com/collections/mainline/products/9213 took longer than 15.0 seconds..
2019-11-10 20:03:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://curtisindustries.net/careers/tel:5088532200>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://curtisindustries.net/careers/tel:5088532200 took longer than 15.0 seconds..
2019-11-10 20:03:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cramco.net/ProductDetails.aspx?item_no=BX461-539&CatId=ff02b02b-a317-4305-a1c9-e1ece177eaa6>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.cramco.net/ProductDetails.aspx?item_no=BX461-539&CatId=ff02b02b-a317-4305-a1c9-e1ece177eaa6 took longer than 15.0 seconds..
2019-11-10 20:03:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://world.dvf.com/new/the-cashmere-shop/m/>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 20:03:40 [scrapy.core.scraper] ERROR: Error downloading <GET http://contour.com/video_listing/file3219-riding-trent-stephens-heat-race-6-sept-14>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2019-11-10 20:03:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.crabtree-evelyn.com/collections/mainline/products/8999>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 20:03:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.conversionlabs.com/charts>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 20:04:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demarini.com/en-us/apparel/pants/girl-s-belted-pant>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demarini.com/en-us/apparel/pants/girl-s-belted-pant took longer than 15.0 seconds..
2019-11-10 20:04:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/communities/south-carolina/villas-at-west-georgia/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/communities/south-carolina/villas-at-west-georgia/ took longer than 15.0 seconds..
2019-11-10 20:04:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cramco.net/ProductDetails.aspx?item_no=W2466-539&CatId=ff02b02b-a317-4305-a1c9-e1ece177eaa6>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.cramco.net/ProductDetails.aspx?item_no=W2466-539&CatId=ff02b02b-a317-4305-a1c9-e1ece177eaa6 took longer than 15.0 seconds..
2019-11-10 20:04:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.dacor.com/Experiences/Events/Kips-Bay>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.dacor.com/Experiences/Events/Kips-Bay took longer than 15.0 seconds..
2019-11-10 20:04:04 [scrapy.extensions.logstats] INFO: Crawled 3474 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 20:04:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://world.dvf.com/melinda-silk-jersey-jumpsuit/13399DVF.html?dwvar_13399DVF_color=VIBPE&dwvar_13399DVF_size=XXS&bcid=new-arrivals-woman-in-charge>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 20:04:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.conversionlabs.com/quote>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 20:04:04 [scrapy.core.scraper] ERROR: Error downloading <GET http://contour.com/video_listing/fail-flip-pulled-behind-utv>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2019-11-10 20:04:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demarini.com/en-us/apparel?gender=15>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demarini.com/en-us/apparel?gender=15 took longer than 15.0 seconds..
2019-11-10 20:04:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cramco.net/ProductDetails.aspx?item_no=W2195-539&CatId=ff02b02b-a317-4305-a1c9-e1ece177eaa6>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.cramco.net/ProductDetails.aspx?item_no=W2195-539&CatId=ff02b02b-a317-4305-a1c9-e1ece177eaa6 took longer than 15.0 seconds..
2019-11-10 20:04:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/communities/south-carolina/village-at-green-meadows/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/communities/south-carolina/village-at-green-meadows/ took longer than 15.0 seconds..
2019-11-10 20:04:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.dacor.com/Experiences/Events/KBIS-2019>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.dacor.com/Experiences/Events/KBIS-2019 took longer than 15.0 seconds..
2019-11-10 20:04:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://curtisindustries.net/warranty/tel:5088532200>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://curtisindustries.net/warranty/tel:5088532200 took longer than 15.0 seconds..
2019-11-10 20:04:28 [scrapy.core.scraper] ERROR: Error downloading <GET http://contour.com/video_listing/gustavo-yakaman-long-beach-contour-camera>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2019-11-10 20:04:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.conversionlabs.com/financial-results>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 20:04:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demarini.com/en-us/apparel?hat_type_baseball=7222>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demarini.com/en-us/apparel?hat_type_baseball=7222 took longer than 15.0 seconds..
2019-11-10 20:04:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cramco.net/ProductDetails.aspx?item_no=G5182-749&CatId=ff02b02b-a317-4305-a1c9-e1ece177eaa6>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.cramco.net/ProductDetails.aspx?item_no=G5182-749&CatId=ff02b02b-a317-4305-a1c9-e1ece177eaa6 took longer than 15.0 seconds..
2019-11-10 20:04:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://world.dvf.com/meg-silk-metallic-tiered-midi-skirt/13450DVF.html?dwvar_13450DVF_color=TIEPB&dwvar_13450DVF_size=XXS&bcid=new-arrivals-woman-in-charge>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://world.dvf.com/meg-silk-metallic-tiered-midi-skirt/13450DVF.html?dwvar_13450DVF_color=TIEPB&dwvar_13450DVF_size=XXS&bcid=new-arrivals-woman-in-charge took longer than 15.0 seconds..
2019-11-10 20:04:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/communities/south-carolina/the-reserve-at-richglen/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/communities/south-carolina/the-reserve-at-richglen/ took longer than 15.0 seconds..
2019-11-10 20:04:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://curtisindustries.net/warranty-claim-process/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://curtisindustries.net/warranty-claim-process/ took longer than 15.0 seconds..
2019-11-10 20:04:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://nationaldesigncontest.dacor.com/enter-contest>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://nationaldesigncontest.dacor.com/enter-contest took longer than 15.0 seconds..
2019-11-10 20:04:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://store.contour.com/cart>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://store.contour.com/cart took longer than 15.0 seconds..
2019-11-10 20:04:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.conversionlabs.com/financials>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 20:04:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://world.dvf.com/pax-wool-blend-cowl-neck-sweater/13339DVF.html?dwvar_13339DVF_color=CAMEL&dwvar_13339DVF_size=XXS&bcid=new-arrivals-woman-in-charge>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2019-11-10 20:04:52 [scrapy.core.scraper] ERROR: Error downloading <GET http://contour.com/video_listing/r1200rtr1200gs>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2019-11-10 20:05:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cramco.net/ProductDetails.aspx?item_no=72095-339&CatId=ff02b02b-a317-4305-a1c9-e1ece177eaa6>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.cramco.net/ProductDetails.aspx?item_no=72095-339&CatId=ff02b02b-a317-4305-a1c9-e1ece177eaa6 took longer than 15.0 seconds..
2019-11-10 20:05:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demarini.com/en-us/bats/fastpitch-bats/2019-bustos-13-fastpitch-bat>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demarini.com/en-us/bats/fastpitch-bats/2019-bustos-13-fastpitch-bat took longer than 15.0 seconds..
2019-11-10 20:05:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://nationaldesigncontest.dacor.com/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://nationaldesigncontest.dacor.com/ took longer than 15.0 seconds..
2019-11-10 20:05:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/communities/south-carolina/pinecrest-at-hollingsworth-park/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/communities/south-carolina/pinecrest-at-hollingsworth-park/ took longer than 15.0 seconds..
2019-11-10 20:05:17 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.dana.com/contact-forms/contact-us-oh>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.dana.com/contact-forms/contact-us-oh took longer than 15.0 seconds..
2019-11-10 20:05:17 [scrapy.extensions.logstats] INFO: Crawled 3476 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 20:05:17 [scrapy.core.scraper] ERROR: Error downloading <GET http://contour.com/video_listing/dirtbike-santa>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2019-11-10 20:05:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cramco.net/ProductDetails.aspx?item_no=G5024-749&CatId=ff02b02b-a317-4305-a1c9-e1ece177eaa6>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.cramco.net/ProductDetails.aspx?item_no=G5024-749&CatId=ff02b02b-a317-4305-a1c9-e1ece177eaa6 took longer than 15.0 seconds..
2019-11-10 20:05:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://world.dvf.com/apple-cashmere-turtleneck/13354DVF.html?dwvar_13354DVF_size=XS&dwvar_13354DVF_color=AURML&bcid=new-arrivals-woman-in-charge>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://world.dvf.com/apple-cashmere-turtleneck/13354DVF.html?dwvar_13354DVF_size=XS&dwvar_13354DVF_color=AURML&bcid=new-arrivals-woman-in-charge took longer than 15.0 seconds..
2019-11-10 20:05:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demarini.com/en-us/bats/fastpitch-bats/2020-demarini-fnx-rising-8-fastpitch-bat>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demarini.com/en-us/bats/fastpitch-bats/2020-demarini-fnx-rising-8-fastpitch-bat took longer than 15.0 seconds..
2019-11-10 20:05:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.conversionlabs.com/email-alerts>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.conversionlabs.com/email-alerts took longer than 15.0 seconds..
2019-11-10 20:05:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/communities/south-carolina/phillips-creek/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/communities/south-carolina/phillips-creek/ took longer than 15.0 seconds..
2019-11-10 20:05:17 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.dana.com/literature%20search#search/query=/pageNum=0/pageSize=10/facets=1614decc-84b5-4ca0-945f-f1a63e379fd5>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.dana.com/literature%20search took longer than 15.0 seconds..
2019-11-10 20:05:17 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.curaegis.com/About/Board/DR-WILLIAM-W-DESTLER>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.curaegis.com/About/Board/DR-WILLIAM-W-DESTLER took longer than 15.0 seconds..
2019-11-10 20:06:05 [scrapy.extensions.logstats] INFO: Crawled 3490 pages (at 14 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 20:09:48 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.dana.com/off-highway/regions/japan>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.dana.com/off-highway/regions/japan took longer than 15.0 seconds..
2019-11-10 20:09:48 [scrapy.extensions.logstats] INFO: Crawled 3490 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 20:12:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/communities/south-carolina/mills-mill-reserve/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/communities/south-carolina/mills-mill-reserve/ took longer than 15.0 seconds..
2019-11-10 20:12:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cramco.net/ProductDetails.aspx?item_no=WE170-42&CatId=272f15d3-e68d-4486-9235-6377af52d74d>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.cramco.net/ProductDetails.aspx?item_no=WE170-42&CatId=272f15d3-e68d-4486-9235-6377af52d74d took longer than 15.0 seconds..
2019-11-10 20:12:54 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.dana.com/off-highway/regions/china>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.dana.com/off-highway/regions/china took longer than 15.0 seconds..
2019-11-10 20:12:54 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.curaegis.com/Cura-Division/myCadian/WhitePapers>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.curaegis.com/Cura-Division/myCadian/WhitePapers took longer than 15.0 seconds..
2019-11-10 20:12:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demarini.com/en-us/bats/fastpitch-bats?baseball_bat_weight_drop=1019>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demarini.com/en-us/bats/fastpitch-bats?baseball_bat_weight_drop=1019 took longer than 15.0 seconds..
2019-11-10 20:12:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.conversionlabs.com/contacts>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.conversionlabs.com/contacts took longer than 15.0 seconds..
2019-11-10 20:12:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://world.dvf.com/new/woman-in-charge/black/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://world.dvf.com/new/woman-in-charge/black/ took longer than 15.0 seconds..
2019-11-10 20:12:54 [scrapy.core.scraper] ERROR: Error downloading <GET http://contour.com/video_listing/rt-29-twisties-bart-linda>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://contour.com/video_listing/rt-29-twisties-bart-linda took longer than 15.0 seconds..
2019-11-10 20:12:54 [scrapy.extensions.logstats] INFO: Crawled 3490 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 20:12:54 [scrapy.core.scraper] ERROR: Error downloading <GET http://contour.com/video_listing/oren-hassan-mx>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://contour.com/video_listing/oren-hassan-mx took longer than 15.0 seconds..
2019-11-10 20:12:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.conversionlabs.com/profile>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.conversionlabs.com/profile took longer than 15.0 seconds..
2019-11-10 20:12:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://world.dvf.com>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://world.dvf.com took longer than 15.0 seconds..
2019-11-10 20:12:54 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.curaegis.com/News-Events/Fatigue-in-the-News-2/Fatigue-Science-5-areas-sleep-has-the-greatest-i>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.curaegis.com/News-Events/Fatigue-in-the-News-2/Fatigue-Science-5-areas-sleep-has-the-greatest-i took longer than 15.0 seconds..
2019-11-10 20:12:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cramco.net/ProductListing.aspx?CatId=272f15d3-e68d-4486-9235-6377af52d74d&cpage=2>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.cramco.net/ProductListing.aspx?CatId=272f15d3-e68d-4486-9235-6377af52d74d&cpage=2 took longer than 15.0 seconds..
2019-11-10 20:12:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demarini.com/en-us/bats/fastpitch-bats?baseball_bat_weight_drop=1020>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demarini.com/en-us/bats/fastpitch-bats?baseball_bat_weight_drop=1020 took longer than 15.0 seconds..
2019-11-10 20:12:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/communities/south-carolina/lakeview-chase-townes/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/communities/south-carolina/lakeview-chase-townes/ took longer than 15.0 seconds..
2019-11-10 20:12:54 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.dana.com/off-highway/regions/north-america>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.dana.com/off-highway/regions/north-america took longer than 15.0 seconds..
2019-11-10 20:13:30 [scrapy.extensions.logstats] INFO: Crawled 3497 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 20:14:46 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.dana.com/off-highway/regions/europe>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.dana.com/off-highway/regions/europe took longer than 15.0 seconds..
2019-11-10 20:14:46 [scrapy.extensions.logstats] INFO: Crawled 3502 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 20:16:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://contour.com/becomeadealer>: User timeout caused connection failure.
2019-11-10 20:16:58 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.dana.com/off-highway/solutions/solutions/connected-vehicles>: User timeout caused connection failure.
2019-11-10 20:16:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.columbia.com/customerService_contactUs.html>: User timeout caused connection failure.
2019-11-10 20:16:58 [scrapy.extensions.logstats] INFO: Crawled 3502 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 20:20:11 [scrapy.core.scraper] ERROR: Error downloading <GET http://contour.com/newsletter-signup/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://contour.com/newsletter-signup/ took longer than 15.0 seconds..
2019-11-10 20:20:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/find-your-home/winchester-va-quick-move-in-homes/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/find-your-home/winchester-va-quick-move-in-homes/ took longer than 15.0 seconds..
2019-11-10 20:20:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cramco.net/ProductDetails.aspx?item_no=CT442-02&CatId=272f15d3-e68d-4486-9235-6377af52d74d>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.cramco.net/ProductDetails.aspx?item_no=CT442-02&CatId=272f15d3-e68d-4486-9235-6377af52d74d took longer than 15.0 seconds..
2019-11-10 20:20:11 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.dana.com/off-highway/products/smart-suite>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.dana.com/off-highway/products/smart-suite took longer than 15.0 seconds..
2019-11-10 20:20:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demarini.com/en-us/bats>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demarini.com/en-us/bats took longer than 15.0 seconds..
2019-11-10 20:20:12 [scrapy.extensions.logstats] INFO: Crawled 3502 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 20:20:12 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.curaegis.com/News-Events/Current-News/Torvec,-Inc-Chief-Executive-Officer-Report>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2019-11-10 20:20:12 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.conferplastics.com/2019/06/public-can-participate-in-the-confer-classics-raffle-june-26th/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.conferplastics.com/2019/06/public-can-participate-in-the-confer-classics-raffle-june-26th/ took longer than 15.0 seconds..
2019-11-10 20:20:12 [scrapy.core.scraper] ERROR: Error downloading <GET http://contour.com/video_listing/estrada-sol-sun-rote>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://contour.com/video_listing/estrada-sol-sun-rote took longer than 15.0 seconds..
2019-11-10 20:20:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.demarini.com/en-us/help/warranty/form>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.demarini.com/en-us/help/warranty/form took longer than 15.0 seconds..
2019-11-10 20:20:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/home-buyer-resources/west-online-new-home-specialist/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/home-buyer-resources/west-online-new-home-specialist/ took longer than 15.0 seconds..
2019-11-10 20:20:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cramco.net/ProductDetails.aspx?item_no=CT167-04&CatId=272f15d3-e68d-4486-9235-6377af52d74d>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.cramco.net/ProductDetails.aspx?item_no=CT167-04&CatId=272f15d3-e68d-4486-9235-6377af52d74d took longer than 15.0 seconds..
2019-11-10 20:23:02 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.conferplastics.com/checkout/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.conferplastics.com/checkout/ took longer than 15.0 seconds..
2019-11-10 20:23:02 [scrapy.extensions.logstats] INFO: Crawled 3515 pages (at 13 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 20:25:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/our-home-plans-2018/winchester-homes/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/our-home-plans-2018/winchester-homes/ took longer than 15.0 seconds..
2019-11-10 20:25:28 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.dana.com/off-highway/markets-and-vehicles/agriculture>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.dana.com/off-highway/markets-and-vehicles/agriculture took longer than 15.0 seconds..
2019-11-10 20:25:28 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.conferplastics.com/cart/>: User timeout caused connection failure.
2019-11-10 20:25:28 [scrapy.core.scraper] ERROR: Error downloading <GET http://contour.com/author/jorge-portillazerofractal-com>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://contour.com/author/jorge-portillazerofractal-com took longer than 15.0 seconds..
2019-11-10 20:25:28 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.curaegis.com/News-Events/Current-News/CEO-Update-April-4th-2019>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.curaegis.com/News-Events/Current-News/CEO-Update-April-4th-2019 took longer than 15.0 seconds..
2019-11-10 20:25:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cramco.net/ProductDetails.aspx?item_no=CT451-06&CatId=272f15d3-e68d-4486-9235-6377af52d74d>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.cramco.net/ProductDetails.aspx?item_no=CT451-06&CatId=272f15d3-e68d-4486-9235-6377af52d74d took longer than 15.0 seconds..
2019-11-10 20:25:28 [scrapy.extensions.logstats] INFO: Crawled 3515 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 20:25:28 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.conferplastics.com/confer-plastics-and-the-american-dream/contact-us/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.conferplastics.com/confer-plastics-and-the-american-dream/contact-us/ took longer than 15.0 seconds..
2019-11-10 20:25:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/communities/south-carolina/greenville/the-reserve-at-richglen/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/communities/south-carolina/greenville/the-reserve-at-richglen/ took longer than 15.0 seconds..
2019-11-10 20:25:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cramco.net/ProductDetails.aspx?item_no=CT451-02&CatId=272f15d3-e68d-4486-9235-6377af52d74d>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.cramco.net/ProductDetails.aspx?item_no=CT451-02&CatId=272f15d3-e68d-4486-9235-6377af52d74d took longer than 15.0 seconds..
2019-11-10 20:25:28 [scrapy.core.scraper] ERROR: Error downloading <GET http://contour.com/video_listing/quito-trip>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://contour.com/video_listing/quito-trip took longer than 15.0 seconds..
2019-11-10 20:27:52 [scrapy.extensions.logstats] INFO: Crawled 3528 pages (at 13 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 20:30:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.dacor.com>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.dacor.com took longer than 15.0 seconds..
2019-11-10 20:30:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.conferplastics.com/confer-plastics-and-the-american-dream/directions-to-confer-plastics/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.conferplastics.com/confer-plastics-and-the-american-dream/directions-to-confer-plastics/ took longer than 15.0 seconds..
2019-11-10 20:30:20 [scrapy.extensions.logstats] INFO: Crawled 3528 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 20:33:14 [scrapy.core.scraper] ERROR: Error downloading <GET http://contour.com/video_listing/carnival-sunshine-waterslides>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://contour.com/video_listing/carnival-sunshine-waterslides took longer than 15.0 seconds..
2019-11-10 20:33:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.conversionlabs.com/quarterly-reports/content/0001213900-17-011996/f10q0917ex32-1_immudyne.htm?TB_iframe=true&height=auto&width=auto&preload=false>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.conversionlabs.com/quarterly-reports/content/0001213900-17-011996/f10q0917ex32-1_immudyne.htm?TB_iframe=true&height=auto&width=auto&preload=false took longer than 15.0 seconds..
2019-11-10 20:33:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cramco.net/ProductDetails.aspx?item_no=CT030-02&CatId=272f15d3-e68d-4486-9235-6377af52d74d>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.cramco.net/ProductDetails.aspx?item_no=CT030-02&CatId=272f15d3-e68d-4486-9235-6377af52d74d took longer than 15.0 seconds..
2019-11-10 20:33:14 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.conferplastics.com/pools-and-spa/optional-equipment/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.conferplastics.com/pools-and-spa/optional-equipment/ took longer than 15.0 seconds..
2019-11-10 20:33:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/communities/south-carolina/greenville/peachtree-village/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/communities/south-carolina/greenville/peachtree-village/ took longer than 15.0 seconds..
2019-11-10 20:33:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.dacor.com/cdn-cgi/l/email-protection#c1a2b4b2b5aeaca4b3b2a0b5a8b2a7a0a2b5a8aeaf81a5a0a2aeb3efa2aeac>: User timeout caused connection failure.
2019-11-10 20:33:14 [scrapy.extensions.logstats] INFO: Crawled 3528 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 20:33:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/communities/virginia/winchester/old-dominion-greens/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/communities/virginia/winchester/old-dominion-greens/ took longer than 15.0 seconds..
2019-11-10 20:33:14 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.dana.com/aftermarket/brands/brands/magnum-gaskets>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.dana.com/aftermarket/brands/brands/magnum-gaskets took longer than 15.0 seconds..
2019-11-10 20:33:14 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.curaegis.com/News-Events/Blog/December-2017/The-25-Benefits-of-Sleep>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.curaegis.com/News-Events/Blog/December-2017/The-25-Benefits-of-Sleep took longer than 15.0 seconds..
2019-11-10 20:33:14 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.conferplastics.com/patio-and-spa-essentials/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.conferplastics.com/patio-and-spa-essentials/ took longer than 15.0 seconds..
2019-11-10 20:33:14 [scrapy.core.scraper] ERROR: Error downloading <GET http://contour.com/video_listing/pow-day-portes-du-soleil>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://contour.com/video_listing/pow-day-portes-du-soleil took longer than 15.0 seconds..
2019-11-10 20:35:34 [scrapy.extensions.logstats] INFO: Crawled 3543 pages (at 15 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 20:38:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://curtisindustries.net/careers/welders/tel:5088532200>: User timeout caused connection failure.
2019-11-10 20:38:38 [scrapy.extensions.logstats] INFO: Crawled 3543 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 20:42:24 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.dana.com/aftermarket/brands/brands/tru-cool>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.dana.com/aftermarket/brands/brands/tru-cool took longer than 15.0 seconds..
2019-11-10 20:42:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://curtisindustries.net/sales-department/tel:5088532200>: User timeout caused connection failure.
2019-11-10 20:42:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.crabtree-evelyn.com/collections/mainline/products/%redirect_store_url%>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.crabtree-evelyn.com/collections/mainline/products/%redirect_store_url% took longer than 15.0 seconds..
2019-11-10 20:42:24 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.curaegis.com/Privacy>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.curaegis.com/Privacy took longer than 15.0 seconds..
2019-11-10 20:42:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/communities/virginia/freedom-manor/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/communities/virginia/freedom-manor/ took longer than 15.0 seconds..
2019-11-10 20:42:24 [scrapy.extensions.logstats] INFO: Crawled 3543 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 20:42:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/communities/virginia/red-bud-run-iii/>: User timeout caused connection failure.
2019-11-10 20:42:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://curtisindustries.net/careers/press-brake-operator/tel:5088532200>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://curtisindustries.net/careers/press-brake-operator/tel:5088532200 took longer than 15.0 seconds..
2019-11-10 20:42:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.crabtree-evelyn.com/collections/evelyn-rose/products/8496>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.crabtree-evelyn.com/collections/evelyn-rose/products/8496 took longer than 15.0 seconds..
2019-11-10 20:42:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cramco.net/ProductDetails.aspx?item_no=TB240-34&CatId=272f15d3-e68d-4486-9235-6377af52d74d>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.cramco.net/ProductDetails.aspx?item_no=TB240-34&CatId=272f15d3-e68d-4486-9235-6377af52d74d took longer than 15.0 seconds..
2019-11-10 20:43:24 [scrapy.extensions.logstats] INFO: Crawled 3555 pages (at 12 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 20:45:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://curtisindustries.net/kawasaki-utv-cabs/%7B%7B%20x.link%20%7D%7D>: User timeout caused connection failure.
2019-11-10 20:45:25 [scrapy.extensions.logstats] INFO: Crawled 3555 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 20:47:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cramco.net/ProductDetails.aspx?item_no=TM150-63&CatId=272f15d3-e68d-4486-9235-6377af52d74d>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.cramco.net/ProductDetails.aspx?item_no=TM150-63&CatId=272f15d3-e68d-4486-9235-6377af52d74d took longer than 15.0 seconds..
2019-11-10 20:47:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.danryanbuilders.com/find-your-home/greenville-sc-quick-move-in-homes/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.danryanbuilders.com/find-your-home/greenville-sc-quick-move-in-homes/ took longer than 15.0 seconds..
2019-11-10 20:47:57 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.dglusa.com/contact-us>: User timeout caused connection failure.
2019-11-10 20:47:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://curtisindustries.net/john-deere-utv-cabs/tel:5088532200>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://curtisindustries.net/john-deere-utv-cabs/tel:5088532200 took longer than 15.0 seconds..
2019-11-10 20:47:57 [scrapy.extensions.logstats] INFO: Crawled 3555 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 20:47:57 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.dglusa.com/licensing>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.dglusa.com/licensing took longer than 15.0 seconds..
2019-11-10 20:47:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.crabtree-evelyn.com/collections/evelyn-rose/products/8487>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.crabtree-evelyn.com/collections/evelyn-rose/products/8487 took longer than 15.0 seconds..
2019-11-10 20:47:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cramco.net/ProductDetails.aspx?item_no=WE570-42&CatId=272f15d3-e68d-4486-9235-6377af52d74d>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.cramco.net/ProductDetails.aspx?item_no=WE570-42&CatId=272f15d3-e68d-4486-9235-6377af52d74d took longer than 15.0 seconds..
2019-11-10 20:47:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://curtisindustries.net/john-deere-utv-cabs/%7B%7B%20x.link%20%7D%7D>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://curtisindustries.net/john-deere-utv-cabs/%7B%7B%20x.link%20%7D%7D took longer than 15.0 seconds..
2019-11-10 20:48:21 [scrapy.extensions.logstats] INFO: Crawled 3561 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 20:49:35 [scrapy.extensions.logstats] INFO: Crawled 3564 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 20:50:24 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.dana.com/off-highway/markets-and-vehicles/construction/wheeled-excavator>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.dana.com/off-highway/markets-and-vehicles/construction/wheeled-excavator took longer than 15.0 seconds..
2019-11-10 20:50:24 [scrapy.extensions.logstats] INFO: Crawled 3567 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 20:51:56 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.dana.com/off-highway/markets-and-vehicles/construction/aerial-work-platform>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.dana.com/off-highway/markets-and-vehicles/construction/aerial-work-platform took longer than 15.0 seconds..
2019-11-10 20:51:56 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.dglusa.com/in-thenew/tag/hype>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.dglusa.com/in-thenew/tag/hype took longer than 15.0 seconds..
2019-11-10 20:51:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/all-sec-filings/xbrl_doc_only/249>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/all-sec-filings/xbrl_doc_only/249 took longer than 15.0 seconds..
2019-11-10 20:51:56 [scrapy.extensions.logstats] INFO: Crawled 3567 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 20:53:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cramco.net/pdf/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.cramco.net/pdf/ took longer than 15.0 seconds..
2019-11-10 20:53:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.crabtree-evelyn.com/products/9255>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.crabtree-evelyn.com/products/9255 took longer than 15.0 seconds..
2019-11-10 20:53:41 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.dana.com/off-highway/markets-and-vehicles/material-handling/fork-lift-truck>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.dana.com/off-highway/markets-and-vehicles/material-handling/fork-lift-truck took longer than 15.0 seconds..
2019-11-10 20:53:41 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.dglusa.com/in-thenew/tag/fargo>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.dglusa.com/in-thenew/tag/fargo took longer than 15.0 seconds..
2019-11-10 20:53:41 [scrapy.extensions.logstats] INFO: Crawled 3567 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 20:53:41 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.dana.com/off-highway/markets-and-vehicles/material-handling/rough-terrain-crane>: User timeout caused connection failure.
2019-11-10 20:53:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.crabtree-evelyn.com/products/8389>: User timeout caused connection failure.
2019-11-10 20:53:41 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.dglusa.com/in-thenew/2015/6/25/ces-2013-armortech-featured-fonemacom>: User timeout caused connection failure.
2019-11-10 20:53:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cramco.net/ProductDetails.aspx?item_no=D8047-74&CatId=272f15d3-e68d-4486-9235-6377af52d74d>: User timeout caused connection failure.
2019-11-10 20:54:21 [scrapy.extensions.logstats] INFO: Crawled 3573 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 20:56:44 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.crabtree-evelyn.com/collections/crabtree/products/%redirect_store_url%>: HTTP status code is not handled or not allowed
2019-11-10 20:56:44 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.conferplastics.com/information/f-a-q/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.conferplastics.com/information/f-a-q/ took longer than 15.0 seconds..
2019-11-10 20:56:44 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.dglusa.com/in-thenew/2015/8/10/miranda-instagrams-lisa-frankdgl-swag>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.dglusa.com/in-thenew/2015/8/10/miranda-instagrams-lisa-frankdgl-swag took longer than 15.0 seconds..
2019-11-10 20:56:44 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/all-sec-filings/xbrl_doc_only/248>: User timeout caused connection failure.
2019-11-10 20:56:44 [scrapy.extensions.logstats] INFO: Crawled 3576 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 20:58:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.conferplastics.com/home-page/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.conferplastics.com/home-page/ took longer than 15.0 seconds..
2019-11-10 20:58:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/all-sec-filings/xbrl_doc_only/245>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/all-sec-filings/xbrl_doc_only/245 took longer than 15.0 seconds..
2019-11-10 20:58:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.crabtree-evelyn.com/collections/evelyn-rose/products/8249>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.crabtree-evelyn.com/collections/evelyn-rose/products/8249 took longer than 15.0 seconds..
2019-11-10 20:58:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.dglusa.com/hype-splash-pages>: User timeout caused connection failure.
2019-11-10 20:58:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.dana.com/corporate-pages/supplier/supplier-diversity/connect>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.dana.com/corporate-pages/supplier/supplier-diversity/connect took longer than 15.0 seconds..
2019-11-10 20:58:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.diamondwipes.com>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.diamondwipes.com took longer than 15.0 seconds..
2019-11-10 20:58:03 [scrapy.extensions.logstats] INFO: Crawled 3576 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 20:58:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.dglusa.com/in-thenew/tag/press+release>: User timeout caused connection failure.
2019-11-10 20:58:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.crabtree-evelyn.com/collections/evelyn-rose/products/8513>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.crabtree-evelyn.com/collections/evelyn-rose/products/8513 took longer than 15.0 seconds..
2019-11-10 20:58:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/all-sec-filings/xbrl_doc_only/244>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/all-sec-filings/xbrl_doc_only/244 took longer than 15.0 seconds..
2019-11-10 20:58:04 [scrapy.extensions.logstats] INFO: Crawled 3578 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 20:59:08 [scrapy.extensions.logstats] INFO: Crawled 3583 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 21:01:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/all-sec-filings/xbrl_doc_only/240>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/all-sec-filings/xbrl_doc_only/240 took longer than 15.0 seconds..
2019-11-10 21:01:04 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.dglusa.com/in-thenew/tag/hype+tapp>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.dglusa.com/in-thenew/tag/hype+tapp took longer than 15.0 seconds..
2019-11-10 21:01:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cyanotech.com/images/Cyan-20181231_xbrl_fileset/cyan-20181231.xsd>: User timeout caused connection failure.
2019-11-10 21:01:04 [scrapy.extensions.logstats] INFO: Crawled 3583 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 21:02:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.crabtree-evelyn.com/collections/evelyn-rose/products/8297>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.crabtree-evelyn.com/collections/evelyn-rose/products/8297 took longer than 15.0 seconds..
2019-11-10 21:02:16 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.dglusa.com/in-thenew/2015/6/25/2015-hype-used-as-props-on-saturday-night-live-louis-ck>: User timeout caused connection failure.
2019-11-10 21:02:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/all-sec-filings/xbrl_doc_only/237>: User timeout caused connection failure.
2019-11-10 21:02:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cyanotech.com/images/Cyan-20181231_xbrl_fileset/cyan-20181231_def.xml>: User timeout caused connection failure.
2019-11-10 21:02:16 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/wp-admin/admin-ajax.php?action=process_simple_like&post_id=23176&nonce=c64bddefbb&is_comment=0&disabled=true>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/wp-admin/admin-ajax.php?action=process_simple_like&post_id=23176&nonce=c64bddefbb&is_comment=0&disabled=true took longer than 15.0 seconds..
2019-11-10 21:02:16 [scrapy.extensions.logstats] INFO: Crawled 3583 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 21:02:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/all-sec-filings/xbrl_doc_only/236>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/all-sec-filings/xbrl_doc_only/236 took longer than 15.0 seconds..
2019-11-10 21:02:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cyanotech.com/images/Cyan-20181231_xbrl_fileset/cyan-20181231_lab.xml>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.cyanotech.com/images/Cyan-20181231_xbrl_fileset/cyan-20181231_lab.xml took longer than 15.0 seconds..
2019-11-10 21:02:17 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/dermaflashs-top-three-tips-for-getting-a-glowing-faux-tan/>: User timeout caused connection failure.
2019-11-10 21:05:14 [scrapy.extensions.logstats] INFO: Crawled 3592 pages (at 9 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 21:07:50 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/six-tips-for-amazing-skin-on-the-big-day/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/six-tips-for-amazing-skin-on-the-big-day/ took longer than 15.0 seconds..
2019-11-10 21:07:50 [scrapy.extensions.logstats] INFO: Crawled 3596 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 21:10:14 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/wp-admin/admin-ajax.php?action=process_simple_like&post_id=23271&nonce=c64bddefbb&is_comment=0&disabled=true>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/wp-admin/admin-ajax.php?action=process_simple_like&post_id=23271&nonce=c64bddefbb&is_comment=0&disabled=true took longer than 15.0 seconds..
2019-11-10 21:10:14 [scrapy.core.scraper] ERROR: Error downloading <GET http://ir.deckers.com/site-map>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://ir.deckers.com/site-map took longer than 15.0 seconds..
2019-11-10 21:10:14 [scrapy.extensions.logstats] INFO: Crawled 3600 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 21:12:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://ir.deckers.com/events-and-presentations>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://ir.deckers.com/events-and-presentations took longer than 15.0 seconds..
2019-11-10 21:12:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://the.dermaflash.com/how-to-get-camera-ready-skin-for-your-fall-wedding/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://the.dermaflash.com/how-to-get-camera-ready-skin-for-your-fall-wedding/ took longer than 15.0 seconds..
2019-11-10 21:12:00 [scrapy.extensions.logstats] INFO: Crawled 3604 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 21:14:15 [scrapy.core.scraper] ERROR: Error downloading <GET http://ir.deckers.com/stock-quote>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://ir.deckers.com/stock-quote took longer than 15.0 seconds..
2019-11-10 21:14:15 [scrapy.extensions.logstats] INFO: Crawled 3608 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 21:15:52 [scrapy.core.scraper] ERROR: Error downloading <GET http://ir.deckers.com/Stock>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://ir.deckers.com/Stock took longer than 15.0 seconds..
2019-11-10 21:15:52 [scrapy.extensions.logstats] INFO: Crawled 3611 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 21:16:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.cyanotech.com/images/Cyan-20180331_xbrl_fileset/cyan-20180331.xml>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.cyanotech.com/images/Cyan-20180331_xbrl_fileset/cyan-20180331.xml took longer than 15.0 seconds..
2019-11-10 21:16:16 [scrapy.extensions.logstats] INFO: Crawled 3615 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 21:17:05 [scrapy.extensions.logstats] INFO: Crawled 3618 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 21:19:38 [scrapy.extensions.logstats] INFO: Crawled 3618 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 21:21:35 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/all-sec-filings/xbrl_doc_only/223>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/all-sec-filings/xbrl_doc_only/223 took longer than 15.0 seconds..
2019-11-10 21:21:35 [scrapy.extensions.logstats] INFO: Crawled 3618 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 21:21:35 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/all-sec-filings/xbrl_doc_only/222>: User timeout caused connection failure.
2019-11-10 21:22:09 [scrapy.extensions.logstats] INFO: Crawled 3621 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 21:23:47 [scrapy.extensions.logstats] INFO: Crawled 3627 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 21:24:37 [scrapy.extensions.logstats] INFO: Crawled 3629 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 21:25:20 [scrapy.extensions.logstats] INFO: Crawled 3631 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 21:26:37 [scrapy.extensions.logstats] INFO: Crawled 3631 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 21:27:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/all-sec-filings/xbrl_doc_only/58>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ir.deltaapparelinc.com/all-sec-filings/xbrl_doc_only/58 took longer than 15.0 seconds..
2019-11-10 21:27:58 [scrapy.extensions.logstats] INFO: Crawled 3631 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 21:27:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://ir.deltaapparelinc.com/all-sec-filings/xbrl_doc_only/57>: User timeout caused connection failure.
2019-11-10 21:28:33 [scrapy.extensions.logstats] INFO: Crawled 3634 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 21:29:37 [scrapy.extensions.logstats] INFO: Crawled 3638 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 21:30:48 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.conferplastics.com/2019/07/coming-this-august-the-edge-step/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.conferplastics.com/2019/07/coming-this-august-the-edge-step/ took longer than 15.0 seconds..
2019-11-10 21:30:48 [scrapy.extensions.logstats] INFO: Crawled 3640 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 21:31:59 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.conferplastics.com/2019/10/boces-students-tour-confer-plastics/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.conferplastics.com/2019/10/boces-students-tour-confer-plastics/ took longer than 15.0 seconds..
2019-11-10 21:31:59 [scrapy.extensions.logstats] INFO: Crawled 3641 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 21:33:14 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.conferplastics.com/2019/10/douglas-confer-scholarship-at-alfred-university/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.conferplastics.com/2019/10/douglas-confer-scholarship-at-alfred-university/ took longer than 15.0 seconds..
2019-11-10 21:33:14 [scrapy.extensions.logstats] INFO: Crawled 3642 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 21:33:49 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.conferplastics.com/2019/06/west-seneca-students-tour-confer-plastics/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.conferplastics.com/2019/06/west-seneca-students-tour-confer-plastics/ took longer than 15.0 seconds..
2019-11-10 21:34:21 [scrapy.extensions.logstats] INFO: Crawled 3646 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 21:35:36 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://www.crabtree-evelyn.com/collections/gift_sets/products/%redirect_store_url%>: HTTP status code is not handled or not allowed
2019-11-10 21:35:36 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.conferplastics.com/2019/06/homeschoolers-tour-confer-plastics/>: User timeout caused connection failure.
2019-11-10 21:35:36 [scrapy.extensions.logstats] INFO: Crawled 3647 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 21:36:09 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.conferplastics.com/2019/06/king-confer-johnston-join-the-twenty-year-club/>: User timeout caused connection failure.
2019-11-10 21:36:09 [scrapy.extensions.logstats] INFO: Crawled 3648 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 21:37:23 [scrapy.extensions.logstats] INFO: Crawled 3650 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 21:38:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.crabtree-evelyn.com/collections/gift_sets/products/8257>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.crabtree-evelyn.com/collections/gift_sets/products/8257 took longer than 15.0 seconds..
2019-11-10 21:38:32 [scrapy.extensions.logstats] INFO: Crawled 3652 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 21:39:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.crabtree-evelyn.com/collections/evelyn-rose/products/%redirect_store_url%>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.crabtree-evelyn.com/collections/evelyn-rose/products/%redirect_store_url% took longer than 15.0 seconds..
2019-11-10 21:39:10 [scrapy.extensions.logstats] INFO: Crawled 3653 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 21:39:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.crabtree-evelyn.com/collections/gift_sets/products/8271>: User timeout caused connection failure.
2019-11-10 21:39:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.crabtree-evelyn.com/collections/gift_sets/products/8241>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.crabtree-evelyn.com/collections/gift_sets/products/8241 took longer than 15.0 seconds..
2019-11-10 21:40:18 [scrapy.extensions.logstats] INFO: Crawled 3656 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 21:41:27 [scrapy.extensions.logstats] INFO: Crawled 3660 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 21:42:31 [scrapy.extensions.logstats] INFO: Crawled 3662 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 21:43:06 [scrapy.extensions.logstats] INFO: Crawled 3664 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 21:44:14 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.conferplastics.com/my-account/lost-password/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.conferplastics.com/my-account/lost-password/ took longer than 15.0 seconds..
2019-11-10 21:44:14 [scrapy.extensions.logstats] INFO: Crawled 3666 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 21:45:25 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.conferplastics.com/2019/06/stanley-g-falk-students-tour-confer-plastics/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.conferplastics.com/2019/06/stanley-g-falk-students-tour-confer-plastics/ took longer than 15.0 seconds..
2019-11-10 21:45:26 [scrapy.extensions.logstats] INFO: Crawled 3667 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 21:46:36 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.conferplastics.com/author/bob/page/3/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.conferplastics.com/author/bob/page/3/ took longer than 15.0 seconds..
2019-11-10 21:46:36 [scrapy.extensions.logstats] INFO: Crawled 3668 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 21:47:13 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.conferplastics.com/2019/03/confer-looking-to-hire-engineering-intern-for-the-summer-months/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.conferplastics.com/2019/03/confer-looking-to-hire-engineering-intern-for-the-summer-months/ took longer than 15.0 seconds..
2019-11-10 21:47:13 [scrapy.extensions.logstats] INFO: Crawled 3670 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 21:47:46 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.conferplastics.com/2019/04/how-do-i-prevent-alga-build-up-in-my-swimming-pool/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.conferplastics.com/2019/04/how-do-i-prevent-alga-build-up-in-my-swimming-pool/ took longer than 15.0 seconds..
2019-11-10 21:48:57 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.conferplastics.com/2019/04/cpi-retiree-dave-bassler-has-passed-away/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.conferplastics.com/2019/04/cpi-retiree-dave-bassler-has-passed-away/ took longer than 15.0 seconds..
2019-11-10 21:48:57 [scrapy.extensions.logstats] INFO: Crawled 3674 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 21:49:53 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.conferplastics.com/2019/04/cpi-donates-skids-to-teen-challenge/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.conferplastics.com/2019/04/cpi-donates-skids-to-teen-challenge/ took longer than 15.0 seconds..
2019-11-10 21:49:53 [scrapy.extensions.logstats] INFO: Crawled 3676 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 21:50:57 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.conferplastics.com/2019/04/whats-so-cool-about-manufacturing-voting-underway/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.conferplastics.com/2019/04/whats-so-cool-about-manufacturing-voting-underway/ took longer than 15.0 seconds..
2019-11-10 21:50:57 [scrapy.extensions.logstats] INFO: Crawled 3677 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 21:51:46 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.conferplastics.com/2019/04/attention-homeschoolers-there-will-be-a-tour-on-june-12th/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.conferplastics.com/2019/04/attention-homeschoolers-there-will-be-a-tour-on-june-12th/ took longer than 15.0 seconds..
2019-11-10 21:51:47 [scrapy.extensions.logstats] INFO: Crawled 3679 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 21:52:11 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.conferplastics.com/2019/05/prom-dress-distribution-sunday-may-5/>: User timeout caused connection failure.
2019-11-10 21:52:11 [scrapy.extensions.logstats] INFO: Crawled 3680 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 21:52:37 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.conferplastics.com/2019/05/ribbon-cutting-at-gratwick-boat-launch/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.conferplastics.com/2019/05/ribbon-cutting-at-gratwick-boat-launch/ took longer than 15.0 seconds..
2019-11-10 21:53:21 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.conferplastics.com/2019/05/memorial-day-2019/>
Traceback (most recent call last):
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\python\failure.py", line 408, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\root\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 320, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.conferplastics.com/2019/05/memorial-day-2019/ took longer than 15.0 seconds..
2019-11-10 21:53:21 [scrapy.extensions.logstats] INFO: Crawled 3684 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 21:54:29 [scrapy.extensions.logstats] INFO: Crawled 3686 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 21:55:42 [scrapy.extensions.logstats] INFO: Crawled 3688 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 21:56:54 [scrapy.extensions.logstats] INFO: Crawled 3690 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 21:57:30 [scrapy.extensions.logstats] INFO: Crawled 3691 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 21:58:41 [scrapy.extensions.logstats] INFO: Crawled 3692 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 21:59:18 [scrapy.extensions.logstats] INFO: Crawled 3693 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 22:00:27 [scrapy.extensions.logstats] INFO: Crawled 3695 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 22:01:04 [scrapy.extensions.logstats] INFO: Crawled 3696 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 22:02:14 [scrapy.extensions.logstats] INFO: Crawled 3698 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 22:03:29 [scrapy.extensions.logstats] INFO: Crawled 3700 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 22:04:07 [scrapy.extensions.logstats] INFO: Crawled 3701 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 22:05:07 [scrapy.extensions.logstats] INFO: Crawled 3703 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 22:06:08 [scrapy.extensions.logstats] INFO: Crawled 3705 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 22:07:22 [scrapy.extensions.logstats] INFO: Crawled 3707 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 22:08:30 [scrapy.extensions.logstats] INFO: Crawled 3709 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 22:09:09 [scrapy.extensions.logstats] INFO: Crawled 3710 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 22:10:24 [scrapy.extensions.logstats] INFO: Crawled 3712 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 22:11:19 [scrapy.extensions.logstats] INFO: Crawled 3714 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 22:12:08 [scrapy.extensions.logstats] INFO: Crawled 3716 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 22:13:39 [scrapy.extensions.logstats] INFO: Crawled 3719 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 22:14:28 [scrapy.extensions.logstats] INFO: Crawled 3721 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2019-11-10 22:14:48 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-10 22:14:48 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 5028,
 'downloader/exception_type_count/scrapy.exceptions.IgnoreRequest': 26,
 'downloader/exception_type_count/twisted.internet.defer.CancelledError': 1,
 'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 30,
 'downloader/exception_type_count/twisted.internet.error.TimeoutError': 4440,
 'downloader/exception_type_count/twisted.web._newclient.ResponseFailed': 1,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 530,
 'downloader/request_bytes': 5179155,
 'downloader/request_count': 9379,
 'downloader/request_method_count/GET': 9379,
 'downloader/response_bytes': 97733281,
 'downloader/response_count': 4377,
 'downloader/response_status_count/200': 3603,
 'downloader/response_status_count/301': 417,
 'downloader/response_status_count/302': 234,
 'downloader/response_status_count/400': 41,
 'downloader/response_status_count/403': 12,
 'downloader/response_status_count/404': 70,
 'dupefilter/filtered': 19956,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 10, 21, 14, 48, 702393),
 'httperror/response_ignored_count': 41,
 'httperror/response_ignored_status_count/400': 41,
 'log_count/ERROR': 1124,
 'log_count/INFO': 1254,
 'log_count/WARNING': 1,
 'offsite/domains': 1235,
 'offsite/filtered': 22930,
 'request_depth_count/0': 36,
 'request_depth_count/1': 2111,
 'request_depth_count/2': 29271,
 'request_depth_count/3': 15291,
 'request_depth_count/4': 775,
 'request_depth_count/5': 99,
 'request_depth_max': 5,
 'response_received_count': 3723,
 'retry/count': 3880,
 'retry/max_reached': 1121,
 'retry/reason_count/twisted.internet.error.DNSLookupError': 20,
 'retry/reason_count/twisted.internet.error.TimeoutError': 3467,
 'retry/reason_count/twisted.web._newclient.ResponseFailed': 1,
 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 392,
 'scheduler/dequeued': 9076,
 'scheduler/dequeued/memory': 9076,
 'scheduler/enqueued': 9076,
 'scheduler/enqueued/memory': 9076,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2019, 11, 9, 17, 11, 4, 165508)}
2019-11-10 22:14:48 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-10 22:14:48 [root] INFO: spider 4 end
